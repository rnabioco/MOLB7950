[
  {
    "objectID": "zzz.html",
    "href": "zzz.html",
    "title": "dummy file so that downlit ends up",
    "section": "",
    "text": "dummy file so that downlit ends up\n\n\nin the renv lock file.\n\nlibrary(downlit)"
  },
  {
    "objectID": "resources/bootcamp-resources.html",
    "href": "resources/bootcamp-resources.html",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2"
  },
  {
    "objectID": "resources/bootcamp-resources.html#r-rstudio",
    "href": "resources/bootcamp-resources.html#r-rstudio",
    "title": "Bootcamp resources",
    "section": "",
    "text": "Installing R\nInstalling RStudio\n\n\n\n\n\nAdvanced R\nComputational Genomics with R\nR for Data Science (R4DS)\nFundamentals of Data Visualization\n\nQuick reference:\n\nData tidying\nYour labels are too small.. Use cowplot themes to automatically adjust.\n\n\n\n\n\nThe Tidyverse is a collection of libaries implementing a principled approach to data analysis.\nBioconductor is a collection of libraries focused on biological data analysis.\nggplot2\ncowplot\nggthemes\n\n\n\n\nThe tidyverse cheat sheets are indispensible references.\nQuick reference:\n\nRStudio\nRmarkdown\ntidyr\ndplyr\nggplot2"
  },
  {
    "objectID": "resources/bootcamp-resources.html#statistics",
    "href": "resources/bootcamp-resources.html#statistics",
    "title": "Bootcamp resources",
    "section": "Statistics",
    "text": "Statistics\n\nPractical Statistics for Data Scientists covers several fundamental concepts with code for both R and Python.\nModern Statistics for Modern Biology is written by two leading figures in computational biology and contains several examples using Bioconductor.\nStatistics for Biologists is a collection of articles on statistical topic."
  },
  {
    "objectID": "resources/bootcamp-resources.html#miscellaneous",
    "href": "resources/bootcamp-resources.html#miscellaneous",
    "title": "Bootcamp resources",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\nOrganizing projects\nHappy Git with R"
  },
  {
    "objectID": "resources/block-dna-resources.html",
    "href": "resources/block-dna-resources.html",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]"
  },
  {
    "objectID": "resources/block-dna-resources.html#foundational-work",
    "href": "resources/block-dna-resources.html#foundational-work",
    "title": "Resources for the DNA block",
    "section": "",
    "text": "These studies below laid the methodological groundwork for high throughput chromatin characterization by DNA sequencing. Some of the authors are here at CU Anschutz!\n\n\n\n\n\n\nTip\n\n\n\nData sets from these studies would be excellent choices as starting points for your final projects.\n\n\n\n\nHesselberth JR, Chen X, Zhang Z, Sabo PJ, Sandstrom R, Reynolds AP, Thurman RE, Neph S, Kuehn MS, Noble WS, Fields S, Stamatoyannopoulos JA. Global mapping of protein-DNA interactions in vivo by digital genomic footprinting. Nat Methods. 2009 19305407; PMCID: PMC2668528. [Link]\n\n\n\nBuenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods. 2013 PMID: 24097267; PMCID: PMC3959825. [Link]\n\n\n\nRamachandran S, Ahmad K, Henikoff S. Transcription and Remodeling Produce Asymmetrically Unwrapped Nucleosomal Intermediates. Mol Cell. 2017 PMID: 29225036; PMCID: PMC6421108. [Link]\n\n\n\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]"
  },
  {
    "objectID": "resources/block-dna-resources.html#software-well-use-in-class",
    "href": "resources/block-dna-resources.html#software-well-use-in-class",
    "title": "Resources for the DNA block",
    "section": "Software we’ll use in class",
    "text": "Software we’ll use in class\n\nRead over the GViz vignette to understand how we’ll use it to vissualize genome-scale data on a reference sequence.\nRead over the valr vignette to understand how we’ll do BEDtools-like (see below) analysis within RStudio.\nLook over the ComplexHeatmap and EnrichedHeatmap documentation, especially XXX. These tools will help us make “meta-plots”: figures that plot genomic signals relative to features."
  },
  {
    "objectID": "resources/block-dna-resources.html#other-important-tools",
    "href": "resources/block-dna-resources.html#other-important-tools",
    "title": "Resources for the DNA block",
    "section": "Other important tools",
    "text": "Other important tools\nThese are other tools I’ll mention in class. We’re not going to use them directly, but they are important tools in upstream data processing and analysis.\n\nAlignment software\nBowtie2 and BWA are popular choices for short read alignment. They are fast, free, and well-maintained.\n\n\nPeak calling\nMACS is the gold-standard in peak calling. It models read coverage as a Poisson process, straightforward identification of regions of higher than expected coverage (i.e., peaks) to be identified using a single parmaeter (lambda) that captures the mean and variance of read coverage.\n\n\nInterval analysis\n\nBEDtools is the “Swiss Army knife” of genome interval analysis. It provides a host of command-line tools that can be linked together for powerful genome signal manipulation."
  },
  {
    "objectID": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "href": "resources/block-dna-resources.html#experimental-rigor-in-chromatin-analysis",
    "title": "Resources for the DNA block",
    "section": "Experimental rigor in chromatin analysis",
    "text": "Experimental rigor in chromatin analysis\nThese studies identified pervasive artifacts in genomewide chromatin analysis and provide recommendations and solutions to the issues.\nTeytelman L, Thurtle DM, Rine J, van Oudenaarden A. Highly expressed loci are vulnerable to misleading ChIP localization of multiple unrelated proteins. Proc Natl Acad Sci U S A. 2013 Nov 12;110(46):18602-7. doi: 10.1073/pnas.1316064110. Epub 2013 Oct 30. PMID: 24173036; PMCID: PMC3831989.\nShah RN, Grzybowski AT, Cornett EM, Johnstone AL, Dickson BM, Boone BA, Cheek MA, Cowles MW, Maryanski D, Meiners MJ, Tiedemann RL, Vaughan RM, Arora N, Sun ZW, Rothbart SB, Keogh MC, Ruthenburg AJ. Examining the Roles of H3K4 Methylation States with Systematically Characterized Antibodies. Mol Cell. 2018 Oct 4;72(1):162-177.e7. doi: 10.1016/j.molcel.2018.08.015. Epub 2018 Sep 20. PMID: 30244833; PMCID: PMC6173622."
  },
  {
    "objectID": "problem-sets/ps-23.html",
    "href": "problem-sets/ps-23.html",
    "title": "RNA Block - Problem Set 23",
    "section": "",
    "text": "Total points: 20. First problem is worth 10 points, second and third problems are worth 5 points."
  },
  {
    "objectID": "problem-sets/ps-23.html#problem-set",
    "href": "problem-sets/ps-23.html#problem-set",
    "title": "RNA Block - Problem Set 23",
    "section": "",
    "text": "Total points: 20. First problem is worth 10 points, second and third problems are worth 5 points."
  },
  {
    "objectID": "problem-sets/ps-23.html#load-libraries",
    "href": "problem-sets/ps-23.html#load-libraries",
    "title": "RNA Block - Problem Set 23",
    "section": "Load libraries",
    "text": "Load libraries\nStart by loading libraries you need analysis in the code chunk below.\nWe have an experiment where we can take neuronal cells and mechanically separate them into soma and neurite fractions. By sequencing RNA from both of these fractions and comparing the relative abundances of RNAs, we can get a sense of how neurite-localized every RNA is. We can also combine this approach with knockouts of specific RBPs. If we have an RBP that we think is involved in this process, we can do this subcellular fractionation in sequencing in both WT and RBP-knockout (KO) cells. Transcripts that depend upon the RBP for transcript to the neurite should be less neurite-enriched in the KO samples than the WT samples.\nWe recently completed this process in mouse cells that lack the RBP TDP-43. We have RNA sequence data for 4 conditions: WT soma, WT neurite, KO soma, and KO neurite with 3 replicates of each condition. These samples have been quantified with salmon.\nRead in this data, collapse salmon’s transcript-level quantification to gene-level quantification with tximport. Then assess the quality of this data by performing hierarchical clustering of pairwise spearman correlation values and PCA analysis of TPM expression values.\nThe salmon data lives in data/block-rna/salmon_tdp43. In that directory, you will find one salmon output directory for each sample."
  },
  {
    "objectID": "problem-sets/ps-23.html#q1-read-in-salmon-data-10-pts",
    "href": "problem-sets/ps-23.html#q1-read-in-salmon-data-10-pts",
    "title": "RNA Block - Problem Set 23",
    "section": "Q1: read in salmon data (10 pts)",
    "text": "Q1: read in salmon data (10 pts)\n\n#There are some hints to help you get started\n\n#Use biomaRt to get a table of transcript/gene relationships\nmart &lt;- biomaRt::useMart(\n  \"ENSEMBL_MART_ENSEMBL\",\n  dataset = \"??\",\n  host = \"www.ensembl.org\"\n)\n\nt2g &lt;- biomaRt::getBM(attributes = c(\"ensembl_transcript_id\", \"ensembl_gene_id\", \"external_gene_name\"), mart = mart) |&gt;\n  dplyr::select(??, ??)\n\n\n\n#Read in salmon quantification files\n\nmetadata &lt;- data.frame(sample_id = list.files(here(\"??\")),\n                   salmon_dirs = list.files(here(\"??\"),recursive = T,pattern = \".gz$\", full.names = T)\n\n                   ) |&gt; \n  separate(col = ??,\n           into = c(\"cell\",\"loc\",\"geno\",\"rep\"),\n           sep = \"??\",\n           remove = F)\n\nmetadata$rep &lt;- gsub(pattern = \"Rep\", replacement = \"\", metadata$rep) \n\nrownames(metadata) &lt;- metadata$sample_id\n\n\n#Get gene-level TPM values with tximport\n\nsalmdir &lt;- metadata$??\nnames(salmdir) &lt;- metadata$??\n\n\ntxi &lt;- tximport(files = ??,\n  type = \"salmon\",\n  tx2gene = ??,\n  dropInfReps = TRUE,\n  countsFromAbundance = \"lengthScaledTPM\"\n)\n\n#Filter genes to remove those that are not expressed at at least 1 TPM in EVERY sample\ntpms &lt;- txi$?? |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ensembl_gene_id\")\n\n\ntpms.cutoff &lt;-\n  mutate(tpms, nSamples = rowSums(tpms[, 2:??] &gt; 1)) |&gt;\n  filter(nSamples &gt;= ??) |&gt;\n  \n  dplyr::select(-nSamples)"
  },
  {
    "objectID": "problem-sets/ps-23.html#q2-make-correlation-heatmap-5-pts",
    "href": "problem-sets/ps-23.html#q2-make-correlation-heatmap-5-pts",
    "title": "RNA Block - Problem Set 23",
    "section": "Q2: make correlation heatmap (5 pts)",
    "text": "Q2: make correlation heatmap (5 pts)\n\n#Use cor() to get a matrix of pairwise correlations between samples\ntpms.cor &lt;- cor(??, method = \"??\")\n\n#Use pheatmap() to plot correlation matrix\n\npheatmap(\n  ??,\n  annotation_col = metadata[,??], # what would be interesting to add as colored categories\n  fontsize = 7,\n  show_colnames = FALSE\n)\n\n\n\nHINT: what your answer should look like\n\n\nProvide 1-2 sentences of interpretation of the similarity of the samples based on the heatmap."
  },
  {
    "objectID": "problem-sets/ps-23.html#q3-make-pca-plot-5-pts",
    "href": "problem-sets/ps-23.html#q3-make-pca-plot-5-pts",
    "title": "RNA Block - Problem Set 23",
    "section": "Q3: make PCA plot (5 pts)",
    "text": "Q3: make PCA plot (5 pts)\n\n#Start with the filtered TPM table from above\ntpms.cutoff.matrix &lt;- tpms.cutoff |&gt;\n  dplyr::select(-??) |&gt;\n  as.??()\n\n\n#Use prcomp() to derive principle component coordinants of *LOGGED*  and *Scaled* TPM values\ntpms.cutoff.matrix &lt;- log??(tpms.cutoff.matrix + ??)\n\n# scale\ntpms.cutoff.matrix &lt;- ??(scale(??(tpms.cutoff.matrix)))\n\n\n# principle components\ntpms.pca &lt;- prcomp(t(tpms.cutoff.matrix))\n\n#Add annotations of the cell compartment (soma / neurite) and TDP-43 status (WT / KO) of the samples\ntpms.pca.pc &lt;- tpms.pca$x %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(var = \"sample_id\") %&gt;% \n  left_join(., metadata[,c(1,??)], by = \"??\")\n\n## \n\ntpms.pca.summary &lt;- summary(tpms.pca)$importance\npc1var &lt;- round(tpms.pca.summary[2, 1] * 100, 1)\npc2var &lt;- round(tpms.pca.summary[2, 2] * 100, 1)\n\n#Plot PCA data\n\nggplot(data = tpms.pca.pc,\n  aes(\n    x = PC1, y = PC2,\n    color = paste(??,??), label = sample_id\n  )\n) +\n  geom_point(size = 5) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_cowplot(16) +\n  labs(\n    x = paste(\"PC1,\", pc1var, \"% explained var.\"),\n    y = paste(\"PC2,\", pc2var, \"% explained var.\")\n  ) +\n  geom_text_repel()\n\n\n\nHINT: what your answer should look like\n\n\nProvide 1-2 sentences of interpretation of the similarity of the samples based on the heatmap."
  },
  {
    "objectID": "problem-sets/ps-18.html",
    "href": "problem-sets/ps-18.html",
    "title": "DNA Block - Problem Set 18",
    "section": "",
    "text": "Total points: 20. First problem is worth 7 points, second problem is worth 13 points."
  },
  {
    "objectID": "problem-sets/ps-18.html#problem-set",
    "href": "problem-sets/ps-18.html#problem-set",
    "title": "DNA Block - Problem Set 18",
    "section": "",
    "text": "Total points: 20. First problem is worth 7 points, second problem is worth 13 points."
  },
  {
    "objectID": "problem-sets/ps-18.html#load-libraries",
    "href": "problem-sets/ps-18.html#load-libraries",
    "title": "DNA Block - Problem Set 18",
    "section": "Load libraries",
    "text": "Load libraries\nStart by loading libraries you need analysis in the code chunk below.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(cowplot)\nlibrary(valr)\n\nLoad the data from the MNase-seq experiment.\n\nmnase_tbl &lt;- read_bed(\n  here(\"data/block-dna/yeast_mnase_chrII.bed.gz\")\n)\n\nIn class we learned that MNase digestion yields nucleosomal “footprints” of ~150 bp in size. I’ve added blue vertical lines to emphasize positions of the major peak (intact nucleosomes) as well as smaller “sub-nucleosomal” peak.\n\nWe can calculate the counts for the histogram above and more precisely determine the maximum signal using which.max() to identify the index of the maximum value in a vector (not the value itself!):\n\nfrag_hist &lt;-\n  mnase_tbl |&gt;\n  mutate(frag_len = end - start) |&gt;\n  count(frag_len)\n\n# `which.max` takes a vector and gives us the index of the maximum value\nmax_idx &lt;- which.max(frag_hist$n)\n\n# now we can use index to find the abundant fragment size.\n# we'll use `ncp_max` later in question 2.\nncp_max &lt;- frag_hist$frag_len[max_idx]\n\nSo this tells us that that the most abundant fragment size in the library is ??? bp."
  },
  {
    "objectID": "problem-sets/ps-18.html#question-1-7-points",
    "href": "problem-sets/ps-18.html#question-1-7-points",
    "title": "DNA Block - Problem Set 18",
    "section": "Question 1 – 7 points",
    "text": "Question 1 – 7 points\nLet’s take a closer look at the some of the smaller fragments in the MNase experiment. In particular, let’s zoom in on the populations of fragments that are smaller than 1 nucleosome in size, the peak between 85 and 95 bp (the left-most blue vertical line).\n\nUse the above strategy to precisely determine the peak of this smaller size range. How big are those fragments? These are called “sub-nucleosomal” fragments.\n\n\n# store the maximum value in `subnuc_max`. we'll use it later in question 2.\n\n\nThe maximum sub-nucleosomal fragments size is ??? bp.\n\n\nDo this one more time, and identify the position of maximum signal in the disome peak (i.e., the fragments protected by two nucleosomes).\n\n\nRecreate the histogram using ggplot2 (using relevant code from class 17) and add the blue vertical lines at the peak positions you calculated, including the position of the disomes above."
  },
  {
    "objectID": "problem-sets/ps-18.html#question-2-13-points",
    "href": "problem-sets/ps-18.html#question-2-13-points",
    "title": "DNA Block - Problem Set 18",
    "section": "Question 2 – 13 points",
    "text": "Question 2 – 13 points\nNext we’re going to look at where these sub-sucleosomes are with respect to intact nucleosomes.\nOur strategy will be to compare the density of sub-nucleosomes relative to the mid-points of previously mapped nucleosomes. Specifically, our reference point will be the midpoints of the +1 nucleosomes.\nSo you’ll make a metaplot, but instead of using transcription start sites as the reference point, we’ll use the midpoints of the +1 nucleosome, and instead of MNase-seq signal density, you’ll count up the number of individual reads that intersect with windows around those midpoints.\n\n\nFirst, load the relevant data. We’ll re-use the yeast_mnase_chrII.bed.gz data you loaded above, plus you’ll need to load two other files:\n\na “genome” file, sacCer3.chrom.sizes\n\na BED file, yeast_p1_chrII.bed.gz which contains the mid-points of the +1 nucleosomes on chromosome 22. Recall that the +1 nucleosome is the nucleosome downstream of the transcription start site.\n\n\n\n\ngenome &lt;- read_???(here(\"data/block-dna/sacCer3.chrom.sizes\"))\np1_tbl &lt;- read_???(here(\"data/block-dna/yeast_p1_chrII.bed.gz\"))\n\n\n\nNext, we need the mid-points of nucleosomes for comparison. The following function needs fixing. The midpoint is the coordinate halfway between the start and end of a given interval.\nYou’re going to provide the mnase_tbl defined in question 1 to this function, which then:\n\ncalculates fragment lengths\nfilters them based on min_len and max_len\ncalculates the midpoints for each interval\n\nThe output is a new tibble with columns `chrom`, `start`, and `end`.\n\n\n\ncalc_mids &lt;- function(tbl, min_len, max_len) {\n  tbl |&gt;\n    mutate(\n      frag_len = ___ - ___\n    ) |&gt;\n    filter(\n      frag_len &gt;= ___ & frag_len &lt;= ___\n    ) |&gt;\n    mutate(\n      # calculate the half-size interval using `end` and `start,\n      # then add that value to `start`\n      midpoint = ___\n    ) |&gt;\n    select(chrom, midpoint) |&gt;\n    rename(start = midpoint) |&gt;\n    mutate(end = start + 1)\n}\n\n\nNext, use that function to calculate midpoints, and expand these midpoints by 20 bp in each direction with bed_slop().\n\n\nncp_mids_tbl &lt;-\n  # first calculate midpoints for nucleosome fragments within 3 bp length `ncp_max`\n  calc_mids(mnase_tbl, ___ - 3, ___ + 3) |&gt;\n  # expand those windows to get a larter window for intersection\n  bed_slop(genome, both = 20)\n\n# now, do the same for nucleosome fragments of length `subnuc_max`\nsubnuc_mids_tbl &lt;-\n  calc_mids(mnase_tbl, ___ - 3, ___ + 3) |&gt;\n  bed_slop(genome, both = 20)\n\n\nNext, we need to make the reference points for a metaplot. We’ll look 100 bp up- and downstream of the +1 nucleosome positions, and make windows that are 1 bp in size.\n\n\np1_win_tbl &lt;-\n  bed_???(\n    p1_tbl,\n    genome,\n    both = 100\n  ) |&gt;\n  bed_???(win_size = 1)\n\n\n\nAlmost there! Now you just need to identify the number of short and long nuclesome fragments (based on their midpoints) that intersect with the +1 nucleosomes you defined above.\nUse bed_intersect() to identify fragments that overlap, and then just count the number of fragments per .win_id (don’t forget the suffix). Note you will do this separately for the short and long fragments.\n\n\n\nncp_mids_summary_tbl &lt;-\n  bed_intersect(\n    p1_win_tbl,\n    ncp_mids_tbl\n  ) |&gt;\n  dplyr::count(___) |&gt;\n  mutate(type = \"Intact nucleosomes (~149 bp)\")\n\nsubnuc_mids_summary_tbl &lt;-\n  bed_intersect(\n    p1_win_tbl,\n    subnuc_mids_tbl\n  ) |&gt;\n  dplyr::count(___) |&gt;\n  mutate(type = \"Sub-nucleosomes (~90 bp)\")\n\n\nThe following joins the tables you made together, and makes the x-axis more informative, by converting to relative genomic position rather than window ID.\n\n\nwin_ids &lt;- seq(-100, 100, 1)\n\nall_tbl &lt;- bind_rows(\n  ncp_mids_summary_tbl,\n  subnuc_mids_summary_tbl\n) |&gt;\n  mutate(win_ids = win_ids, .by = \"type\")\n\n\nFinally, we plot the data with position on the x-axis, and count on the y-axis.\n\n\nggplot(\n  all_tbl,\n  aes(win_ids, n)\n) +\n  geom_???(color = \"red\") +\n  facet_wrap(\n    ~ type,\n    scales = \"free_y\"\n  ) +\n  theme_minimal_grid() +\n  labs(\n    x = \"Position relative to +1 nucleosome midpoints\",\n    y = \"Number of intersecting fragments\",\n    title = \"Fragment density around +1 nucleosome midpoints\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-18.html#output",
    "href": "problem-sets/ps-18.html#output",
    "title": "DNA Block - Problem Set 18",
    "section": "Output",
    "text": "Output\nYour plot should look like this.\n\n\nPlot output of step 7"
  },
  {
    "objectID": "problem-sets/ps-18.html#interpretation",
    "href": "problem-sets/ps-18.html#interpretation",
    "title": "DNA Block - Problem Set 18",
    "section": "Interpretation",
    "text": "Interpretation\nHow do you interpret these plots?\nRationalize the pattern for intact nucleosomes. What pattern did you expect to see?\n\nAnswer.\n\nRationalize the pattern for sub-nucleosomes. How would you describe the positions of sub-nucleosomal fragments, relative to the +1 nucleosome midpoints? What might this mean with respect to gene transcription?\n\nAnswer.\n\nWhat do the differences between signal magnitudes (reflected by the y-axis) mean?\n\nAnswer."
  },
  {
    "objectID": "problem-sets/ps-18.html#submit",
    "href": "problem-sets/ps-18.html#submit",
    "title": "DNA Block - Problem Set 18",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output. Then paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-15.html",
    "href": "problem-sets/ps-15.html",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\nang &lt;- read_csv(here(\"data/bootcamp/edger.csv.gz\")) |&gt;\n  clean_names() |&gt;\n  filter(fdr &lt; 0.05) |&gt;\n  select(log_fc_time0_25:log_fc_time8) |&gt;\n  as.matrix()\n\ncolnames(ang) &lt;- gsub(pattern = \"log_fc_\", \"\", colnames(ang))"
  },
  {
    "objectID": "problem-sets/ps-15.html#problem-1",
    "href": "problem-sets/ps-15.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "Problem # 1",
    "text": "Problem # 1\nMake sure to run the chunk above. The data represent the avg fold change in gene expression for an angiotensin II time course (.25, .5, .75, 1, 1.5, 2, 3, 4, 6, 8, 24 hrs) compared to unstimulated."
  },
  {
    "objectID": "problem-sets/ps-15.html#correlation",
    "href": "problem-sets/ps-15.html#correlation",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "correlation",
    "text": "correlation\nCreate hierarchical clustering heatmap of pairwise pearson correlation coefficients. And provide 1-2 observations.\n\n# scale\n\n# pairwise pearson correlation\n\n\n# make heatmap\n\nTimepoints close to each other tend to correlate strongly with each other. The 4,6, and 8 hr time points are the most different from all others."
  },
  {
    "objectID": "problem-sets/ps-15.html#pca",
    "href": "problem-sets/ps-15.html#pca",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\nPerform PCA and visualize PC1 vs PC2.Provide 1-2 observations.\n\n# pca\n\n\n# gather info from summary\n\n\n\n\n# we make a dataframe out of the rotations and will use this to plot\n\n\n# plot"
  },
  {
    "objectID": "problem-sets/ps-15.html#calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "href": "problem-sets/ps-15.html#calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "Calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling",
    "text": "Calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling\nIn order to do this, you will need to:\n\nIdentify which cluster is the most enriched for DUX4 targets.\n\nDetermine how many genes are in the cluster. You will need to know this to figure out how many genes to sample from the whole data set.\nDetermine how many of the genes in the cluster are DUX4 targets. This is the metric that you are interested in comparing between the null distribution and your observation.\n\n\nGenerate 1000 random sample of the proper size from all genes and find out how many of them are DUX4 targets.\nVisualize the distribution of DUX4 targets in these 1000 random (your null distribution) and overlay the number of DUX4 targets you observed in the cluster that was most enriched for DUX4 targets.\n\n\n# read in data\ncd &lt;- read_tsv(here(\"data\", \"dux4_clustering_results.csv.gz\"))\n\nRows: 10566 Columns: 15\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr  (2): gene_symbol, target\ndbl (13): hour00_rep1, hour00_rep2, hour00_rep3, hour04_rep1, hour04_rep2, h...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# how many genes are in cluster of interest?\n\n# how many dux targets are in cluster interest?\n\n\n\n# initialize empty vector\nsampled_targets &lt;- vector()\n\n# randomly sample # genes above from data 1000x and tally number of dux4 targets each random sampling\n\n\n\n# plot\n\nWhat is the p-value?\nWhat is your interpretation?"
  },
  {
    "objectID": "problem-sets/ps-13.html",
    "href": "problem-sets/ps-13.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-sets/ps-13.html#problem-1",
    "href": "problem-sets/ps-13.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nIs there an association between mouse calcium and sodium levels?\n1. Make a scatterplot to inspect variable\n2. Are they normal (enough)?\nWhich test will you use and why?\n\n\n\n3. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that there is no dependency/association between \\(calcium\\) and \\(sodium\\)\n4. Calculate and plot the correlation on a scatterplot"
  },
  {
    "objectID": "problem-sets/ps-13.html#problem-2",
    "href": "problem-sets/ps-13.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 2",
    "text": "Problem # 2"
  },
  {
    "objectID": "problem-sets/ps-13.html#do-mouse-calcium-levels-explain-mouse-sodium-levels-if-so-to-what-extent",
    "href": "problem-sets/ps-13.html#do-mouse-calcium-levels-explain-mouse-sodium-levels-if-so-to-what-extent",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Do mouse calcium levels explain mouse sodium levels? If so, to what extent?",
    "text": "Do mouse calcium levels explain mouse sodium levels? If so, to what extent?\nUse a linear model to do the following:\n1. Specify the Response and Explanatory variables — (2 pts)\n\nThe response variable y is The explantory variable x is\n\n2. Declare the null hypothesis — (1 pts)\n\nThe null hypothesis is …\n\n3. Use the lm function to create a fit (linear model)\nalso save the slope and intercept for later\n4. Add residuals to the data and create a plot visualizing the residuals\n5. Calculate the \\(R^2\\) and compare to \\(R^2\\) from fit\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\\(SS_{fit} = \\sum_{i=1}^{n} (data - line)^2 = \\sum_{i=1}^{n} (y_{i} - (\\beta_0 \\cdot 1+ \\beta_1 \\cdot x)^2\\)\n\\(SS_{null}\\) &lt;80&gt;&lt;94&gt; sum of squared errors around the mean of \\(y\\)\n\\(SS_{null} = \\sum_{i=1}^{n} (data - mean)^2 = \\sum_{i=1}^{n} (y_{i} - \\overline{y})^2\\)\n6. Using \\(R^2\\), describe the extent to which calcium explains sodium levels\n\n\n\n7. Report (do not calculate) the \\(p-value\\) and your decision on the null\n\nThe null hypothesis is …\n\nCalcium levels to predict sodium levels."
  },
  {
    "objectID": "problem-sets/ps-13.html#problem-3",
    "href": "problem-sets/ps-13.html#problem-3",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 3",
    "text": "Problem # 3\nWhat is the association between mouse weight and age levels for different sexes?\n1. Calculate the pearson correlation coefficient between weight and age for females and males\n2. Describe your observations\n\nThe relationship between weight and age…"
  },
  {
    "objectID": "problem-sets/ps-11.html",
    "href": "problem-sets/ps-11.html",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp"
  },
  {
    "objectID": "problem-sets/ps-11.html#problem-1",
    "href": "problem-sets/ps-11.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Problem # 1",
    "text": "Problem # 1\nAssume that the height jackalopes fit a normal distribution. Through careful field research measuring 1000 wild jackalopes, we have determined the mean height is 97 cm and the standard deviation is 10 cm. Your was camping and found a jackalope. Being a great friend and knowing your interest in jackalopes, they (harmlessly) subdued and measured the wild jackalope and found that it was 75 cm.\n\nSimulate a normal distribution of 1000 jackalope heights using the mean and sd you painstakingly measured.\n\n\nPlot the density of the jackalope height distribution. Indicate with a vertical line the height of the jackalope your friend measured.\n\n\nCalculate the probability of a jackalope being 75 cm or shorter.\n\n\nAre jackalope heights normally distributed?"
  },
  {
    "objectID": "problem-sets/ps-11.html#explore-coin-flip-distribution-characteristics",
    "href": "problem-sets/ps-11.html#explore-coin-flip-distribution-characteristics",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Explore coin flip distribution characteristics",
    "text": "Explore coin flip distribution characteristics\nWhen we flip a fair coin multiple times (numFlips) in a row, we expect to get heads (or tails) 50% of the time on average. This is not always the case for a single round of flipping, but if we do multiple rounds with (numRounds) that average should be 50%."
  },
  {
    "objectID": "problem-sets/ps-11.html#problem-2",
    "href": "problem-sets/ps-11.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Problem # 2",
    "text": "Problem # 2\nIn class, we simulated coin flip experiments using two different coins that were either fair (0.5 prob of head) or unfair (0.9 prob of head). We varied the number of flips in a single round (numFlips) and the number of rounds of flipping (numRounds). For this assignment, use the same to coins and use all possible combinations of numFlips and numRounds from the table below.\n\nparameters to explore\n\nnumFlips\nnumRounds\n\n\n\n5\n10\n\n\n500\n100\n\n\n\n\nCreate a tibble has all the combinations of numFlips, numRounds, and prob of getting heads.\n\n\n# hint for 8 flips and 12 rounds of a fair coin you could do\n# rbinom(n = 8, size = 12, prob = .5)/12\n\n\nPlot your result using faceting. I recommend faceting by numFlips (like in class describing both the number and fair v unfair) . Include the observed mean as a black diamond and the true mean as a dashed line.\n\n3. Report the means and sd of each pair of numFlips and numRounds\n4. Describe in a few sentences how increasing numFlips and numRounds alters:\nThe estimation of and spread around the true mean."
  },
  {
    "objectID": "problem-sets/ps-07.html",
    "href": "problem-sets/ps-07.html",
    "title": "R Bootcamp Problem Set 6",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-sets/ps-07.html#problem-set",
    "href": "problem-sets/ps-07.html#problem-set",
    "title": "R Bootcamp Problem Set 6",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-sets/ps-07.html#grading-rubric",
    "href": "problem-sets/ps-07.html#grading-rubric",
    "title": "R Bootcamp Problem Set 6",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-sets/ps-07.html#libraries",
    "href": "problem-sets/ps-07.html#libraries",
    "title": "R Bootcamp Problem Set 6",
    "section": "Libraries",
    "text": "Libraries\nLoad the libraries you need for analysis below."
  },
  {
    "objectID": "problem-sets/ps-07.html#question-1---5-points",
    "href": "problem-sets/ps-07.html#question-1---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 1 - 5 points\n",
    "text": "Question 1 - 5 points\n\nRun the following chunk:\n\nset.seed(42)\nx &lt;- sample(1000, replace = TRUE)\n\nNow use logical indexing to find the number of values &gt; 450 in x."
  },
  {
    "objectID": "problem-sets/ps-07.html#question-2---5-points",
    "href": "problem-sets/ps-07.html#question-2---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 2 - 5 points\n",
    "text": "Question 2 - 5 points\n\nCount the number of species in the penguins tibble using forcats::fct_count()\nCount number of island + sex combinations using dplyr::count(), and sort the result by count."
  },
  {
    "objectID": "problem-sets/ps-07.html#question-3---5-points",
    "href": "problem-sets/ps-07.html#question-3---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 3 - 5 points\n",
    "text": "Question 3 - 5 points\n\nUse stringr::str_c() to combine upper and lowercase letters from letters and LETTERS with a slash.\nYour answer should look like: \"A/a\" \"B/b\" \"C/c\" etc.\nUse stringr::str_split() or one of its variants to split up the strings you made above and extract the letter after the slash."
  },
  {
    "objectID": "problem-sets/ps-07.html#question-4---5-points",
    "href": "problem-sets/ps-07.html#question-4---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 4 - 5 points\n",
    "text": "Question 4 - 5 points\n\nCreate a ggplot using the diamonds data set.\n\nGenerate a ggridges::geom_density_ridges() for the prices, with a different fill color for each cut.\nRecolor the densities using ggplot2::scale_fill_brewer(), choosing a specific palette.\nmake the outline of the densities black, and change their alpha to 0.2.\nchange the theme to cowplot::theme_minimal_grid()\n\nremove the legend (google: “remove legend from ggplot2”)\nadd an informative title and subtitle using ggplot2::labs()."
  },
  {
    "objectID": "problem-sets/ps-07.html#submit",
    "href": "problem-sets/ps-07.html#submit",
    "title": "R Bootcamp Problem Set 6",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-04.html",
    "href": "problem-sets/ps-04.html",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-sets/ps-04.html#problem-set",
    "href": "problem-sets/ps-04.html#problem-set",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-sets/ps-04.html#grading-rubric",
    "href": "problem-sets/ps-04.html#grading-rubric",
    "title": "R Bootcamp Problem Set 4",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-sets/ps-04.html#question-1-2-points",
    "href": "problem-sets/ps-04.html#question-1-2-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 1 2 points\n",
    "text": "Question 1 2 points\n\n\nLoad the tidyverse and here packages.\n\nImport datasets: data/data_rna_protein.csv.gz.\n\ndata_rna_protein.csv.gz: This is a combined dataset from an RNAseq and SILAC proteomics experiment, where a transcription factor (TF) was differentially expressed and the fold change in RNA and protein calculated between TF-expressing and non-expressing cells."
  },
  {
    "objectID": "problem-sets/ps-04.html#question-2-9-points",
    "href": "problem-sets/ps-04.html#question-2-9-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 2 9 points\n",
    "text": "Question 2 9 points\n\nUsing the imported data set, carry out the following:\n\nInspect the data so you know what you are dealing with (summary() etc).\nSelect only the following columns: geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, and pval.\nRename them as follows: rna_FC = iDUX4_logFC, rna_pval = iDUX4_fdr, protein_FC = hl.ratio, protein_pval = pval (hint: use dplyr::rename())\nDrop all rows with NA values in them (hint: use a function from tidyr)\nRemove duplicate rows (hint: use dplyr::distinct()).\nArrange the table by descending rna_FC and ascending protein_FC.\nConduct steps 2-7 by piping the output of one step to another (i.e, a single workflow & remember to comment).\nSave the output of this workflow into a new object."
  },
  {
    "objectID": "problem-sets/ps-04.html#question-3-9-points",
    "href": "problem-sets/ps-04.html#question-3-9-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 3 9 points\n",
    "text": "Question 3 9 points\n\nHow well do the overall rna_FC and protein_FC values correlate in this experiment?\nUsing the output from Question 2, do the following:\n\nCreate a scatter plot of rna_FC vs protein_FC. observe how the points scatter.\nAdd a line to the plot that would indicate perfect 1:1 correlation. Hint: use geom_abline() with its slope argument.\nAdd a linear model fit using geom_smooth() using its method = 'lm' argument. Observe how the x=y line deviates from your geom_smooth line.\nCalculate the Spearman correlation coefficient. (Hint: This uses a base R math function called cor. Use ?cor or Google to learn more and how to specify method as spearman.\nUsing all of the information from above, comment on the correlation between rna_FC and protein_FC below.\n\nAnswer"
  },
  {
    "objectID": "problem-sets/ps-04.html#submit",
    "href": "problem-sets/ps-04.html#submit",
    "title": "R Bootcamp Problem Set 4",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-02.html",
    "href": "problem-sets/ps-02.html",
    "title": "R Bootcamp Problem Set 2",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-02.html#setup",
    "href": "problem-sets/ps-02.html#setup",
    "title": "R Bootcamp Problem Set 2",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-02.html#problem-set",
    "href": "problem-sets/ps-02.html#problem-set",
    "title": "R Bootcamp Problem Set 2",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Aug 30.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-1",
    "href": "problem-sets/ps-02.html#question-1",
    "title": "R Bootcamp Problem Set 2",
    "section": "Question 1",
    "text": "Question 1\nImport the data set data_transcript_exp_subset using the readr package, and assign it to a variable called exp_tbl.\nThe file is located at the following path data/data_transcript_exp_subset.csv.gz"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-2",
    "href": "problem-sets/ps-02.html#question-2",
    "title": "R Bootcamp Problem Set 2",
    "section": "Question 2",
    "text": "Question 2\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates.\nThe column names have the format of molecule_time_replicate\nFirst, explore the structure of the data set using some of the functions we learned in class (e.g., summary())\nComment on whether this data set is tidy, and if not, list the reasons why. Remember: in tidy data, every column represents a single variable and every row represents a single observation\nAnswer below"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-3",
    "href": "problem-sets/ps-02.html#question-3",
    "title": "R Bootcamp Problem Set 2",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nHint: Use pivot_longer()"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-4",
    "href": "problem-sets/ps-02.html#question-4",
    "title": "R Bootcamp Problem Set 2",
    "section": "Question 4",
    "text": "Question 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nHint: Use separate()"
  },
  {
    "objectID": "problem-sets/ps-02.html#question-5",
    "href": "problem-sets/ps-02.html#question-5",
    "title": "R Bootcamp Problem Set 2",
    "section": "Question 5",
    "text": "Question 5\nHow will you save your output as a TSV file?\nHint: Use the readr cheatsheet to figure this out.\nhttps://rstudio.cloud/learn/cheat-sheets"
  },
  {
    "objectID": "problem-set-keys/ps-key-21.html",
    "href": "problem-set-keys/ps-key-21.html",
    "title": "DNA Block - Problem Set 21",
    "section": "",
    "text": "In this problem set you’ll examine the binding sites of the Reb1 transcription factor by CUT&RUN.\nThe first several chunks just run, putting libraries and files in your environment\nEach question below is worth 4 points.\n\nStart by loading libraries you need analysis in the code chunk below.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(valr)\nlibrary(cowplot)\n\n# genome viz\nlibrary(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\nlibrary(Gviz)\nlibrary(rtracklayer)\n\n# motif discovery and viz\nlibrary(BSgenome.Scerevisiae.UCSC.sacCer3)\nlibrary(rGADEM)\nlibrary(seqLogo)\n\nNext, load the coverage tracks for CUT&RUN data.\n\ntrack_start &lt;- 1e5 \ntrack_end &lt;- 2e5 \n\n# genes track\nsgd_genes_trk &lt;-\n  GeneRegionTrack(\n    TxDb.Scerevisiae.UCSC.sacCer3.sgdGene,\n    chromosome = \"chrII\",\n    start = track_start,\n    end = track_end,\n    fill = \"#009E73\",\n    background.title = \"white\",\n    col.title = \"black\",\n    fontsize = 14\n  )\n\n# signal tracks\ntrack_info &lt;-\n  tibble(\n    file_name = c(\n      \"CutRun_Reb1_lt120.bw\",\n      \"CutRun_Abf1_lt120.bw\",\n      \"CutRun_Reb1_gt150.bw\",\n      \"CutRun_Abf1_gt150.bw\"\n    ),\n    sample_type = c(\n      \"Reb1_Short\", \"Abf1_Short\",\n      \"Reb1_Long\", \"Abf1_Long\"\n    )\n  ) |&gt;\n  mutate(\n    file_path = here(\"data/block-dna\", file_name),\n    big_wig = purrr::map(\n      file_path, ~ import.bw(.x, as = \"GRanges\")\n    ),\n    data_track = purrr::map2(\n      big_wig, sample_type,\n      ~ DataTrack(\n          .x,\n          name = .y,\n          background.title = \"white\",\n          col.title = \"black\",\n          col.axis = \"black\",\n          fontsize = 12\n      )\n    )\n  ) |&gt;\n  dplyr::select(sample_type, big_wig, data_track)\n\n# x-axis track\nx_axis_trk &lt;- GenomeAxisTrack(\n  col = \"black\",\n  col.axis = \"black\",\n  fontsize = 16\n)\n\nNow that we have tracks loaded, we can make a plot.\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\n\nHow do you interpret the differences in signals between the short and long fragments above? I.e., where are the short fragments enriched? And where do you see more of the long fragments?\n\nShort fragments generated from MNase digestion of transcription factor complexes are enriched in paromoter regions. Gene bodies contain more longer fragments, where nucleosomes are present and yield longer digestion products.\n\n\nRemake the plot above, but zoom in to a promoter region that has strong enrichment for both Reb1 and Abf1 (short fragments).\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = 160000,\n  to = 170000,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\nDo the signals for Reb1 and Abf1 line up with one another? Why is this the case?\n\nIn this region, the major peaks of Reb1 and Abf1 are near but do not overlap, consistent with these factors requiring specific DNA sequences for binding.\n\n\nNext we’ll take a look at Reb1 CUT&RUN data. In the following chunk, use the approach we took in class to identify enriched sites of Reb1 binding.\n\nreb1_tbl &lt;- read_bigwig(here(\"data/block-dna/CutRun_Reb1_lt120.bw\"))\n\n# number of reads in the original Reb1 BED file\ntotal_reads &lt;- 16e6\n\ngenome &lt;- read_genome(here(\"data/block-dna/sacCer3.chrom.sizes\"))\n\n# how can we calculate genome size?\ngenome_size &lt;- sum(genome$size)\n\n# defind the genome-wide lambda value here\ngenome_lambda &lt;- total_reads / genome_size\n\npeak_calls &lt;-\n  reb1_tbl |&gt;\n  # define single-base sites\n  mutate(\n    midpoint = start + round((end - start) / 2),\n    start = midpoint,\n    end = start + 1,\n    # use the poisson to calculate a p-value with the genome-wide lambda\n    pval = dpois(score, genome_lambda),\n    # convert p-values to FDR\n    fdr = p.adjust(pval, method = \"fdr\")\n  )\n\nLet’s take a look at a plot of the p-value across a chromosome.\nUse geom_hline() to draw a red horizontal line at a cutoff that selects ~10 regions enriched for Reb1 binding. You’ll use this cutoff in the code chunks below.\n\nggplot(\n  filter(peak_calls, chrom == \"chrII\"),\n  # convert p-values to positive values for plotting\n  aes(start, -log10(pval))\n) + \n  geom_line() +\n  xlim(track_start, track_end) +\n  theme_cowplot() +\n  geom_hline(yintercept = 20, color = 'red')\n\nWarning: Removed 55930 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\nHow many peaks are called in this region? Use the cutoff you defined above to identify “peaks” of Reb1 binding.\n\npeak_calls |&gt; \n  filter(-log10(pval) &gt;= 20) |&gt;\n  filter(start &gt;= track_start & end &lt;= track_end) |&gt;\n  bed_merge(max_dist = 20) |&gt;\n  nrow()\n\n[1] 261\n\n\nHow many total peaks are identified in the genome using this cutoff?\n\npeak_calls |&gt; \n  filter(-log10(pval) &gt;= 20) |&gt;\n  bed_merge(max_dist = 20) |&gt;\n  nrow()\n\n[1] 2568\n\n\n\n# most stringent cut-off\npeak_calls_sig &lt;- \n  filter(\n    peak_calls,\n    -log10(pval) &gt;= 20, \n    ) |&gt;\n    # collapse neighboring, significant sites\n    bed_merge(max_dist = 20)\n\nfilter(\n  peak_calls_sig,\n  chrom == \"chrII\" &\n    start &gt;= track_start &\n    end &lt;= track_end\n)\n\n# A tibble: 28 x 3\n   chrom  start    end\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;\n 1 chrII 111281 111371\n 2 chrII 116933 117055\n 3 chrII 122242 122335\n 4 chrII 124885 125083\n 5 chrII 132274 132369\n 6 chrII 135587 135638\n 7 chrII 135696 136060\n 8 chrII 137335 137424\n 9 chrII 139151 139182\n10 chrII 142981 143030\n# i 18 more rows\n\n\nLet’s visualize these peaks in the context of genomic CUT&RUN signal. We need to define an AnnotationTrack with the peak intervals, which we can plot against the CUT&RUN coverage we defined above.\n\n# need a GRanges object to convert to an AnnotationTrack\npeak_calls_gr &lt;-\n  GRanges(\n    seqnames = peak_calls_sig$chrom,\n    ranges = IRanges(peak_calls_sig$start, peak_calls_sig$end)\n  )\n\npeak_calls_trk &lt;-\n  AnnotationTrack(\n    peak_calls_gr,\n    name = \"Peak calls\",\n    fill = \"red\",\n    background.title = \"white\",\n    col.title = \"red\",\n    fontsize = 16,\n    rotation.title = 0\n  )\n\nreb1_short_trk &lt;-\n  filter(\n    track_info,\n    sample_type == \"Reb1_Short\"\n  ) |&gt;\n  pull(data_track)\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    reb1_short_trk,\n    peak_calls_trk,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\n\nUse the peak calls you defined to identify a putative sequence motif bound by Reb1. You can assume that the most abundant motif identified is the most likely candidate.\nUse Google and Pubmed to identify a study that defines a Reb1 motif using a genomewide analysis. How well does your motif match the previously defined one?\n\nThe identified Reb1 motif is a good match to several studies including PMID 19305407 and 28079019.\n\n\npeak_seqs &lt;- BSgenome::getSeq(\n  # provided by BSgenome.Scerevisiae.UCSC.sacCer3\n  Scerevisiae,\n  peak_calls_gr\n)\n\n# takes ~2 minutes to run\ngadem &lt;- rGADEM::GADEM(\n  peak_seqs,\n  genome = Scerevisiae,\n  verbose = 1\n)\n\n\n# look at the consensus motifs\nconsensus(gadem)\n\n[1] \"nmGGGTAAy\"                \"nTTTTTTTTTTTn\"            \"nCGGGrnCCssvmAsGrGn\"      \"mmmmmmmmmmCCACACCCACACmC\" \"nTwwwTwwTwAhTwwTTATw\"     \"nAmwAAwAhTAmATmAAAAn\"     \"yTywCymTACAACwnTTyn\"\n\n# how many consensus motifs are there?\nnOccurrences(gadem)\n\n[1] 1438  541  290  315  234  201  240\nNow let’s look at the sequence logo for the top hit.\n\npwm &lt;- gadem@motifList[[1]]@pwm\n\nseqLogo::seqLogo(pwm)"
  },
  {
    "objectID": "problem-set-keys/ps-key-21.html#problem-set",
    "href": "problem-set-keys/ps-key-21.html#problem-set",
    "title": "DNA Block - Problem Set 21",
    "section": "",
    "text": "In this problem set you’ll examine the binding sites of the Reb1 transcription factor by CUT&RUN.\nThe first several chunks just run, putting libraries and files in your environment\nEach question below is worth 4 points.\n\nStart by loading libraries you need analysis in the code chunk below.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(valr)\nlibrary(cowplot)\n\n# genome viz\nlibrary(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\nlibrary(Gviz)\nlibrary(rtracklayer)\n\n# motif discovery and viz\nlibrary(BSgenome.Scerevisiae.UCSC.sacCer3)\nlibrary(rGADEM)\nlibrary(seqLogo)\n\nNext, load the coverage tracks for CUT&RUN data.\n\ntrack_start &lt;- 1e5 \ntrack_end &lt;- 2e5 \n\n# genes track\nsgd_genes_trk &lt;-\n  GeneRegionTrack(\n    TxDb.Scerevisiae.UCSC.sacCer3.sgdGene,\n    chromosome = \"chrII\",\n    start = track_start,\n    end = track_end,\n    fill = \"#009E73\",\n    background.title = \"white\",\n    col.title = \"black\",\n    fontsize = 14\n  )\n\n# signal tracks\ntrack_info &lt;-\n  tibble(\n    file_name = c(\n      \"CutRun_Reb1_lt120.bw\",\n      \"CutRun_Abf1_lt120.bw\",\n      \"CutRun_Reb1_gt150.bw\",\n      \"CutRun_Abf1_gt150.bw\"\n    ),\n    sample_type = c(\n      \"Reb1_Short\", \"Abf1_Short\",\n      \"Reb1_Long\", \"Abf1_Long\"\n    )\n  ) |&gt;\n  mutate(\n    file_path = here(\"data/block-dna\", file_name),\n    big_wig = purrr::map(\n      file_path, ~ import.bw(.x, as = \"GRanges\")\n    ),\n    data_track = purrr::map2(\n      big_wig, sample_type,\n      ~ DataTrack(\n          .x,\n          name = .y,\n          background.title = \"white\",\n          col.title = \"black\",\n          col.axis = \"black\",\n          fontsize = 12\n      )\n    )\n  ) |&gt;\n  dplyr::select(sample_type, big_wig, data_track)\n\n# x-axis track\nx_axis_trk &lt;- GenomeAxisTrack(\n  col = \"black\",\n  col.axis = \"black\",\n  fontsize = 16\n)\n\nNow that we have tracks loaded, we can make a plot.\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\n\nHow do you interpret the differences in signals between the short and long fragments above? I.e., where are the short fragments enriched? And where do you see more of the long fragments?\n\nShort fragments generated from MNase digestion of transcription factor complexes are enriched in paromoter regions. Gene bodies contain more longer fragments, where nucleosomes are present and yield longer digestion products.\n\n\nRemake the plot above, but zoom in to a promoter region that has strong enrichment for both Reb1 and Abf1 (short fragments).\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = 160000,\n  to = 170000,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\nDo the signals for Reb1 and Abf1 line up with one another? Why is this the case?\n\nIn this region, the major peaks of Reb1 and Abf1 are near but do not overlap, consistent with these factors requiring specific DNA sequences for binding.\n\n\nNext we’ll take a look at Reb1 CUT&RUN data. In the following chunk, use the approach we took in class to identify enriched sites of Reb1 binding.\n\nreb1_tbl &lt;- read_bigwig(here(\"data/block-dna/CutRun_Reb1_lt120.bw\"))\n\n# number of reads in the original Reb1 BED file\ntotal_reads &lt;- 16e6\n\ngenome &lt;- read_genome(here(\"data/block-dna/sacCer3.chrom.sizes\"))\n\n# how can we calculate genome size?\ngenome_size &lt;- sum(genome$size)\n\n# defind the genome-wide lambda value here\ngenome_lambda &lt;- total_reads / genome_size\n\npeak_calls &lt;-\n  reb1_tbl |&gt;\n  # define single-base sites\n  mutate(\n    midpoint = start + round((end - start) / 2),\n    start = midpoint,\n    end = start + 1,\n    # use the poisson to calculate a p-value with the genome-wide lambda\n    pval = dpois(score, genome_lambda),\n    # convert p-values to FDR\n    fdr = p.adjust(pval, method = \"fdr\")\n  )\n\nLet’s take a look at a plot of the p-value across a chromosome.\nUse geom_hline() to draw a red horizontal line at a cutoff that selects ~10 regions enriched for Reb1 binding. You’ll use this cutoff in the code chunks below.\n\nggplot(\n  filter(peak_calls, chrom == \"chrII\"),\n  # convert p-values to positive values for plotting\n  aes(start, -log10(pval))\n) + \n  geom_line() +\n  xlim(track_start, track_end) +\n  theme_cowplot() +\n  geom_hline(yintercept = 20, color = 'red')\n\nWarning: Removed 55930 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\nHow many peaks are called in this region? Use the cutoff you defined above to identify “peaks” of Reb1 binding.\n\npeak_calls |&gt; \n  filter(-log10(pval) &gt;= 20) |&gt;\n  filter(start &gt;= track_start & end &lt;= track_end) |&gt;\n  bed_merge(max_dist = 20) |&gt;\n  nrow()\n\n[1] 261\n\n\nHow many total peaks are identified in the genome using this cutoff?\n\npeak_calls |&gt; \n  filter(-log10(pval) &gt;= 20) |&gt;\n  bed_merge(max_dist = 20) |&gt;\n  nrow()\n\n[1] 2568\n\n\n\n# most stringent cut-off\npeak_calls_sig &lt;- \n  filter(\n    peak_calls,\n    -log10(pval) &gt;= 20, \n    ) |&gt;\n    # collapse neighboring, significant sites\n    bed_merge(max_dist = 20)\n\nfilter(\n  peak_calls_sig,\n  chrom == \"chrII\" &\n    start &gt;= track_start &\n    end &lt;= track_end\n)\n\n# A tibble: 28 x 3\n   chrom  start    end\n   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;\n 1 chrII 111281 111371\n 2 chrII 116933 117055\n 3 chrII 122242 122335\n 4 chrII 124885 125083\n 5 chrII 132274 132369\n 6 chrII 135587 135638\n 7 chrII 135696 136060\n 8 chrII 137335 137424\n 9 chrII 139151 139182\n10 chrII 142981 143030\n# i 18 more rows\n\n\nLet’s visualize these peaks in the context of genomic CUT&RUN signal. We need to define an AnnotationTrack with the peak intervals, which we can plot against the CUT&RUN coverage we defined above.\n\n# need a GRanges object to convert to an AnnotationTrack\npeak_calls_gr &lt;-\n  GRanges(\n    seqnames = peak_calls_sig$chrom,\n    ranges = IRanges(peak_calls_sig$start, peak_calls_sig$end)\n  )\n\npeak_calls_trk &lt;-\n  AnnotationTrack(\n    peak_calls_gr,\n    name = \"Peak calls\",\n    fill = \"red\",\n    background.title = \"white\",\n    col.title = \"red\",\n    fontsize = 16,\n    rotation.title = 0\n  )\n\nreb1_short_trk &lt;-\n  filter(\n    track_info,\n    sample_type == \"Reb1_Short\"\n  ) |&gt;\n  pull(data_track)\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    reb1_short_trk,\n    peak_calls_trk,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\n\nUse the peak calls you defined to identify a putative sequence motif bound by Reb1. You can assume that the most abundant motif identified is the most likely candidate.\nUse Google and Pubmed to identify a study that defines a Reb1 motif using a genomewide analysis. How well does your motif match the previously defined one?\n\nThe identified Reb1 motif is a good match to several studies including PMID 19305407 and 28079019.\n\n\npeak_seqs &lt;- BSgenome::getSeq(\n  # provided by BSgenome.Scerevisiae.UCSC.sacCer3\n  Scerevisiae,\n  peak_calls_gr\n)\n\n# takes ~2 minutes to run\ngadem &lt;- rGADEM::GADEM(\n  peak_seqs,\n  genome = Scerevisiae,\n  verbose = 1\n)\n\n\n# look at the consensus motifs\nconsensus(gadem)\n\n[1] \"nmGGGTAAy\"                \"nTTTTTTTTTTTn\"            \"nCGGGrnCCssvmAsGrGn\"      \"mmmmmmmmmmCCACACCCACACmC\" \"nTwwwTwwTwAhTwwTTATw\"     \"nAmwAAwAhTAmATmAAAAn\"     \"yTywCymTACAACwnTTyn\"\n\n# how many consensus motifs are there?\nnOccurrences(gadem)\n\n[1] 1438  541  290  315  234  201  240\nNow let’s look at the sequence logo for the top hit.\n\npwm &lt;- gadem@motifList[[1]]@pwm\n\nseqLogo::seqLogo(pwm)"
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html",
    "href": "problem-set-keys/ps-key-16.html",
    "title": "DNA Block - Problem Set 16",
    "section": "",
    "text": "You have two tasks for this problem set.\n\nRead the two papers in the preparation document before class on Wed.\nLook over the vignettes for the software in the preparation document. Use valr to complete the tasks below. These problems are due Wed at 5pm.\n\nEach problem below is worth 15 points."
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html#problem-set",
    "href": "problem-set-keys/ps-key-16.html#problem-set",
    "title": "DNA Block - Problem Set 16",
    "section": "",
    "text": "You have two tasks for this problem set.\n\nRead the two papers in the preparation document before class on Wed.\nLook over the vignettes for the software in the preparation document. Use valr to complete the tasks below. These problems are due Wed at 5pm.\n\nEach problem below is worth 15 points."
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html#setup",
    "href": "problem-set-keys/ps-key-16.html#setup",
    "title": "DNA Block - Problem Set 16",
    "section": "Setup",
    "text": "Setup\nLoad libraries you’ll need for analysis below.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(valr)"
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html#question-1-5-points",
    "href": "problem-set-keys/ps-key-16.html#question-1-5-points",
    "title": "DNA Block - Problem Set 16",
    "section": "Question 1 – 5 points",
    "text": "Question 1 – 5 points\nWe’ll work with a few different files for the next questions.\n\n\nhg19.refGene.chr22.bed.gz is a BED12 file containing gene (mRNA) information for chr22.\n\nhg19.rmsk.chr22.bed.gz is a BED6 containing repetitive elements in the human genome.\n\nhg19.dnase1.bw is a bigWig file containing DNaseI signal.\n\nYou can find the path to each with valr_example(). Load each one invdividually using the read_* functions.\n\ngene_tbl &lt;- read_bed(valr_example(\"hg19.refGene.chr22.bed.gz\"))\nrmsk_tbl &lt;- read_bed(valr_example(\"hg19.rmsk.chr22.bed.gz\"))\ndnase_tbl &lt;- read_bigwig(valr_example(\"hg19.dnase1.bw\"))\n\nSome valr functions require a “genome” file, which is just a tibble of chromosome names and sizes.\nThe hg19 genome file is available at valr_example(\"hg19.chrom.sizes.gz\"). Use read_genome() to load it.\nInspect the tibble. How many columns does it have? What is the largest chromosome?\n\ngenome &lt;- read_genome(valr_example(\"hg19.chrom.sizes.gz\"))\n\nncol(genome)\n\n[1] 2\n\narrange(genome, desc(size)) |&gt; head(1)\n\n# A tibble: 1 x 2\n  chrom      size\n  &lt;chr&gt;     &lt;dbl&gt;\n1 chr1  249250621"
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html#question-2-5-points",
    "href": "problem-set-keys/ps-key-16.html#question-2-5-points",
    "title": "DNA Block - Problem Set 16",
    "section": "Question 2 – 5 points",
    "text": "Question 2 – 5 points\nWhich repeat class covers the largest amount of chromosome 22?\n\n# N.B.: the following doesn't collapse intervals within repeat classes, but it's a\n# decent approximation.\nrmsk_tbl |&gt;\n  mutate(int_size = end - start) |&gt;\n  group_by(name) |&gt;\n  summarize(total_size = sum(int_size)) |&gt;\n  arrange(desc(total_size))\n\n# A tibble: 1,053 x 2\n   name      total_size\n   &lt;chr&gt;          &lt;int&gt;\n 1 ALR/Alpha     110767\n 2 AluSx1        103112\n 3 AluY           94814\n 4 AluSx          88923\n 5 MIRb           83177\n 6 L2a            73070\n 7 AluSz          72584\n 8 AluJb          67103\n 9 AluSq2         61591\n10 AluJr          49571\n# i 1,043 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html#question-3",
    "href": "problem-set-keys/ps-key-16.html#question-3",
    "title": "DNA Block - Problem Set 16",
    "section": "Question 3",
    "text": "Question 3\nWhich promoter has the highest DNase I accessibility?\n\nUse the create_tss() function to generate transcription start sites from the refGene annotations. How be are these intervals?\nGenerate some promoter regions with bed_slop(), adding 500 bp up- and downstream of the TSS. bed_slop() requires the genome file above.\nUse bed_map() to calculate the total (i.e., summed) DNase I signal in the promoters (the score column in the DNase file).\n\nWhich gene has the highest DNase I in the region you defined above?\n\ntss_tbl &lt;- create_tss(gene_tbl)\npromoter_tbl &lt;- bed_slop(tss_tbl, genome, both = 500)\n\nbed_map(\n  promoter_tbl,\n  dnase_tbl,\n  score_sum = sum(score)\n) |&gt;\n  arrange(desc(score_sum)) |&gt;\n  head(1)\n\n# A tibble: 1 x 7\n  chrom    start      end name      score strand score_sum\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 chr22 17082300 17083301 NR_001591 0     +            863"
  },
  {
    "objectID": "problem-set-keys/ps-key-16.html#submit",
    "href": "problem-set-keys/ps-key-16.html#submit",
    "title": "DNA Block - Problem Set 16",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html",
    "href": "problem-set-keys/ps-key-14.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:ggpubr':\n\n    get_legend\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#problem-1",
    "href": "problem-set-keys/ps-key-14.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nCan mouse sex explain mouse cholesterol? {.smaller}"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#step-1-null-hypothesis-and-variable-specification",
    "href": "problem-set-keys/ps-key-14.html#step-1-null-hypothesis-and-variable-specification",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 1: Null hypothesis and variable specification",
    "text": "STEP 1: Null hypothesis and variable specification\n\\(\\mathcal{H}_0:\\) mouse \\(sex\\) does NOT explain \\(cholesterol\\)\n\n\\(cholesterol\\) is the response variable\n\n\n\\(sex\\) is the explanatory variable"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#step-2-fit-linear-model-and-examine-results",
    "href": "problem-set-keys/ps-key-14.html#step-2-fit-linear-model-and-examine-results",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_cs &lt;- lm(formula = tot_cholesterol ~ 1 + sex, data = b)\n\nFit summary:\n\nglance(fit_cs) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\n\n\n\n\n\nr.squared\n      adj.r.squared\n      sigma\n      statistic\n      p.value\n      df\n      logLik\n      AIC\n      BIC\n      deviance\n      df.residual\n      nobs\n    \n\n0.184\n0.183\n0.576\n400.774\n1.425116e-80\n1\n-1546.04\n3098.081\n3114.537\n591.5753\n1780\n1782\n\n\n\n\n\nCoefficient summary:\n\ntidy(fit_cs) |&gt;\n  gt() |&gt;\n  fmt_number(columns = estimate:statistic, decimals = 3)\n\n\n\n\n\n\nterm\n      estimate\n      std.error\n      statistic\n      p.value\n    \n\n\n(Intercept)\n2.797\n0.019\n144.812\n0.000000e+00\n\n\nsexM\n0.547\n0.027\n20.019\n1.425116e-80"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#collecting-residuals-and-other-information",
    "href": "problem-set-keys/ps-key-14.html#collecting-residuals-and-other-information",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\n# augment\nb_cs &lt;- augment(fit_cs, data = b)\n\n\navg_c &lt;- mean(b_cs$tot_cholesterol)\n\nc &lt;- b |&gt;\n  group_by(sex) |&gt;\n  get_summary_stats(tot_cholesterol, type = \"mean\")\n\n\n# mean chol female\navg_cf &lt;- pull(c[1, 4])\n\n\n# mean chol male\navg_cm &lt;- pull(c[2, 4])"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#step-4-visualize-the-error-around-fit",
    "href": "problem-set-keys/ps-key-14.html#step-4-visualize-the-error-around-fit",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 4: Visualize the error around fit",
    "text": "STEP 4: Visualize the error around fit\n\n# plot of data with mean and colored by residuals\np_cs &lt;- ggplot(\n  b_cs,\n  aes(x = sex, y = tot_cholesterol)\n) +\n  geom_point(\n    position = position_jitter(),\n    aes(color = .resid)\n  ) +\n  scale_color_gradient2(\n    low = \"blue\",\n    mid = \"black\",\n    high = \"yellow\"\n  ) +\n  geom_hline(\n    yintercept = avg_c,\n    color = \"darkgrey\"\n  ) +\n  geom_segment(\n    aes(\n      x = .5, xend = 1.5,\n      y = avg_cf, yend = avg_cf\n    ),\n    color = \"red\"\n  ) +\n  geom_segment(\n    aes(\n      x = 1.5, xend = 2.5,\n      y = avg_cm\n    ),\n    yend = avg_cm,\n    color = \"red\"\n  ) +\n  theme_cowplot()\n\np_cs"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "href": "problem-set-keys/ps-key-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 3: Visualize the error around the null (mean weight)",
    "text": "STEP 3: Visualize the error around the null (mean weight)\n\np_c &lt;- ggplot(\n  b_cs,\n  aes(x = sex, y = tot_cholesterol)\n) +\n  geom_point(\n    position = position_jitter(),\n    aes(color = tot_cholesterol - avg_c)\n  ) +\n  scale_color_gradient2(\n    low = \"blue\",\n    mid = \"black\",\n    high = \"yellow\"\n  ) +\n  geom_hline(\n    yintercept = avg_c,\n    color = \"darkgrey\"\n  ) +\n  theme_cowplot()\n\np_c"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#plot-the-fit-error-and-the-null-error-as-2-panels",
    "href": "problem-set-keys/ps-key-14.html#plot-the-fit-error-and-the-null-error-as-2-panels",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Plot the fit error and the null error as 2 panels",
    "text": "Plot the fit error and the null error as 2 panels\n\nplot_grid(p_cs, p_c, ncol = 2, labels = c(\"cholesterol by sex\", \"cholesterol\"))"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#calculate-r2",
    "href": "problem-set-keys/ps-key-14.html#calculate-r2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\nss_fit &lt;- sum(b_cs$.resid^2)\n\nss_null &lt;- sum(\n  (b_cs$tot_cholesterol - avg_c)^2\n)\n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\nrsq &lt;- 1 - ss_fit / ss_null\nrsq\n\n[1] 0.1837759\n\n\ncheck agains Rsq in your fit\n\nglance(fit_cs) |&gt; select(r.squared)\n\n# A tibble: 1 x 1\n  r.squared\n      &lt;dbl&gt;\n1     0.184"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#compare-to-traditional-t-test",
    "href": "problem-set-keys/ps-key-14.html#compare-to-traditional-t-test",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Compare to traditional t-test",
    "text": "Compare to traditional t-test\n\n# run analagous t-test\nb |&gt;\n  t_test(tot_cholesterol ~ 1 + sex) |&gt;\n  select(-c(n1, n2, df)) |&gt;\n  gt()\n\n\n\n\n\n\n.y.\n      group1\n      group2\n      statistic\n      p\n    \n\ntot_cholesterol\nF\nM\n-20.01933\n1.46e-80\n\n\n\n\n\n\ntidy(fit_cs) |&gt;\n  select(term, estimate, statistic, p.value) |&gt;\n  gt()\n\n\n\n\n\n\nterm\n      estimate\n      statistic\n      p.value\n    \n\n\n(Intercept)\n2.7968013\n144.81230\n0.000000e+00\n\n\nsexM\n0.5467901\n20.01933\n1.425116e-80"
  },
  {
    "objectID": "problem-set-keys/ps-key-14.html#provide-your-interpreation-of-the-result",
    "href": "problem-set-keys/ps-key-14.html#provide-your-interpreation-of-the-result",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Provide your interpreation of the result",
    "text": "Provide your interpreation of the result\nThe null model that mouse \\(sex\\) does NOT explain \\(cholesterol\\) is not well supported. Therefore, i believe that mouse \\(sex\\) is able to explain ~%18 of the variation in \\(cholesterol\\)."
  },
  {
    "objectID": "problem-set-keys/ps-key-12.html",
    "href": "problem-set-keys/ps-key-12.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-set-keys/ps-key-12.html#problem-1",
    "href": "problem-set-keys/ps-key-12.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nDoes mouse sex explain mouse total cholesterol levels? Make sure to run chunks above.\n1. Examine and specify the variable(s)\n\nThe response variable y is \\(tot\\_cholesterol\\)\nThe explantory variable x is \\(sex\\)\n\nMake a plot:\nresponse variable on the y-axis\nexplanatory variable on the x-axis\n\nggviolin(\n  data = b,\n  y = \"tot_cholesterol\",\n  x = \"sex\",\n  fill = \"sex\",\n  add = \"mean_sd\"\n)\n\n\n\n\nGet n, mean, median, sd\n\nb |&gt;\n  group_by(sex) |&gt;\n  get_summary_stats(tot_cholesterol,\n    type = \"common\",\n    show = c(\"mean\", \"median\", \"sd\")\n  )\n\n# A tibble: 2 x 6\n  sex   variable            n  mean median    sd\n  &lt;chr&gt; &lt;fct&gt;           &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 F     tot_cholesterol   891  2.80   2.75 0.566\n2 M     tot_cholesterol   891  3.34   3.3  0.587\n\n\nIs it normally distribute?\n\nggqqplot(\n  data = b,\n  x = \"tot_cholesterol\",\n  color = \"sex\"\n)\n\n\n\nb |&gt;\n  group_by(sex) |&gt;\n  shapiro_test(tot_cholesterol) |&gt;\n  gt()\n\n\n\n\n\n\nsex\n      variable\n      statistic\n      p\n    \n\n\nF\ntot_cholesterol\n0.9913284\n4.268190e-05\n\n\nM\ntot_cholesterol\n0.9868903\n3.759361e-07\n\n\n\n\n\n\n\nYes, based on the qq-plot and the high \\(n\\), but i do understand if you want to play it safe due to the shapiro_test p-value.\n\nIs it variance similar between groups?\n\nb |&gt;\n  levene_test(tot_cholesterol ~ sex) |&gt;\n  gt()\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\n\n\n\n\n\ndf1\n      df2\n      statistic\n      p\n    \n\n1\n1780\n0.6460877\n0.4216222\n\n\n\n\n\n\nYes\n\nWhat kind of test are you picking and why?\n\nt_test since i think it is normally distribute, with equal variance based on levene test\n\n2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that \\(sex\\) does not explain \\(tot\\_cholesterol\\)\n3. Calculate test-statistic, exact p-value and plot\n\nb |&gt;\n  t_test(tot_cholesterol ~ sex,\n    var.equal = T,\n    ref.group = \"F\"\n  ) |&gt;\n  gt()\n\n\n\n\n\n\n.y.\n      group1\n      group2\n      n1\n      n2\n      statistic\n      df\n      p\n    \n\ntot_cholesterol\nF\nM\n891\n891\n-20.01933\n1780\n1.43e-80\n\n\n\n\nstatres &lt;- b |&gt;\n  t_test(tot_cholesterol ~ sex,\n    var.equal = T,\n    ref.group = \"F\"\n  )\n\n\nggviolin(\n  data = b,\n  y = \"tot_cholesterol\",\n  x = \"sex\",\n  fill = \"sex\",\n  add = \"mean_sd\"\n) +\n  stat_pvalue_manual(\n    statres,\n    label = \"p\",\n    y.position = 5.8\n  ) +\n  ylim(1, 6)\n\nWarning: Removed 1 rows containing missing values (`geom_violin()`).\n\n\n\n\n\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\n  \"B1.5:E1.4(4) B1.5:A1.4(5)\",\n  \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n  \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n  \"D5.4:G2.3(4) D5.4:C4.3(4)\"\n)\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels()\n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref = \"B1\")"
  },
  {
    "objectID": "problem-set-keys/ps-key-12.html#problem-2",
    "href": "problem-set-keys/ps-key-12.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 2",
    "text": "Problem # 2\nDoes mouse family explain mouse total cholesterol levels? Make sure to run chunk above.\n1. Examine and specify the variable(s)\n\nThe response variable y is \\(tot\\_cholesterol\\)\nThe explantory variable x is \\(family\\)\n\nMake a plot:\nresponse variable on the y-axis\nexplanatory variable on the x-axis\n\nggviolin(\n  data = bfam,\n  y = \"tot_cholesterol\",\n  x = \"family\",\n  fill = \"family\",\n  add = \"mean_sd\"\n)\n\n\n\n\nGet n, mean, median, sd\n\nbfam |&gt;\n  group_by(family) |&gt;\n  get_summary_stats(tot_cholesterol,\n    type = \"common\",\n    show = c(\"mean\", \"median\", \"sd\")\n  )\n\n# A tibble: 4 x 6\n  family variable            n  mean median    sd\n  &lt;fct&gt;  &lt;fct&gt;           &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 B1     tot_cholesterol    11  2.68   2.6  0.555\n2 A1     tot_cholesterol    12  3.51   3.41 0.722\n3 D5     tot_cholesterol    20  3.58   3.58 0.617\n4 F1     tot_cholesterol    11  3.28   3.43 0.579\n\n\nIs it normally distribute?\n\nggqqplot(\n  data = bfam,\n  x = \"tot_cholesterol\",\n  color = \"family\"\n)\n\n\n\nbfam |&gt;\n  group_by(family) |&gt;\n  shapiro_test(tot_cholesterol) |&gt;\n  gt()\n\n\n\n\n\n\nfamily\n      variable\n      statistic\n      p\n    \n\n\nB1\ntot_cholesterol\n0.8864050\n0.1253641\n\n\nA1\ntot_cholesterol\n0.9304722\n0.3851437\n\n\nD5\ntot_cholesterol\n0.9470242\n0.3241655\n\n\nF1\ntot_cholesterol\n0.9173114\n0.2968795\n\n\n\n\n\n\n\nYes\n\nIs it variance similar between groups?\n\nb |&gt;\n  levene_test(tot_cholesterol ~ family) |&gt;\n  gt()\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\n\n\n\n\n\ndf1\n      df2\n      statistic\n      p\n    \n\n170\n1611\n1.139081\n0.1165763\n\n\n\n\n\n\nYes\n\nWhat kind of test are you picking and why?\n\nanova_test since i think it is normally distribute and has equal variance\n\n2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that \\(family\\) does not explain \\(tot\\_cholesterol\\)\n3. Calculate test-statistic, exact p-value and plot\n\nbfam |&gt;\n  anova_test(tot_cholesterol ~ family) |&gt;\n  gt()\n\n\n\n\n\n\nEffect\n      DFn\n      DFd\n      F\n      p\n      p&lt;.05\n      ges\n    \n\nfamily\n3\n50\n5.401\n0.003\n*\n0.245\n\n\n\n\nggviolin(\n  data = bfam,\n  y = \"tot_cholesterol\",\n  x = \"family\",\n  fill = \"family\",\n  add = \"mean_sd\"\n) +\n  stat_anova_test()"
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html",
    "href": "problem-set-keys/ps-key-09.html",
    "title": "R Bootcamp Problem Set 9",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 11."
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#problem-set",
    "href": "problem-set-keys/ps-key-09.html#problem-set",
    "title": "R Bootcamp Problem Set 9",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 11."
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#libraries",
    "href": "problem-set-keys/ps-key-09.html#libraries",
    "title": "R Bootcamp Problem Set 9",
    "section": "Libraries",
    "text": "Libraries\nLoad the libraries you need for analysis below.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\n\nLoad the data\nLoad the data sets and inspect.\n\nqpcr_names &lt;- read_tsv(here(\"data/qpcr_names_ps.tsv.gz\"))\n\nRows: 18 Columns: 19\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr (19): row, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nqpcr_data &lt;- read_tsv(here(\"data/qpcr_data_ps.tsv.gz\"))\n\nRows: 18 Columns: 19\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr  (1): row\ndbl (18): 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTidy the data\nGiven the experimental setup and the shape of the tibbles, you should be able to answer: Are these data tidy?\n\nWhat are the variables in the data?\n\n\ngenotype, time, gene, biological replicate, technical replicate\n\n\nAre the variables the column names?\n\n\nNope.\n\nThe names are encoded in the following order:\ngt, time, gene, rep_tech, rep_bio.\n\nqpcr_names_long &lt;-\n  pivot_longer(qpcr_names, -row, names_to = \"col\") |&gt;\n  separate(\n    value,\n    into = c(\"gt\", \"time\", \"gene\", \"rep_tech\", \"rep_bio\"),\n    sep = \"_\",\n    convert = TRUE\n  )\nqpcr_data_long &lt;-\n  pivot_longer(qpcr_data, -row, names_to = \"col\", values_to = \"exp\")\n\nqpcr_tidy &lt;-\n  left_join(qpcr_names_long, qpcr_data_long) |&gt;\n  select(-row, -col)\n\nJoining with `by = join_by(row, col)`"
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#question-1",
    "href": "problem-set-keys/ps-key-09.html#question-1",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 1",
    "text": "Question 1\nCalculate summary statistics for the experiment.\n\nCalculate the mean of the technical replicates within each group of genotype, time, gene, and biological replicate.\nCalculate the mean and standard deviation of the biolgical replicates (which is the mean of technical replicates, above).\n\nYou should have a tibble that looks like this:\n# A tibble: 36 &lt;c3&gt;&lt;97&gt; 5\n   gt         time gene     bio_mean bio_sd\n   &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 RL-mutant     0 GAPDH       0.456  0.133\n 2 RL-mutant     0 IFN-beta    3.54   0.203\n 3 RL-mutant     4 GAPDH       1.65   0.432\n 4 RL-mutant     4 IFN-beta   17.0    2.22 \n 5 RL-mutant     8 GAPDH       2.09   1.17 \n 6 RL-mutant     8 IFN-beta   31.8    3.29 \n 7 RL-mutant    12 GAPDH       4.90   1.38 \n 8 RL-mutant    12 IFN-beta   45.8    3.61 \n 9 RL-mutant    24 GAPDH       8.50   2.49 \n10 RL-mutant    24 IFN-beta   78.1    5.80 \n# &lt;e2&gt;&lt;84&gt;&lt;b9&gt; 26 more rows\n# &lt;e2&gt;&lt;84&gt;&lt;b9&gt; Use `print(n = ...)` to see more rows\n\nqpcr_summary &lt;-\n  qpcr_tidy |&gt;\n  group_by(gt, time, gene, rep_bio) |&gt;\n  summarize(\n    tech_mean = mean(exp),\n  ) |&gt;\n  group_by(gt, time, gene) |&gt;\n  summarize(\n    bio_mean = mean(tech_mean),\n    bio_sd = sd(tech_mean)\n  ) |&gt;\n  ungroup()\n\n`summarise()` has grouped output by 'gt', 'time', 'gene'. You can override\nusing the `.groups` argument.\n`summarise()` has grouped output by 'gt', 'time'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#question-2",
    "href": "problem-set-keys/ps-key-09.html#question-2",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 2",
    "text": "Question 2\n\nCreate a plot of expression by time from the data, using the mean of the biological replicates as the y value.\nColor the plot by genes.\nUse ggplot2::geom_pointrange() do represent the standard deviation of the data. Alternatively, use ggplot2::geom_errobar() with geom_point().\nDraw a line through the points with geom_line().\nFacet the plot by genotype.\nChange the colors of the of the plot with a scale function.\nUpdate the labels on the plot (“time (hours)”, etc.).\n\n\nggplot(\n  qpcr_summary,\n  aes(\n    x = time,\n    y = bio_mean,\n    color = gene\n  )\n) +\n  geom_pointrange(\n    aes(\n      ymin = bio_mean - bio_sd,\n      ymax = bio_mean + bio_sd\n    )\n  ) +\n  geom_line() +\n  facet_grid(~gt) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_cowplot()\n\n\n\n\nInterpret the plot\n\nWhat can you say about the expression of GAPDH and IFN in the different cell types?\n\n\n\n\n\nCan you come up with a simple molecular mechanism to explain the results?\n\n\nA straightforward explanation is that “TF” is a repssor of IFN induction (i.e., IFN goes up in its absence), and RL is similar, but possibly via an indirect effect on IFN expression. In any case, the mutants have negligible impact on GAPDH expression."
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#question-3",
    "href": "problem-set-keys/ps-key-09.html#question-3",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 3",
    "text": "Question 3\nReformat the data from question 2 such that you calculate a ratio of IFN to GAPDH. Start with the data question 1.2 above.\nRe-plot the data as in question 2, but leave out the color as you have collapsed the two genes into one value.\n\nqpcr_summary |&gt;\n  select(-bio_sd) |&gt;\n  pivot_wider(names_from = gene, values_from = bio_mean) |&gt;\n  rowwise() |&gt;\n  mutate(exp_ratio = `IFN-beta` / GAPDH) |&gt;\n  ggplot(\n    aes(x = time, y = exp_ratio)\n  ) +\n  geom_point() +\n  facet_grid(~gt) +\n  ylim(0, 15) +\n  theme_cowplot()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nThis is considerably less interesting than I was planning, caused by the fractional values of GAPDH. C’est la vie. Consider this an exercise in pivoting."
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#question-4",
    "href": "problem-set-keys/ps-key-09.html#question-4",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 4",
    "text": "Question 4\nIs there greater variance across the technical replicates, or across the biological replicates (across the whole experiment)?\nTo get at this question, calculate the standard deviations across the two sets of replicates separately. Which one has a greater spread?\n\nThe key is the way you used group_by(). The technical replicates are tighter, which is expected if i) biology is variable and ii) you are any good at pipetting.\n\n\n# one way\nqpcr_tidy |&gt;\n  group_by(rep_tech) |&gt;\n  summarize(tech_sd = sd(exp))\n\n# A tibble: 3 x 2\n  rep_tech tech_sd\n     &lt;int&gt;   &lt;dbl&gt;\n1        1    69.6\n2        2    78.7\n3        3    74.8\n\nqpcr_tidy |&gt;\n  group_by(rep_bio) |&gt;\n  summarize(bio_sd = sd(exp))\n\n# A tibble: 3 x 2\n  rep_bio bio_sd\n    &lt;int&gt;  &lt;dbl&gt;\n1       1   73.2\n2       2   80.8\n3       3   68.9\n\n# another\nqpcr_tidy |&gt;\n  group_by(rep_tech) |&gt;\n  summarize(tech_range = max(exp) - min(exp))\n\n# A tibble: 3 x 2\n  rep_tech tech_range\n     &lt;int&gt;      &lt;dbl&gt;\n1        1       415.\n2        2       458.\n3        3       389.\n\nqpcr_tidy |&gt;\n  group_by(rep_bio) |&gt;\n  summarize(bio_range = max(exp) - min(exp))\n\n# A tibble: 3 x 2\n  rep_bio bio_range\n    &lt;int&gt;     &lt;dbl&gt;\n1       1      389.\n2       2      458.\n3       3      380."
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#grading-rubric",
    "href": "problem-set-keys/ps-key-09.html#grading-rubric",
    "title": "R Bootcamp Problem Set 9",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-set-keys/ps-key-09.html#submit",
    "href": "problem-set-keys/ps-key-09.html#submit",
    "title": "R Bootcamp Problem Set 9",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-05.html",
    "href": "problem-set-keys/ps-key-05.html",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "🐧❤️🍕\n\nCodelibrary(tidyverse)\nlibrary(emo)\nlibrary(here)\nlibrary(gganimate)\nlibrary(palmerpenguins)\nlibrary(ragg)\n\nanim &lt;- penguins |&gt;\n  drop_na() |&gt;\n  mutate(\n    emoji = case_when(\n      sex == \"female\" ~ emo::ji(\"pizza\"),\n      sex == \"male\" ~ emo::ji(\"penguin\")\n    )\n  ) |&gt;\n  rowwise() |&gt;\n  mutate(angle = sample(0:360, size = 1)) |&gt;\n  ungroup() |&gt;\n  ggplot(\n    aes(\n      x = body_mass_g,\n      y = flipper_length_mm\n    )\n  ) +\n  geom_text(\n    aes(\n      label = emoji,\n      angle = angle\n    ),\n    size = 13,\n  ) +\n  coord_trans(x = \"log\", y = \"log\") +\n  labs(\n    title = paste0(\n      \"PENGUIN\", emo::ji(\"penguin\"),\n      \"PIZZA\", emo::ji(\"pizza\"),\n      \"PARTY\", emo::ji(\"party\"),\n      collapse = \"\"\n    ),\n    x = paste0(emo::ji(\"island\"), \"maybe latitude or longitude\", collapse = \"  \"),\n    y = paste0(emo::ji(\"sun\"), \"temperature (K)\", collapse = \"  \")\n  ) +\n  theme(\n    legend.position = \"none\",\n    axis.text = element_text(angle = 180),\n    plot.title = element_text(hjust = 0.5, size = 30),\n    axis.title = element_text(size = 30),\n    axis.text.x = element_text(size = 2),\n    axis.text.y = element_text(size = 2),\n    plot.background = element_rect(fill = \"#ffcc5c\"),\n    panel.background = element_rect(fill = \"#ffeead\"),\n    panel.grid.major = element_line(color = \"#ff6f69\"),\n    panel.grid.minor = element_line(color = \"#96ceb4\")\n  ) +\n  transition_states(\n    transition_length = 1,\n    state_length = 0.001,\n    year\n  ) +\n  enter_grow() +\n  exit_shrink() +\n  view_follow()\n\np &lt;- animate(anim, device = \"ragg_png\")\nanim_save(here(\"img/ugly_plot.gif\"), p)"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html",
    "href": "problem-set-keys/ps-key-03.html",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#setup",
    "href": "problem-set-keys/ps-key-03.html#setup",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#problem-set",
    "href": "problem-set-keys/ps-key-03.html#problem-set",
    "title": "R Bootcamp Problem Set 3",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 5 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Aug 31.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-1",
    "href": "problem-set-keys/ps-key-03.html#question-1",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 1",
    "text": "Question 1\nLoad the palmerpenguins package. Inspect the penguins tibble with summary.\nUse drop_na() to remove rows with NA values in the penguins tibble. How many rows were removed from the tibble?\n\nlibrary(palmerpenguins)\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\npenguins_nona &lt;- drop_na(penguins)\nnrow(penguins) - nrow(penguins_nona)\n\n[1] 11\n\n\nThen, use replace_na() to replace NA values in bill_length_mm and bill_depth_mm with a value of 0.\n\nreplace_na(penguins, list(bill_length_mm = 0, bill_depth_mm = 0))\n\n# A tibble: 344 x 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen            0             0                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# i 334 more rows\n# i 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-2",
    "href": "problem-set-keys/ps-key-03.html#question-2",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 2",
    "text": "Question 2\nUse arrange, filter, and select on a data frame. Do the following, in order:\n\nImport the data set data/data_transcript_exp_tidy.csv.\nSort the tibble by expression data (count) from highest to lowest level.\nFilter the tibble by count &gt; 100\nSelect all columns except for type\n\n\n\nexp_tbl &lt;- read_csv(here(\"data/data_transcript_exp_tidy.csv.gz\"))\n\nRows: 600 Columns: 5\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (4): ensembl_transcript_id, type, time, replicate\ndbl (1): count\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nexp_tbl |&gt;\n  arrange(count) |&gt;\n  filter(count &gt; 100) |&gt;\n  select(-type)\n\n# A tibble: 109 x 4\n   ensembl_transcript_id      time  replicate count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000342753.8_291_1314 0h    rep2       101 \n 2 ENST00000378251.2_29_1778  0h    rep3       102 \n 3 ENST00000378230.7_524_3101 0h    rep3       105 \n 4 ENST00000054666.10_116_416 14h   rep3       105 \n 5 ENST00000344843.11_97_544  14h   rep1       106 \n 6 ENST00000400809.7_379_1567 14h   rep3       106.\n 7 ENST00000054666.10_116_416 14h   rep1       108 \n 8 ENST00000615252.4_548_1268 14h   rep3       108.\n 9 ENST00000445648.5_40_1390  0h    rep1       109.\n10 ENST00000291386.3_370_895  14h   rep2       109 \n# i 99 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-3",
    "href": "problem-set-keys/ps-key-03.html#question-3",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 3",
    "text": "Question 3\nHow will you:\n\ncreate a new column log10count that contains log10 transformed count values and\nrearrange the columns in the following order: ensembl_transcript_id, type, time, replicate, count, log10count.\n\n(Note that we have dropped extra)\nHint: Use mutate and select\n\nexp_tbl |&gt;\n  mutate(log10count = log10(count)) |&gt;\n  select(ensembl_transcript_id, type, time, replicate, count, log10count)\n\n# A tibble: 600 x 6\n   ensembl_transcript_id      type  time  replicate count log10count\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna   0h    rep1        243      2.39 \n 2 ENST00000327044.6_51_2298  rna   0h    rep2        322      2.51 \n 3 ENST00000327044.6_51_2298  rna   0h    rep3        303      2.48 \n 4 ENST00000327044.6_51_2298  rna   14h   rep1        177      2.25 \n 5 ENST00000327044.6_51_2298  rna   14h   rep2        177      2.25 \n 6 ENST00000327044.6_51_2298  rna   14h   rep3        239      2.38 \n 7 ENST00000338591.7_360_2034 rna   0h    rep1         19      1.28 \n 8 ENST00000338591.7_360_2034 rna   0h    rep2         17      1.23 \n 9 ENST00000338591.7_360_2034 rna   0h    rep3         15      1.18 \n10 ENST00000338591.7_360_2034 rna   14h   rep1          9      0.954\n# i 590 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-03.html#question-4",
    "href": "problem-set-keys/ps-key-03.html#question-4",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 4",
    "text": "Question 4\nCalculate a per-transcript sum, while keeping the time information?\nHint: Use group_by with multiple variables, and summarise the “count” values using sum()\n\nexp_tbl |&gt;\n  group_by(ensembl_transcript_id, time) |&gt;\n  summarize(count_sum = sum(count))\n\n`summarise()` has grouped output by 'ensembl_transcript_id'. You can override\nusing the `.groups` argument.\n\n\n# A tibble: 200 x 3\n# Groups:   ensembl_transcript_id [100]\n   ensembl_transcript_id        time  count_sum\n   &lt;chr&gt;                        &lt;chr&gt;     &lt;dbl&gt;\n 1 ENST00000054650.8_159_876    0h         33.8\n 2 ENST00000054650.8_159_876    14h        16.5\n 3 ENST00000054666.10_116_416   0h        447  \n 4 ENST00000054666.10_116_416   14h       281  \n 5 ENST00000054668.5_220_418    0h          0  \n 6 ENST00000054668.5_220_418    14h        22.5\n 7 ENST00000234590.8_121_1423   0h      31565  \n 8 ENST00000234590.8_121_1423   14h     16394  \n 9 ENST00000263741.11_1328_1496 0h         97.5\n10 ENST00000263741.11_1328_1496 14h        79  \n# i 190 more rows"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html",
    "href": "problem-set-keys/ps-key-01.html",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 10 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#problem-set",
    "href": "problem-set-keys/ps-key-01.html#problem-set",
    "title": "Problem Set 1 Key",
    "section": "",
    "text": "Each problem below is worth 10 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#setup",
    "href": "problem-set-keys/ps-key-01.html#setup",
    "title": "Problem Set 1 Key",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis below. When in doubt, start by loading the tidyverse package.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-1",
    "href": "problem-set-keys/ps-key-01.html#question-1",
    "title": "Problem Set 1 Key",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5\n\ny should be a numerica vector of length 5\n\nz should be a logical vector of length 5\n\nUse length() to calculate the length of each vector.\n\nx &lt;- LETTERS[1:5]\ny &lt;- 1:5\nz &lt;- c(TRUE, TRUE, FALSE, FALSE, FALSE)\n\nx\n\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\ny\n\n[1] 1 2 3 4 5\n\nz\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\nlength(x)\n\n[1] 5\n\nlength(y)\n\n[1] 5\n\nlength(z)\n\n[1] 5"
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#question-2",
    "href": "problem-set-keys/ps-key-01.html#question-2",
    "title": "Problem Set 1 Key",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z.\nUse nrow() and ncol() to calculate the number of rows and columns.\nWhat do you notice about the length of the vectors and the number of rows.\n\ntbl &lt;- tibble(x = x, y = y, z = z)\nnrow(tbl)\n\n[1] 5\n\nncol(tbl)\n\n[1] 3\n\n\nAnswer\nThe length of the vectors and the number of rows are the same, because tibble columns are simply the vectors we started with."
  },
  {
    "objectID": "problem-set-keys/ps-key-01.html#submit",
    "href": "problem-set-keys/ps-key-01.html#submit",
    "title": "Problem Set 1 Key",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problemt set on Canvas."
  },
  {
    "objectID": "prepare/prepare-19.html",
    "href": "prepare/prepare-19.html",
    "title": "Preparation for factor-centric chromatin analysis",
    "section": "",
    "text": "Important\n\n\n\nYou will need to review this material before class 20."
  },
  {
    "objectID": "prepare/prepare-19.html#experimental-methods",
    "href": "prepare/prepare-19.html#experimental-methods",
    "title": "Preparation for factor-centric chromatin analysis",
    "section": "Experimental methods",
    "text": "Experimental methods\nSkene PJ, Henikoff S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. Elife. 2017 PMID: 28079019; PMCID: PMC5310842. [Link]\nKaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG, Ahmad K, Henikoff S. CUT&Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun. 2019 PMID: 31036827; PMCID: PMC6488672. [Link]"
  },
  {
    "objectID": "prepare/prepare-19.html#software-tools",
    "href": "prepare/prepare-19.html#software-tools",
    "title": "Preparation for factor-centric chromatin analysis",
    "section": "Software tools",
    "text": "Software tools\nMACS is the gold-standard in peak calling. It models read coverage as a Poisson process, enabling identification of regions of higher than expected coverage (i.e., peaks) to be identified using a single parmaeter (lambda) that captures the mean and variance of read coverage. Read over the paper to get a sense of how it works.\nWe’ll use the motifRG R library, which implements a discriminative (i.e., foreground / background) approach for motif discovery and answer the question, “Which sequences drive factor association to DNA?”."
  },
  {
    "objectID": "prepare/prepare-11.html",
    "href": "prepare/prepare-11.html",
    "title": "Stats Bootcamp",
    "section": "",
    "text": "Watch the following videos from StatQuest (it will take ~15 mins to watch them all):"
  },
  {
    "objectID": "prepare/prepare-11.html#prepare",
    "href": "prepare/prepare-11.html#prepare",
    "title": "Stats Bootcamp",
    "section": "",
    "text": "Watch the following videos from StatQuest (it will take ~15 mins to watch them all):"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MOLB 7950: Informatics and Statistics for Molecular Biology",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n  \n    \n      MOLB 7950 - Fall 2023 Schedule\n    \n    \n      Classes held in-person in AHSB 2201, 9:00-10:30am\n    \n    \n      \n      Date\n      Block\n      Topic\n      Instructor\n      Title\n      \n        Links\n      \n    \n    \n      Prepare\n      Slides\n      Exercises\n      HW\n      Key\n    \n  \n  \n    \n      Week 1\n    \n    01\nMon, Aug 28, 2023\nBootcamp\nR\nHesselberth\nIntro to R & RStudio\n📖\n📄\n💪\n🧠\n🔑\n    02\nTue, Aug 29, 2023\nBootcamp\nR\nHesselberth\nTidy data & tidyr\n\n📄\n💪\n🧠\n🔑\n    03\nWed, Aug 30, 2023\nBootcamp\nR\nHesselberth\ndplyr\n\n📄\n💪\n🧠\n🔑\n    04\nThu, Aug 31, 2023\nBootcamp\nR\nHesselberth\nggplot2\n\n📄\n💪\n🧠\n🔑\n    05\nFri, Sep 1, 2023\nBootcamp\nR\nHesselberth\nggplot2\n\n📄\n💪\n🧠\n🔑\n    \n      Week 2\n    \n    06\nMon, Sep 4, 2023\n-\n-\n-\nNO CLASS: LABOR DAY\n\n\n\n\n\n    07\nTue, Sep 5, 2023\nBootcamp\nR\nHesselberth\ntidyverse odds & ends\n\n📄\n💪\n🧠\n🔑\n    08\nWed, Sep 6, 2023\nBootcamp\nR\nHesselberth\nputting it all together\n\n\n💪\n\n\n    09\nThu, Sep 7, 2023\nBootcamp\nR\nHesselberth\nputting it all together\n\n\n💪\n🧠\n🔑\n    10\nFri, Sep 8, 2023\nBootcamp\nStatistics\nMukherjee\nStats intro and history\n\n📄\n💪\n\n\n    \n      Week 3\n    \n    11\nMon, Sep 11, 2023\nBootcamp\nStatistics\nMukherjee\nProbability and descriptive stats\n📖\n📄\n💪\n🧠\n🔑\n    12\nTue, Sep 12, 2023\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n\n📄\n💪\n🧠\n🔑\n    13\nWed, Sep 13, 2023\nBootcamp\nStatistics\nMukherjee\nHypothesis testing\n\n📄\n💪\n🧠\n🔑\n    14\nThu, Sep 14, 2023\nBootcamp\nStatistics\nMukherjee\nExploratory data analysis\n\n📄\n💪\n🧠\n🔑\n    15\nFri, Sep 15, 2023\nBootcamp\nStatistics\nMukherjee\nBig data concerns\n\n📄\n💪\n🧠\n🔑\n    \n      Week 4\n    \n    16\nMon, Sep 18, 2023\nDNA\nMapping chromatin structure and transactions\nHesselberth\nExperimental overview\n📖\n📄\n💪\n🧠\n🔑\n    17\nWed, Sep 20, 2023\nDNA\nChromatin-centric methods\nHesselberth\nInformation from fragment length distributions\n\n\n💪\n\n\n    18\nFri, Sep 22, 2023\nDNA\nChromatin-centric methods\nHesselberth\nMeta-plots and heatmaps\n\n\n💪\n🧠\n🔑\n    \n      Week 5\n    \n    19\nMon, Sep 25, 2023\nDNA\nWhere do proteins bind in the genome?\nHesselberth\nExperimental overview\n📖\n\n\n\n\n    20\nWed, Sep 27, 2023\nDNA\nFactor-centric methods\nHesselberth\nPeak calling\n\n\n\n\n\n    21\nFri, Sep 29, 2023\nDNA\nFactor-centric methods\nHesselberth\nSequence motif analysis\n\n\n💪\n🧠\n🔑\n    \n      Week 6\n    \n    22\nMon, Oct 2, 2023\nRNA\nRNA-seq Overview\nMukherjee\n-\n\n📄\n💪\n\n\n    23\nWed, Oct 4, 2023\nRNA\nDifferential Gene Expression\nMukherjee\n-\n📖\n📄\n💪\n🧠\n\n    24\nFri, Oct 6, 2023\nRNA\nDifferential Gene Expression\nMukherjee\n-\n\n📄\n💪\n🧠\n\n    \n      Week 7\n    \n    25\nMon, Oct 9, 2023\nRNA\nAlternative Splicing\nMukherjee\n-\n\n\n\n\n\n    26\nWed, Oct 11, 2023\nRNA\nVignette\nMukherjee\n-\n\n\n\n\n\n    27\nFri, Oct 13, 2023\n-\n-\n-\nNO CLASS: CSDV RETREAT\n\n\n\n\n\n    \n      Week 8\n    \n    28\nMon, Oct 16, 2023\nRNA\nRBP\nMukherjee\n-\n\n\n\n\n\n    29\nWed, Oct 18, 2023\nRNA\nRBP\nMukherjee\n-\n\n\n\n\n\n    30\nFri, Oct 20, 2023\nRNA\nLong-read sequencing\nHesselberth\n-\n\n\n\n\n\n    \n      Week 9\n    \n    31\nMon, Oct 23, 2023\nRNA\nSingle-cell\nRiemondy\n-\n\n\n\n\n\n    32\nWed, Oct 25, 2023\nRNA\nSingle-cell\nRiemondy\n-\n\n\n\n\n\n    33\nFri, Oct 27, 2023\n-\n-\n-\nNO CLASS: MOLB RETREAT\n\n\n\n\n\n    \n      Week 10\n    \n    34\nMon, Oct 30, 2023\nFinal\n-\n-\nFinal project presentations\n\n\n\n\n\n    35\nWed, Nov 1, 2023\nFinal\n-\n-\nFinal project presentations"
  },
  {
    "objectID": "exercises/ex-23.html",
    "href": "exercises/ex-23.html",
    "title": "RNAseq QC",
    "section": "",
    "text": "We can get this relationships between transcripts and genes through biomaRt.\nbiomaRt has many tables that relate genes, transcripts, and other useful data include gene biotypes and gene ontology categories, even across species. Let’s use it here to get a table of genes and transcripts for the mouse genome.\n\n# First we need to define a 'mart' to use.\n# There are a handful of them that\n# you can see here:\nlistMarts(\n  mart = NULL,\n  host = \"www.ensembl.org\"\n)\n\nI encourage you to see what is in each mart, but for now we are only going to use ENSEMBL_MART_ENSEMBL.\n\nmart &lt;- biomaRt::useMart(\"??\", host = \"www.ensembl.org\")"
  },
  {
    "objectID": "exercises/ex-23.html#relating-genes-and-transcripts",
    "href": "exercises/ex-23.html#relating-genes-and-transcripts",
    "title": "RNAseq QC",
    "section": "",
    "text": "We can get this relationships between transcripts and genes through biomaRt.\nbiomaRt has many tables that relate genes, transcripts, and other useful data include gene biotypes and gene ontology categories, even across species. Let’s use it here to get a table of genes and transcripts for the mouse genome.\n\n# First we need to define a 'mart' to use.\n# There are a handful of them that\n# you can see here:\nlistMarts(\n  mart = NULL,\n  host = \"www.ensembl.org\"\n)\n\nI encourage you to see what is in each mart, but for now we are only going to use ENSEMBL_MART_ENSEMBL.\n\nmart &lt;- biomaRt::useMart(\"??\", host = \"www.ensembl.org\")"
  },
  {
    "objectID": "exercises/ex-23.html#using-biomart",
    "href": "exercises/ex-23.html#using-biomart",
    "title": "RNAseq QC",
    "section": "Using biomaRt",
    "text": "Using biomaRt\nAlright, we’ve chosen our mart. What data sets are available in this mart?\n\ndatasets &lt;- listDatasets(mart)\ngt(datasets)\n\nA lot of stuff for a lot of species! Perhaps we want to limit it to see which ones are relevant to mouse.\n\nmousedatasets &lt;- filter(datasets, grepl(\"??\", dataset))\n\ngt(mousedatasets)"
  },
  {
    "objectID": "exercises/ex-23.html#using-biomart-1",
    "href": "exercises/ex-23.html#using-biomart-1",
    "title": "RNAseq QC",
    "section": "Using biomaRt",
    "text": "Using biomaRt\nAh so we probably want the dataset called ‘mmusculus_gene_ensembl’!\n\nmart &lt;- biomaRt::useMart(\n  \"ENSEMBL_MART_ENSEMBL\",\n  dataset = \"??\",\n  host = \"www.ensembl.org\"\n)"
  },
  {
    "objectID": "exercises/ex-23.html#using-biomart-2",
    "href": "exercises/ex-23.html#using-biomart-2",
    "title": "RNAseq QC",
    "section": "Using biomaRt",
    "text": "Using biomaRt\n\ngoodies &lt;- listAttributes(mart)\ngt(goodies[1:20,])"
  },
  {
    "objectID": "exercises/ex-23.html#using-biomart-3",
    "href": "exercises/ex-23.html#using-biomart-3",
    "title": "RNAseq QC",
    "section": "Using biomaRt",
    "text": "Using biomaRt\nSo there are 2885 rows of goodies about the mouse genome and its relationship to many other genomes. However, you can probably see that the ones that are most useful to us right now are right at the top: ‘ensembl_transcript_id’ and ‘ensembl_gene_id’. We can use those attributes in our mart to make a table relating genes and transcripts.\nI’m going to through one more attribute in: external_gene_name. Those are usually more informative than ensembl IDs.\n\nt2g &lt;- biomaRt::getBM(attributes = c(\"??\", \"??\", \"??\"), mart = mart)\n\n# write_tsv(x = t2g, file = here(\"data\",\"block-rna\",\"t2g.tsv.gz\"))\n# t2g &lt;- read_tsv(here(\"data\",\"block-rna\",\"t2g.tsv.gz\"))\n\ngt(t2g[1:20, ])"
  },
  {
    "objectID": "exercises/ex-23.html#using-biomart-4",
    "href": "exercises/ex-23.html#using-biomart-4",
    "title": "RNAseq QC",
    "section": "Using biomaRt",
    "text": "Using biomaRt\nAlright this looks good! We are going to split this into two tables. One that contains transcript ID and gene ID, and the other that contains gene ID and gene name.\n\nt2g &lt;- t2g |&gt; dplyr::select(??, ??)"
  },
  {
    "objectID": "exercises/ex-23.html#getting-gene-level-expression-data-with-tximport",
    "href": "exercises/ex-23.html#getting-gene-level-expression-data-with-tximport",
    "title": "RNAseq QC",
    "section": "Getting gene level expression data with tximport\n",
    "text": "Getting gene level expression data with tximport\n\nNow that we have our table relating transcripts and genes, we can give it to tximport to have it calculate gene-level expression data from our transcript-level expression data.\nFirst, we have to tell it where the salmon quantification files (the quant.sf.gz files) are. Here’s what our directory structure that contains these files looks like:"
  },
  {
    "objectID": "exercises/ex-23.html#gene-expression-data-with-tximport",
    "href": "exercises/ex-23.html#gene-expression-data-with-tximport",
    "title": "RNAseq QC",
    "section": "Gene expression data with tximport\n",
    "text": "Gene expression data with tximport\n\n\n# The directory where all of the sample-specific salmon subdirectories live\n\n# list.files(here(\"data/block-rna/salmonouts\"), pattern = \"^DIV\")\n\nmetadata &lt;- data.frame(sample_id = ??, # sample id\n                   salmon_dirs = ?? # path to files\n\n                   ) |&gt;\n  separate(col = sample_id, into = c(\"samp\",\"rep\"), sep = \"\\\\.\", remove = F)\n\nmetadata$rep &lt;- gsub(pattern = \"Rep\", replacement = \"\", metadata$rep) \n\n\n## add sample id to rownames\nrownames(metadata) &lt;- metadata$sample_id"
  },
  {
    "objectID": "exercises/ex-23.html#gene-expression-data-with-tximport-1",
    "href": "exercises/ex-23.html#gene-expression-data-with-tximport-1",
    "title": "RNAseq QC",
    "section": "Gene expression data with tximport\n",
    "text": "Gene expression data with tximport\n\nYou can see that we got a list of sample names and the absolute path to each sample’s quantification file.\nNow we are ready to run tximport\ntximport is going to want paths to all the quantification files (salm_dirs) and a table that relates transcripts to genes (t2g). Luckily, we happen to have those exact two things.\n\n# create a list containg paths\nsalmdir &lt;- ??\n\n# add names\nnames(salmdir) &lt;- ??\n\n\ntxi &lt;- tximport(files = salmdir,\n  type = \"salmon\",\n  tx2gene = t2g,\n  dropInfReps = TRUE,\n  countsFromAbundance = \"lengthScaledTPM\"\n)"
  },
  {
    "objectID": "exercises/ex-23.html#gene-expression-data-with-tximport-2",
    "href": "exercises/ex-23.html#gene-expression-data-with-tximport-2",
    "title": "RNAseq QC",
    "section": "Gene expression data with tximport\n",
    "text": "Gene expression data with tximport\n\nNotice how we chose lengthscaledTPM for our abundance measurement. This is going to give us TPM values (transcripts per million) for expression in the $abundance slot. Let’s check out what we have now.\n\ntpms &lt;- txi$abundance |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ensembl_gene_id\")\n\ngt(tpms[1:50, ])"
  },
  {
    "objectID": "exercises/ex-23.html#tpm-as-an-expression-metric",
    "href": "exercises/ex-23.html#tpm-as-an-expression-metric",
    "title": "RNAseq QC",
    "section": "TPM as an expression metric",
    "text": "TPM as an expression metric\nAlright, not bad!\nLet’s stop and think for a minute about what tximport did and the metric we are using (TPM). What does transcripts per million mean? Well, it means pretty much what it sounds like. For every million transcripts in the cell, X of them are this particular transcript. Importantly, this means when this TPM value was calculated from the number of counts a transcript received, this number had to be adjusted for both the total number of counts in the library and the length of a transcript.\nIf sample A had twice the number of total counts as sample B (i.e. was sequenced twice as deeply), then you would expect every transcript to have approximately twice the number of counts in sample A as it has in sample B. Similarly, if transcript X is twice as long as transcript Y, then you would expect that if they were equally expressed (i.e. the same number of transcript X and transcript Y molecules were present in the sample) that X would have approximately twice the counts that Y does. Working with expression units of TPM incorporates both of these normalizations.\nSo, if a TPM of X means that for every million transcripts in the sample that X of them were the transcript of interest, then the sum of TPM values across all species should equal one million, right?\nLet’s check and see if that’s true."
  },
  {
    "objectID": "exercises/ex-23.html#tpm-as-an-expression-metric-1",
    "href": "exercises/ex-23.html#tpm-as-an-expression-metric-1",
    "title": "RNAseq QC",
    "section": "TPM as an expression metric",
    "text": "TPM as an expression metric\n\ncolSums(tpms[,-1])\nsum(tpms$??)\nsum(tpms$??)\nsum(tpms$??)\n\nOK, not quite one million, but pretty darn close.\nThis notion that TPMs represent proportions of a whole also leads to another interesting insight into what tximport is doing here. If all transcripts belong to genes, then the TPM for a gene must be the sum of the TPMs of its transcripts. Can we verify that that is true?"
  },
  {
    "objectID": "exercises/ex-23.html#tpm-as-an-expression-metric-2",
    "href": "exercises/ex-23.html#tpm-as-an-expression-metric-2",
    "title": "RNAseq QC",
    "section": "TPM as an expression metric",
    "text": "TPM as an expression metric\n\n# Redefine for clarity in comparisons\ntpms.genes &lt;- tpms\n\n# Make a new tximport object, but this time instead\n# of giving gene expression values, give transcript expression values\n\n# This is controlled by the `txOut` argument\ntxi.transcripts &lt;- tximport(\n  salmdir,\n  type = \"salmon\",\n  tx2gene = t2g,\n  dropInfReps = TRUE,\n  countsFromAbundance = \"lengthScaledTPM\",\n  txOut = TRUE\n)\n\n# Make a table of tpm values for every transcript\ntpms.txs &lt;- ?? |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ensembl_transcript_id\") |&gt;\n  inner_join(t2g, ., by = \"ensembl_transcript_id\")\n\ngt(tpms.txs[1:20, ])\n\nOK so lets look at the expression of ENSMUSG00000020634 in the first sample (DIVminus8.Rep1)."
  },
  {
    "objectID": "exercises/ex-23.html#tpm-as-an-expression-metric-3",
    "href": "exercises/ex-23.html#tpm-as-an-expression-metric-3",
    "title": "RNAseq QC",
    "section": "TPM as an expression metric",
    "text": "TPM as an expression metric\n\n# Get sum of tpm values for transcripts that belong to ENSMUSG00000020634\ntpms.tx.ENSMUSG00000020634 &lt;- filter(tpms.txs, ensembl_gene_id == \"ENSMUSG00000020634\")\nsumoftxtpm &lt;- sum(tpms.tx.ENSMUSG00000020634$DIVminus8.Rep1)\n\n# Get gene level tpm value of ENSMUSG00000020634\ngenetpm &lt;- filter(tpms.genes, ensembl_gene_id == \"ENSMUSG00000020634\")$DIVminus8.Rep1\n\n# Are they the same?\nsumoftxtpm\ngenetpm"
  },
  {
    "objectID": "exercises/ex-23.html#basic-rnaseq-qc",
    "href": "exercises/ex-23.html#basic-rnaseq-qc",
    "title": "RNAseq QC",
    "section": "Basic RNAseq QC",
    "text": "Basic RNAseq QC\nOK now that we’ve got expression values for all genes, we now might want to use these expression values to learn a little bit about our samples. One simple question is &gt; Are replicates similar to each other, or at least more similar to each other than to other samples?\nIf our data is worth anything at all, we would hope that differences between replicates, which are supposed to be drawn from the same condition, are smaller than differences between samples drawn from different conditions. If that’s not true, it could indicate that one replicate is very different from other replciates (in which case we might want to remove it), or that the data in general is of poor quality.\nAnother question is:\n\nHow similar is each sample to every other sample?\n\nIn our timecourse, we might expect that samples drawn from adjacent timepoints might be more similar to each other than samples from more distant timepoints."
  },
  {
    "objectID": "exercises/ex-23.html#hierarchical-clustering",
    "href": "exercises/ex-23.html#hierarchical-clustering",
    "title": "RNAseq QC",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering\nA simple way to think about this is to simply correlate TPM values for genes between samples. For plotting purposes here, let’s plot the log(TPM) of two samples against each other. However, for the actual correlation coefficient we are going to be using the Spearman correlation method, which uses ranks, not absolute values. This means that whether or not you take the log will have no effect on the Spearman correlation coefficient.\n\n# DIVminus8.Rep1 vs DIVminus8.Rep2\n\nr.spearman &lt;- cor(tpms$DIVminus8.Rep1, tpms$DIVminus8.Rep2,\n  method = \"spearman\")\n\nr.spearman &lt;- signif(r.spearman, 2)\n\n# plot adding pseudocount + log\nggplot(tpms, aes(x = log??(DIVminus8.Rep1 + ??), y = log??(DIVminus8.Rep2 + ??))) +\n  geom_point() +\n  theme_classic() +\n  annotate(\"text\", x = 2, y = 0, label = paste0(\"R = \", r.spearman))"
  },
  {
    "objectID": "exercises/ex-23.html#hierarchical-clustering-1",
    "href": "exercises/ex-23.html#hierarchical-clustering-1",
    "title": "RNAseq QC",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering\nWith RNAseq data, the variance of a gene’s expression increases as the expression increases. However, using a pseudocount and taking the log of the expression value actually reverses this trend. Now, genes with the lowest expression have the most variance. Why is this a problem? Well, the genes with the most variance are going to be the ones that contribute the most to intersample differences. Ideally, we would like to therefore remove the relationship between expression and variance.\nThere are transformations, notably rlog and vst, that are made to deal with this, but they are best used when dealing with normalized count data, while here we are dealing with TPMs. We will talk about counts later, but not here.\nSo, for now, we will take another approach of simply using an expression threshold. Any gene that does not meet our threshold will be excluded from the analysis. Obviously where to set this threshold is a bit subjective. For now, we will set this cutoff at 1 TPM."
  },
  {
    "objectID": "exercises/ex-23.html#hierarchical-clustering-2",
    "href": "exercises/ex-23.html#hierarchical-clustering-2",
    "title": "RNAseq QC",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering\n\n# DIVminus8.Rep1 vs DIVminus8.Rep2\n\n# Since we are plotting log TPM values we will only keep for genes that have expression of at least 1 TPM in both samples\ntpms_filt &lt;- tpms |&gt;\n  dplyr::select(ensembl_gene_id, DIVminus8.Rep1, DIVminus8.Rep2) |&gt;\n  filter(?? &gt;= ?? & ?? &gt;= ??)\n\n# pull the correlation coefficient\nr.spearman &lt;- cor(\n  tpms_filt$DIVminus8.Rep1,\n  tpms_filt$DIVminus8.Rep2,\n  method = \"spearman\"\n)\n\n# round/set sig digits\nr.spearman &lt;- signif(r.spearman, 2)\n\n# plot adding pseudocount + log\nggplot(tpms_filt, aes(x = log10(DIVminus8.Rep1 + 1e-3), y = log10(DIVminus8.Rep2 + 1e-3))) +\n  geom_point() +\n  theme_classic() +\n  annotate(\"text\", x = 2, y = 1, label = paste0(\"R = \", r.spearman))"
  },
  {
    "objectID": "exercises/ex-23.html#filtering-lowly-expressed-genes",
    "href": "exercises/ex-23.html#filtering-lowly-expressed-genes",
    "title": "RNAseq QC",
    "section": "Filtering lowly expressed genes",
    "text": "Filtering lowly expressed genes\nOK that’s two samples compared to each other, but now we want to see how all samples compare to all other samples. Before we do this we need to decide how to apply our expression cutoff across many samples. Should a gene have to meet the cutoff in only one sample? In all samples? Let’s start by saying it has to meet the cutoff in at least half of the 30 samples.\n\n# Make a new column in tpms that is the number of samples in which the value is at least 1\ntpms.cutoff &lt;-\n  mutate(tpms, nSamples = rowSums(tpms[, ??] &gt; 1)) |&gt;\n  # Now filter for rows where nSamples is at least 15\n  # Meaning that at least 15 samples passed the threshold\n  filter(nSamples &gt;= ??) |&gt;\n  # Get rid of the nSamples column\n  dplyr::select(-nSamples)\n\nnrow(tpms)\nnrow(tpms.cutoff)"
  },
  {
    "objectID": "exercises/ex-23.html#correlating-gene-expression-values",
    "href": "exercises/ex-23.html#correlating-gene-expression-values",
    "title": "RNAseq QC",
    "section": "Correlating gene expression values",
    "text": "Correlating gene expression values\nNow we can use the cor function to calculate pairwise correlations in a .red[matrix] of TPM values.\n\ntpms.cutoff.matrix &lt;- tpms.cutoff |&gt;\n  dplyr::select(-ensembl_gene_id) |&gt;\n  as.matrix() # some functions just take matrices\n\ntpms.cor &lt;- cor(??, method = \"spearman\")\n\nhead(tpms.cor)"
  },
  {
    "objectID": "exercises/ex-23.html#hierarchical-clustering-3",
    "href": "exercises/ex-23.html#hierarchical-clustering-3",
    "title": "RNAseq QC",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering\nNow we need to plot these and have similar samples (i.e. those that are highly correlated with each other) be clustered near to each other. We will use pheatmap to do this.\n\n# let's pull information that we want to add as categories\npheatmap(\n  tpms.cor,\n  annotation_col = ??,\n  fontsize = 7,\n  show_colnames = FALSE\n)\n\nThis looks pretty good! There are two main points to takeaway here. First, all replicates for a given timepoint are clustering with each other. Second, you can kind of derive the order of the timepoints from the clustering. The biggest separation is between early (DIVminus8 to DIV1) and late (DIV7 to DIV28). After that you can then see finer-grained structure."
  },
  {
    "objectID": "exercises/ex-23.html#pca-analysis",
    "href": "exercises/ex-23.html#pca-analysis",
    "title": "RNAseq QC",
    "section": "PCA analysis",
    "text": "PCA analysis\nAnother way to visualize relationships is using a dimensionality reduction technique called Principal Component Analysis (PCA). Let’s watch this short video. It focuses more on how to interpret them rather than the math behind their creation."
  },
  {
    "objectID": "exercises/ex-23.html#pca-analysis-1",
    "href": "exercises/ex-23.html#pca-analysis-1",
    "title": "RNAseq QC",
    "section": "PCA analysis",
    "text": "PCA analysis\nPCA works best when values are approximately normally distributed, so we will first take the log of our expression values.\nWith our cutoff as it is now (genes have to have expression of at least 1 TPM in half the samples), it is possible that we will have some 0 values. Taking the log of 0 might cause a problem, so we will add a pseudocount.\n\ntpms.cutoff.matrix &lt;-\n  dplyr::select(tpms.cutoff, -ensembl_gene_id) |&gt;\n  as.matrix()\n\n# Add pseudocount and take log2\ntpms.cutoff.matrix &lt;- log2(tpms.cutoff.matrix + 1e-3)\n\n# scale - annoying double transpose\ntpms.cutoff.matrix &lt;- t(scale(t(tpms.cutoff.matrix)))"
  },
  {
    "objectID": "exercises/ex-23.html#pca-analysis-2",
    "href": "exercises/ex-23.html#pca-analysis-2",
    "title": "RNAseq QC",
    "section": "PCA analysis",
    "text": "PCA analysis\nVery similar interpretation as before (heatmap of correlation).\n\n# prcomp expects samples to be rownames, right now they are columns\n# so we need to transpose the matrix using `t`\ntpms.pca &lt;- prcomp(t(tpms.cutoff.matrix))\n\n# The coordinates of samples on the principle components are stored in the $x slot\n# These are what we are going to use to plot\n# We can also also some data about the samples here so that our plot is a little more interesting\n\n\n\n### Tricky piping!!\ntpms.pca.pc &lt;- tpms.pca$x %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(var = \"sample_id\") %&gt;%\n  left_join(., metadata[,1:3], by = \"sample_id\")\n\n\n\n# We can see how much of the total variance is explained by each PC using the summary function\ntpms.pca.summary &lt;- summary(tpms.pca)$importance\n\n# The amount of variance explained by PC1 is the second row, first column of this table\n# It's given as a fraction of 1, so we multiply it by 100 to get a percentage\npc1var &lt;- round(tpms.pca.summary[2, 1] * 100, 1)\n\n# The amount of variance explained by PC2 is the second row, second column of this table\npc2var &lt;- round(tpms.pca.summary[2, 2] * 100, 1)\n\n# Reorder timepoints explicitly for plotting purposes\n\ntpms.pca.pc$samp &lt;-\n  factor(\n    tpms.pca.pc$samp,\n    levels = c(\n      \"DIVminus8\", \"DIVminus4\", \"DIV0\",\n      \"DIV1\", \"DIV7\", \"DIV16\", \"DIV21\", \"DIV28\"\n    )\n  )\n\n# Plot results\nggplot(data = tpms.pca.pc,\n  aes(\n    x = PC1, y = PC2,\n    color = samp, label = sample_id\n  )\n) +\n  geom_point(size = 5) +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_cowplot(16) +\n  labs(\n    x = paste(\"PC1,\", pc1var, \"% explained var.\"),\n    y = paste(\"PC2,\", pc2var, \"% explained var.\")\n  ) +\n  geom_text_repel()"
  },
  {
    "objectID": "exercises/ex-21.html",
    "href": "exercises/ex-21.html",
    "title": "Factor-centric chromatin analysis",
    "section": "",
    "text": "Today we’ll look at where two yeast transcription factors bind in the genome using CUT&RUN.\nTechniques like CUT&RUN require an affinity reagent (e.g., an antibody) that uniquely recognizes a transcription factor in the cell.\nThis antibody is added to permeabilized cells, and the antibody associates with the epitope. A separate reagent, a fusion of Protein A (which binds IgG) and micrococcal nuclease (MNase) then associates with the antibody. Addition of calcium activates MNase, and nearby DNA is digested. These DNA fragments are then isolated and sequenced to identify sites of TF association in the genome.\n\n\nFig 1a, Skene et al.\n\n\nCUT&RUN data were downloaded from the NCBI GEO page for Skene et al.\nI selected the 16 second time point for S. cerevisiae Abf1 and Reb1 (note the paper combined data from the 1-32 second time points).\nBED files containing mapped DNA fragments were separated by size and converted to bigWig with:\n# separate fragments by size\nawk '($3 - $2 &lt;= 120)' Abf1.bed &gt; CutRun_Abf1_lt120.bed\nawk '($3 - $2 =&gt; 150)' Abf1.bed &gt; CutRun_Abf1_gt150.bed\n\n# for each file with the different sizes\nbedtools genomecov -i Abf1.bed -g sacCer3.chrom.sizes -bg &gt; Abf1.bg\nbedGraphToBigWig Abf1.bg sacCer3.chrom.sizes Abf1.bw\nThe bigWig files are available here in the data/ directory.\n\n\nHow do you ensure your antibody recognizes what you think it recognizes? What are important controls for ensuring it recognizes a specific epitope?\nWhat are important controls for CUT&RUN experiments?"
  },
  {
    "objectID": "exercises/ex-21.html#data-download-and-pre-processing",
    "href": "exercises/ex-21.html#data-download-and-pre-processing",
    "title": "Factor-centric chromatin analysis",
    "section": "",
    "text": "CUT&RUN data were downloaded from the NCBI GEO page for Skene et al.\nI selected the 16 second time point for S. cerevisiae Abf1 and Reb1 (note the paper combined data from the 1-32 second time points).\nBED files containing mapped DNA fragments were separated by size and converted to bigWig with:\n# separate fragments by size\nawk '($3 - $2 &lt;= 120)' Abf1.bed &gt; CutRun_Abf1_lt120.bed\nawk '($3 - $2 =&gt; 150)' Abf1.bed &gt; CutRun_Abf1_gt150.bed\n\n# for each file with the different sizes\nbedtools genomecov -i Abf1.bed -g sacCer3.chrom.sizes -bg &gt; Abf1.bg\nbedGraphToBigWig Abf1.bg sacCer3.chrom.sizes Abf1.bw\nThe bigWig files are available here in the data/ directory.\n\n\nHow do you ensure your antibody recognizes what you think it recognizes? What are important controls for ensuring it recognizes a specific epitope?\nWhat are important controls for CUT&RUN experiments?"
  },
  {
    "objectID": "exercises/ex-21.html#examine-genome-coverage",
    "href": "exercises/ex-21.html#examine-genome-coverage",
    "title": "Factor-centric chromatin analysis",
    "section": "Examine genome coverage",
    "text": "Examine genome coverage\n\ntrack_start &lt;- 90000\ntrack_end &lt;- 150000\n\n# genes track\nsgd_genes_trk &lt;-\n  GeneRegionTrack(\n    TxDb.Scerevisiae.UCSC.sacCer3.sgdGene,\n    chromosome = \"chrII\",\n    start = track_start,\n    end = track_end,\n    fill = \"#009E73\",\n    background.title = \"white\",\n    col.title = \"black\",\n    fontsize = 14\n  )\n\n# signal tracks\ntrack_info &lt;-\n  tibble(\n    file_name = c(\n      \"CutRun_Reb1_lt120.bw\",\n      \"CutRun_Abf1_lt120.bw\",\n      \"CutRun_Reb1_gt150.bw\",\n      \"CutRun_Abf1_gt150.bw\"\n    ),\n    sample_type = c(\n      \"Reb1_Short\", \"Abf1_Short\",\n      \"Reb1_Long\", \"Abf1_Long\"\n    )\n  ) |&gt;\n  mutate(\n    file_path = here(\"data/block-dna\", file_name),\n    big_wig = purrr::map(\n      file_path, ~ import.bw(.x, as = \"GRanges\")\n    ),\n    data_track = purrr::map2(\n      big_wig, sample_type,\n      ~ DataTrack(\n          .x,\n          name = .y,\n          background.title = \"white\",\n          col.title = \"black\",\n          col.axis = \"black\",\n          fontsize = 12\n      )\n    )\n  ) |&gt;\n  dplyr::select(sample_type, big_wig, data_track)\n\n# x-axis track\nx_axis_trk &lt;- GenomeAxisTrack(\n  col = \"black\",\n  col.axis = \"black\",\n  fontsize = 16\n)\n\nNow that we have tracks loaded, we can make a plot.\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\n\n\nQuestions\n\nWhat features stand out in the above tracks? What is different between Reb1 and Abf1? Between the short and long fragments?\nWhere are the major signals with respect to genes?"
  },
  {
    "objectID": "exercises/ex-21.html#peak-calling",
    "href": "exercises/ex-21.html#peak-calling",
    "title": "Factor-centric chromatin analysis",
    "section": "Peak calling",
    "text": "Peak calling\nA conceptually simple approach to identification of regions containing “peaks” where a transcription factor was bound is available in the MACS software (paper, github). There’s also a nice blog post covering the main ideas.\nTheory\nThe Poisson distribution is a discrete probability distribution of the form:\n\\[ P_\\lambda (X=k) = \\frac{ \\lambda^k }{ k! * e^{-\\lambda} } \\]\nwhere \\(\\lambda\\) captures both the mean and variance of the distribution.\nThe R functions dpois(), ppois(), and rpois() provide access to the density, distribution, and random generation for the Poisson distribution. See ?dpois for details.\n\n\n\n\n\nPractice\nHere, we model read coverage using the Poisson distribution. Given a genome size \\(G\\) and and a number of reads collected \\(N\\), we can approximate \\(\\lambda\\) from \\(N/G\\), scaled by the size of the sequence read (about 100 bp).\nThe intuition here is: where are \\(N\\) reads placed randomly on a genome of size \\(G\\)?\nMACS uses this value (the “genomic” lambda) and also calculates several “local” lambda values to account for variation among genomic regions. We’ll just using the genomic lambda, which provides a conservative threshold for peak calling.\nUsing genomic lambda, we can use the Poisson distribution to address the question: How surprised should I be to see \\(k\\) reads at position X?\n\nabf1_tbl &lt;- read_bigwig(here(\"data/block-dna/CutRun_Abf1_lt120.bw\"))\n\n# number of reads in the original Abf1 BED file\ntotal_reads &lt;- 16e6\n\ngenome &lt;- read_genome(here(\"data/block-dna/sacCer3.chrom.sizes\"))\n# how can we calculate genome size?\ngenome_size &lt;- ___ \n\ngenome_lambda &lt;- total_reads / genome_size\n\npeak_calls &lt;-\n  abf1_tbl |&gt;\n  # define single-base sites\n  mutate(\n    midpoint = start + round((end - start) / 2),\n    start = midpoint,\n    end = start + 1,\n    # use the poisson to calculate a p-value with the genome-wide lambda\n    pval = ___(score, genome_lambda),\n    # convert p-values to FDR\n    fdr = p.adjust(pval, method = \"fdr\")\n  )\n\nLet’s take a look at a plot of the p-value across a chromosome. What do you notice about this plot, when compared to the coverage of the CUT&RUN coverage above?\n\nggplot(\n  filter(peak_calls, chrom == \"chrII\"),\n  # convert p-values to positive values for plotting\n  aes(start, ___)\n) + \n  geom_line() +\n  xlim(track_start, track_end) +\n  theme_cowplot() \n\nHow many peaks are called in this region?\n\n# most stringent cut-off\npeak_calls_sig &lt;- \n  filter(\n    peak_calls,\n    fdr == 0\n    ) |&gt;\n    # collapse neighboring, significant sites\n    bed_merge(max_dist = 20)\n\nfilter(\n  peak_calls_sig,\n  chrom == \"chrII\" &\n    start &gt;= track_start &\n    end &lt;= track_end\n)\n\nLet’s visualize these peaks in the context of genomic CUT&RUN signal. We need to define an AnnotationTrack with the peak intervals, which we can plot against the CUT&RUN coverage we defined above.\n\n# need a GRanges object to convert to an AnnotationTrack\npeak_calls_gr &lt;-\n  GRanges(\n    seqnames = peak_calls_sig$chrom,\n    ranges = IRanges(peak_calls_sig$start, peak_calls_sig$end)\n  )\n\npeak_calls_trk &lt;-\n  AnnotationTrack(\n    peak_calls_gr,\n    name = \"Peak calls\",\n    fill = \"red\",\n    background.title = \"white\",\n    col.title = \"red\",\n    fontsize = 16,\n    rotation.title = 0\n  )\n\nabf1_short_trk &lt;-\n  filter(\n    track_info,\n    sample_type == \"Abf1_Short\"\n  ) |&gt;\n  pull(data_track)\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    abf1_short_trk,\n    peak_calls_trk,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\nQuestions\n\nHow many peaks were called throughout the genome? How wide are the called peaks, on average?\nHow else might we define a significance threshold for identifying peaks?\nWhat might the relative heights of the peaks indicate? What types of technical or biological variables might influence peak heights?"
  },
  {
    "objectID": "exercises/ex-21.html#motif-discovery",
    "href": "exercises/ex-21.html#motif-discovery",
    "title": "Factor-centric chromatin analysis",
    "section": "Motif discovery",
    "text": "Motif discovery\nTheory\nThere are two major approaches to defining sequence motifs enriched in a sample: enumerative and probabilistic approaches.\nHere we’ll apply a probabilistic approach (GADEM) to discover motifs in a collection of DNA sequences. During the RNA block, you’ll learn about k-mer analysis, which is a form of enumerative approach.\nIn each case, the goal is to define a set of sequence motifs that are encriched in a set of provided sequences (i.e., peaks from CUT&RUN data) relative to a genomic background.\nMotifs are expressed in a Position Weight Matrix, which captures the propensities for a position to be a particular nucleotide in a sequence motif.\nThese PWMs can be represented as sequence logos, visually represent the amount of information provided by the motif, typically using “information content”, expressed in bits.\n\n\nLexA sequence motif\n\nPractice\nWe’ll use the rGADEM package from Bioconductor to derive sequence motifs from the peaks we called above. This is a straightforward process:\n\nCollect the DNA sequences within the peak windows using the BSgenome for S. cerevisiae\n\nProvide those sequences and the genomic background to rGADEM::GADEM(), which runs uses an Expectation-Maximization (EM) approach to identify and refine motifs.\nExamine the discovered motifs, and plot as a logo using seqLogo::seqLogo().\n\n\npeak_seqs &lt;- BSgenome::getSeq(\n  # provided by BSgenome.Scerevisiae.UCSC.sacCer3\n  Scerevisiae,\n  peak_calls_gr\n)\n\n# takes ~2 minutes to run\ngadem &lt;- rGADEM::GADEM(\n  peak_seqs,\n  genome = Scerevisiae,\n  verbose = 1\n)\n\n# look at the consensus motifs\nconsensus(gadem)\n\n# how many consensus motifs are there?\nnOccurrences(gadem)\n\nNow let’s look at the sequence logo for the top hit.\n\npwm &lt;- gadem@motifList[[1]]@pwm\n\nseqLogo::seqLogo(pwm)\n\nQuestions\n\nDoes this motif make sense, based on what you know about the requirements and specificity of DNA binding by transcription factors?\nHow might you confirm that a specific sequence (that conforms to a motif) is bound directly by a transcription factor?"
  },
  {
    "objectID": "exercises/ex-21.html#references",
    "href": "exercises/ex-21.html#references",
    "title": "Factor-centric chromatin analysis",
    "section": "References",
    "text": "References\nGADEM: a genetic algorithm guided formation of spaced dyads coupled with an EM algorithm for motif discovery. J Comput Biol 2009 [PMC free article] [PubMed] [Google Scholar]"
  },
  {
    "objectID": "exercises/ex-17.html",
    "href": "exercises/ex-17.html",
    "title": "Chromatin accessibility I",
    "section": "",
    "text": "This class we’ll examine chromatin accessibility patterns and begin to get a sense of what they mean, both at the fine-scale (single base-pair) and across the genome."
  },
  {
    "objectID": "exercises/ex-17.html#chromatin-accessibility-patterns-and-genome-function",
    "href": "exercises/ex-17.html#chromatin-accessibility-patterns-and-genome-function",
    "title": "Chromatin accessibility I",
    "section": "",
    "text": "This class we’ll examine chromatin accessibility patterns and begin to get a sense of what they mean, both at the fine-scale (single base-pair) and across the genome."
  },
  {
    "objectID": "exercises/ex-17.html#load-the-libraries",
    "href": "exercises/ex-17.html#load-the-libraries",
    "title": "Chromatin accessibility I",
    "section": "Load the libraries",
    "text": "Load the libraries\nThese are libraries we’ve used before. patchwork is a library for composing groups of plots.\n\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(here)\nlibrary(patchwork)\nlibrary(broom)\n\nThese are new libraries specifically for genome analysis. You learned about valr and Gviz for your homework.\nrtracklayer provides a few utility functions we’ll use today, and TxDb.Scerevisiae.UCSC.sacCer3.sgdGene provides gene annotations for the S. cerevisiae genome.\n\nlibrary(valr)\nlibrary(Gviz)\n\nlibrary(rtracklayer)\nlibrary(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)"
  },
  {
    "objectID": "exercises/ex-17.html#load-the-data",
    "href": "exercises/ex-17.html#load-the-data",
    "title": "Chromatin accessibility I",
    "section": "Load the data",
    "text": "Load the data\nIn this and the next class we will analyze ATAC-seq and MNase-seq data sets from budding yeast. Here are the references for the two data set:\nATAC-seq\n\nSchep AN, Buenrostro JD, Denny SK, Schwartz K, Sherlock G, Greenleaf WJ. Structured nucleosome fingerprints enable high-resolution mapping of chromatin architecture within regulatory regions. Genome Res. 2015 PMID: 26314830; PMCID: PMC4617971. [Link] [Data]\n\nMNase-seq\n\nZentner GE, Henikoff S. Mot1 redistributes TBP from TATA-containing to TATA-less promoters. Mol Cell Biol. 2013 PMID: 24144978; PMCID: PMC3889552. [Link] [Data]\n\nExperimental consideration\nIn a standard MNase-seq experiment, DNA around ~150 bp is extracted to look closely at nucleosome occupancy & positioning. However, the above study did not perform size selection. This is important as now we can look at both transcription factor binding sites and nucleosome positions."
  },
  {
    "objectID": "exercises/ex-17.html#fragment-size-distributions-are-informative",
    "href": "exercises/ex-17.html#fragment-size-distributions-are-informative",
    "title": "Chromatin accessibility I",
    "section": "Fragment size distributions are informative",
    "text": "Fragment size distributions are informative\nFirst, we will determine the fragment size distributions obtained from the two experiments. These sizes are the fingerprints of particles that were protecting nuclear DNA from digestion.\nI have performed the alignment of paired-end reads and converted all reads into a bed file where each line of the bed file denotes a single fragment from start to end.\nFirst, load the ATAC-seq reads. They’re in a BED file, so we’ll use what function from valr?\n\natac_tbl &lt;- read_???(\n  here(\"data/block-dna/yeast_atac_chrII.bed.gz\"),\n)\natac_tbl\n\nNext, load the MNase reads.\n\nmnase_tbl &lt;- read_???(\n  here(\"data/block-dna/yeast_mnase_chrII.bed.gz\")\n)\nmnase_tbl"
  },
  {
    "objectID": "exercises/ex-17.html#expectations-for-chromatin-fragment-lengths",
    "href": "exercises/ex-17.html#expectations-for-chromatin-fragment-lengths",
    "title": "Chromatin accessibility I",
    "section": "Expectations for chromatin fragment lengths",
    "text": "Expectations for chromatin fragment lengths\nLet’s remind ourselves of the expectations for chromatin fragment lengths from MNase-seq and ATAC-seq experiments.\nMNase-seq\n\nATAC-seq"
  },
  {
    "objectID": "exercises/ex-17.html#length-distributions-of-chromatin-derived-dna-fragments",
    "href": "exercises/ex-17.html#length-distributions-of-chromatin-derived-dna-fragments",
    "title": "Chromatin accessibility I",
    "section": "Length distributions of chromatin-derived DNA fragments",
    "text": "Length distributions of chromatin-derived DNA fragments\nFor the MNase-seq BED file, you see that there are only three columns: chrom, start, and end. How do we calculate fragment length?\n\nmutate(mnase_tbl, frag_len = ___ - ___)\n\nLet’s use this approach to examine the fragment length distribution. First, we’ll combine all the MNase and ATAC data into one tibble.\n\nacc_tbl &lt;-\n  bind_rows(\n    mutate(mnase_tbl, type = \"mnase\"),\n    mutate(atac_tbl, type = \"atac\")\n  )\n\nNext, we’ll make a histogram and facet by the type we defined above.\n\nggplot(\n  acc_tbl,\n  # define the x-axis as fragment length\n  aes(x = ___ - ___)\n) +\n  geom_histogram(\n    # how to define single base-pair resolution?\n    # ?geom_histogram\n    ___ = 1\n  ) +\n  facet_grid(\n    rows = vars(type),\n    scales = \"free_y\"\n  ) +\n  xlim(30, 500) +\n  labs(\n    x = \"fragment length (bp)\",\n    title = \"Histogram of fragment lengths from\\naccessibility measurements\"\n  ) +\n  theme_cowplot()\n\nInterpretations\n\nHow would you describe the two fragment length distributions? Are they similar?\nCan you make any biological conclusions based on the length distributions?"
  },
  {
    "objectID": "exercises/ex-17.html#periodicity-in-the-fragment-lengths",
    "href": "exercises/ex-17.html#periodicity-in-the-fragment-lengths",
    "title": "Chromatin accessibility I",
    "section": "Periodicity in the fragment lengths",
    "text": "Periodicity in the fragment lengths\nThe ATAC data seems to be periodic. How can we test that hypothesis? We can calculate the autocorrelation of the length distribution. Can someone explain what autocorrelation means?\nLet’s write a function to calculate densities of the above histogram.\n\nfragment_len_density &lt;- function(tbl) {\n    mutate(\n      tbl,\n      frag_len = end - start\n    ) |&gt;\n    filter(\n      frag_len &gt;= 30 &\n        frag_len &lt;= 500\n    ) |&gt;\n    count(frag_len) |&gt;\n    # now, calculate weighted counts\n    mutate(___ = ___ / ___) |&gt;\n    pull(___)\n}\n\nNow let’s use that function to calculate the density of ATAC fragment lengths.\n\natac_frag_len_density &lt;- fragment_len_density(atac_tbl)\n\nWe now have a vector of densities of fragment lengths at base-pair resolution. We will use acf() to calculate the autocorrelation of these values and store the tidied result.\n\natac_acf_tbl &lt;-\n  ___(\n    atac_frag_len_density,\n    lag.max = 40,\n    plot = FALSE\n  ) |&gt;\n  broom::tidy()\n\natac_acf_tbl\n\nNow let’s plot the autocorrelation.\n\nplot_acf &lt;- function(tbl, title) {\n  ggplot(\n    tbl,\n    aes(lag, acf)\n  ) +\n    geom_point(size = 2) +\n    geom_line() +\n    theme_minimal_grid() +\n    labs(title = title)\n}\n\n\nplot_atac_acf &lt;- plot_acf(atac_acf_tbl, title = \"ATAC ACF\")\nplot_atac_acf\n\nLet’s add lines to annotate where we think the inflection points are.\n\n# add vertical lines to the plot\natac_acf_tbl + geom_???(xintercept = c(___, ___), colo = \"red\")\n\nLet’s also compare this to the MNase data, which doesn’t seem to have the same pattern.\n\nmnase_frag_len_density &lt;-\n  fragment_len_density(mnase_tbl)\n\nmnase_acf_tbl &lt;-\n  acf(\n    mnase_frag_len_density,\n    lag.max = 40,\n    plot = FALSE\n  ) |&gt;\n  broom::tidy()\n\nplot_mnase_acf &lt;- plot_acf(mnase_acf_tbl, title = \"MNase ACF\")\n\n# patchwork plot\nplot_atac_acf + plot_mnase_acf\n\nWe can see a monotonic decrease in the MNase-seq data, which confirms that the bumps we see are distinctive features of ATAC-seq data.\nWhat are these features? Consider that the specificity of binding of DNase, MNase, and Tn5 is not completely generic. These enzymes have specificity for the minor groove of DNA, and there is an optimal substrate geometry for cleavage. You can see this in previous studies, where DNase-seq revealed high-resolution views of DNA:protein structures.\nSo what then, exactly is the ~10-11 bp periodicity? And why is this not present in MNase data?"
  },
  {
    "objectID": "exercises/ex-17.html#visualize-read-density-in-genomic-regions",
    "href": "exercises/ex-17.html#visualize-read-density-in-genomic-regions",
    "title": "Chromatin accessibility I",
    "section": "Visualize read density in genomic regions",
    "text": "Visualize read density in genomic regions\nWe will use Gviz to visualize read densities relative to a reference sequence.\nLoad tracks\nFirst, we load the gene annotations from the Saccharomyces Genome Databases (SGD).\n\ntrack_start &lt;- 530000\ntrack_end &lt;- 540000\n\nsgd_genes &lt;-\n  GeneRegionTrack(\n    TxDb.Scerevisiae.UCSC.sacCer3.sgdGene,\n    chromosome = \"chrII\",\n    start = track_start,\n    end = track_end,\n  )\n\nsgd_genes\n\nGeneRegionTrack 'GeneRegionTrack'\n| genome: sacCer3\n| active chromosome: chrII\n| annotation features: 8\n\n\nNext, import the bigwig file containing yeast nucleosome-sized fragments (via MNase-seq) using rtracklayer::import.bw().\nInspect the object. What is “GRanges”?\n\nmnase_nuc_gr &lt;- import.bw(\n  here(\"data/block-dna/yeast_mnase_134_160.bw\"),\n  as = \"GRanges\"\n)\nmnase_nuc_gr\n\nGRanges object with 81160 ranges and 1 metadata column:\n          seqnames        ranges strand |     score\n             &lt;Rle&gt;     &lt;IRanges&gt;  &lt;Rle&gt; | &lt;numeric&gt;\n      [1]    chrII         10-19      * |   3.81086\n      [2]    chrII         20-29      * |   3.81086\n      [3]    chrII         30-39      * |   5.71629\n      [4]    chrII         40-49      * |   5.71629\n      [5]    chrII         50-59      * |   5.71629\n      ...      ...           ...    ... .       ...\n  [81156]    chrII 813130-813139      * |  15.24344\n  [81157]    chrII 813140-813149      * |   7.62172\n  [81158]    chrII 813150-813159      * |   7.62172\n  [81159]    chrII 813160-813169      * |   7.62172\n  [81160]    chrII 813170-813179      * |   5.71629\n  -------\n  seqinfo: 1 sequence from an unspecified genome\n\n\nNext, load the GRanges object as a track for Gviz to plot:\n\nmnase_nuc_trk &lt;- DataTrack(\n  mnase_nuc_gr,\n  name = \"MNase_nuc\"\n)\nmnase_nuc_trk\n\nDataTrack 'MNase_nuc'\n| genome: NA\n| active chromosome: chrII\n| positions: 81160\n| samples:1\n| strand: * \n\n\nNow, we can make a plot for this particular region of chrII:\n\n# special track for the x-axis\nx_axis &lt;- GenomeAxisTrack()\n\nplotTracks(\n  c(\n    sgd_genes,\n    mnase_nuc_trk,\n    x_axis\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)"
  },
  {
    "objectID": "exercises/ex-17.html#load-the-remaining-data",
    "href": "exercises/ex-17.html#load-the-remaining-data",
    "title": "Chromatin accessibility I",
    "section": "Load the remaining data",
    "text": "Load the remaining data\nThat looks great! Let’s load all the other data sets.\n\nLoad each bigWig as a GRanges object with rtracklayer::import.bw()\n\nConvert each to a Gviz::DataTrack() for plotting\n\nWe can do this one of two ways. We can do it one-by-one:\n\n# complete the following steps for each of the four tracks\nfile_name &lt;- \"yeast_mnase_lt50.bw\"\ntrack_name &lt;- \"MNase_Short\"\nbig_wig &lt;- import.bw(here(\"data/block-dna\", file_name))\ndata_track &lt;- DataTrack(big_wig, track_name)\n\nOr we can create a tibble with file and track names, and use purrr to load and convert each one. First, we make a tibble containing file names and paths.\n\ntrack_info &lt;-\n  tibble(\n    file_name = c(\n      \"yeast_mnase_lt50.bw\",\n      \"yeast_mnase_134_160.bw\",\n      \"yeast_atac_lt120.bw\",\n      \"yeast_atac_gt120.bw\"\n    ),\n    file_path = here(\"data/block-dna\", file_name),\n    track_name = c(\n      \"MNase_Short\", \"MNase_Long\",\n      \"ATAC_Short\", \"ATAC_Long\"\n    )\n  )\n\nThen, we use purrr::map to “map” the import.bw() function onto each item in the file_path column, then then convert each of the results into a DataTrack.\n\ntrack_info &lt;-\n  mutate(\n    track_info,\n    big_wig = purrr::map(\n      file_path, ~ import.bw(.x, as = \"GRanges\")\n    ),\n    data_track = purrr::map2(\n      big_wig, track_name, ~ DataTrack(.x, name = .y)\n    )\n  )\n\nNow, we just have to make a list of tracks to plot and Gviz takes care of the rest.\n\nplotTracks(\n  c(\n    sgd_genes,\n    track_info$data_track\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)"
  },
  {
    "objectID": "exercises/ex-17.html#interpretations-1",
    "href": "exercises/ex-17.html#interpretations-1",
    "title": "Chromatin accessibility I",
    "section": "Interpretations",
    "text": "Interpretations\nRecall this plot:\n\nSome questions to think about as you look at the tracks:\n\nWhat is each data set reporting on?\nWhat are the major differences between MNase-seq and ATAC-seq based on these tracks?\nWhat can you infer about gene regulation based on these tracks?"
  },
  {
    "objectID": "exercises/ex-17.html#homework",
    "href": "exercises/ex-17.html#homework",
    "title": "Chromatin accessibility I",
    "section": "Homework",
    "text": "Homework\nYour homework tonight is to review the material from today. We’ll build on these concepts on Friday, and your problem set will integrate all of these concepts.\nIn particular, you should think a little about what the peaks are in the MNase-seq plot are that appear between ~90-120 bp. Consider the chromatin state at a model gene. What types of chromatin transitions occur during gene expression that might generate these kinds of particles? We’ll talk more about this on Friday."
  },
  {
    "objectID": "exercises/ex-15.html",
    "href": "exercises/ex-15.html",
    "title": "Stats Bootcamp - class 15",
    "section": "",
    "text": "Types of error and multiple test corrections\nExploratory data analysis\nClustering and overlaps"
  },
  {
    "objectID": "exercises/ex-15.html#learning-objectives",
    "href": "exercises/ex-15.html#learning-objectives",
    "title": "Stats Bootcamp - class 15",
    "section": "",
    "text": "Types of error and multiple test corrections\nExploratory data analysis\nClustering and overlaps"
  },
  {
    "objectID": "exercises/ex-15.html#types-i-and-ii-error",
    "href": "exercises/ex-15.html#types-i-and-ii-error",
    "title": "Stats Bootcamp - class 15",
    "section": "Types I and II error",
    "text": "Types I and II error\nFalse positives and False negatives\n\n\\(\\alpha\\) - significance level OR evidentiary standard\n\\(\\beta\\) - type II error rate, 1 - \\(\\beta\\) is power"
  },
  {
    "objectID": "exercises/ex-15.html#different-visualization",
    "href": "exercises/ex-15.html#different-visualization",
    "title": "Stats Bootcamp - class 15",
    "section": "Different visualization",
    "text": "Different visualization\nPower vs Significance"
  },
  {
    "objectID": "exercises/ex-15.html#genomics---lots-of-data---lots-of-hypothesis-tests",
    "href": "exercises/ex-15.html#genomics---lots-of-data---lots-of-hypothesis-tests",
    "title": "Stats Bootcamp - class 15",
    "section": "Genomics -> Lots of Data -> Lots of Hypothesis Tests",
    "text": "Genomics -&gt; Lots of Data -&gt; Lots of Hypothesis Tests\nIn a typical RNA-seq experiment, we test ~10K different hypotheses. For example, you have 10K genes and for each gene you test whether the mean expression changed in condition A vs condition B. Using a standard p-value cut-off of 0.05, we’d expect 500 genes to be deemed “significant” by chance. Thus, we are very concerned about False Positives or Type I Errors."
  },
  {
    "objectID": "exercises/ex-15.html#multiple-test-corrections",
    "href": "exercises/ex-15.html#multiple-test-corrections",
    "title": "Stats Bootcamp - class 15",
    "section": "Multiple test corrections",
    "text": "Multiple test corrections\n\nControl overall  (also known as family-wise error rate or FWER), which will affect the * for each test. That is, we are controlling the overall probability of making at least one false discovery. Bonferroni and Sidak corrections all control FWER.\nControl false discovery rate (FDR). These procedures allow for type 1 errors (false positives) but control the proportion of these false positives in relation to true positives. This is done by adjusting the decision made for the p-value associated with each individual test to decide rejection or not. Because this will result in a higher type 1 error rate, it has higher power. This affords a higher probability of true discoveries. The step procedures control for FDR."
  },
  {
    "objectID": "exercises/ex-15.html#bonferroni-correction",
    "href": "exercises/ex-15.html#bonferroni-correction",
    "title": "Stats Bootcamp - class 15",
    "section": "Bonferroni Correction",
    "text": "Bonferroni Correction\nThe most conservative of corrections, the Bonferroni correction is also perhaps the most straightforward in its approach. Simply divide  by the number of tests (m).\n\n = /m\n\nHowever, with many tests,  will become very small. This reduces power, which means that we are very unlikely to make any true discoveries.\nSidak Correction\n\n = 1-(1-)^(1/m)"
  },
  {
    "objectID": "exercises/ex-15.html#holms-step-down-procedure",
    "href": "exercises/ex-15.html#holms-step-down-procedure",
    "title": "Stats Bootcamp - class 15",
    "section": "Holm’s Step-Down Procedure",
    "text": "Holm’s Step-Down Procedure\nThe Holm-Bonferroni method is also fairly simple to calculate, but it is more powerful than the single-step Bonferroni.\n\\(HB = \\displaystyle \\frac {target \\alpha}{n - rank + 1}\\)\nH1: 0.005\nH2: 0.01\nH3: 0.03\nH4: = 0.04\nStep 1: Order the p-values from smallest to greatest (already done)\nStep 2: Calc HB for the first rank HB = .05 / 4 – 1 + 1 = .05 / 4 = .0125 H1: 0.005 &lt; .0125, so we reject the null\nStep 4: Repeat the HB formula for the second rank and keep going until we find \\(H{_N}\\) &gt; \\(HB{_N}\\). All subsequent hypotheses are non-significant (i.e. not rejected)."
  },
  {
    "objectID": "exercises/ex-15.html#hochbergs-step-up-procedure",
    "href": "exercises/ex-15.html#hochbergs-step-up-procedure",
    "title": "Stats Bootcamp - class 15",
    "section": "Hochberg’s Step-Up Procedure",
    "text": "Hochberg’s Step-Up Procedure\nMore powerful than Holm’s step-down procedure, Hochberg’s step-up procedure also seeks to control the FDR and follows a similar process, only p-values are ranked from largest to smallest.\nFor each ranked p-value, it is compared to the  calculated for its respective rank (same formula as Holm’s procedure). Testing continues until you reach the first non-rejected hypothesis. You would then fail to reject all following hypotheses."
  },
  {
    "objectID": "exercises/ex-15.html#example",
    "href": "exercises/ex-15.html#example",
    "title": "Stats Bootcamp - class 15",
    "section": "Example",
    "text": "Example\n\nrna &lt;- read_csv(here(\"data/data_rna_protein.csv.gz\")) |&gt;select(iDUX4_pval)\n\n\nrna$fdr &lt;- p.adjust(p = ??, method = \"fdr\", n = nrow(rna))\n\nrna$BH &lt;- p.adjust(p = rna$iDUX4_pval, method = \"BH\", n = nrow(rna))\n\nrna$bon &lt;- p.adjust(p = rna$iDUX4_pval, method = \"bonferroni\", n = nrow(rna))\n\n\nrna_long &lt;- rna |&gt;pivot_longer(cols = iDUX4_pval:bon, names_to = \"type\") \n\n\n\nggplot(data = rna_long, aes(x=value, fill = type)) +\n  geom_histogram(bins = 50) +\n  facet_wrap(~type) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#exploratory-data-analysis-eda",
    "href": "exercises/ex-15.html#exploratory-data-analysis-eda",
    "title": "Stats Bootcamp - class 15",
    "section": "Exploratory data analysis (EDA)",
    "text": "Exploratory data analysis (EDA)\nOur goal here is to get an top-down big picture of the similarity/differences between variables in a dataset. For example, let’s say you do RNA-seq in triplicate on 4 treatment/developmental times.\nPCA\nWe will perform PCA on all of the samples and visualize the relationship between samples.\nCorrelation matrix\nWe will perform hierarchical clustering on a matrix representing the pairwise correlation between all these samples."
  },
  {
    "objectID": "exercises/ex-15.html#explore-data",
    "href": "exercises/ex-15.html#explore-data",
    "title": "Stats Bootcamp - class 15",
    "section": "Explore data",
    "text": "Explore data\nIs it normal-ish?\n\n# get dux targets\ndux_targets &lt;- read_csv(file = here(\"data\",\"target_genes.csv.gz\"))\n\n# get expression data\nd &lt;- read_tsv(here(\"data\",\"data_genelevel.tsv.gz\")) |&gt;\n  mutate(target = case_when(\n    gene_symbol %in% dux_targets$hgnc_symbol ~ \"target\",\n    TRUE ~ \"not_target\")\n         ) |&gt;\n  filter(gene_symbol!=\"ISCA1\") |&gt;\n  drop_na()\n\n\nd |&gt;\n  pivot_longer(cols = hour00_rep1:hour14_rep3) |&gt; \n  ggplot(aes(x=value, color=name)) +\n  ??() +\n  theme_cowplot()\n\n. . .\nDefinitely not normal"
  },
  {
    "objectID": "exercises/ex-15.html#data-transformations",
    "href": "exercises/ex-15.html#data-transformations",
    "title": "Stats Bootcamp - class 15",
    "section": "Data transformations",
    "text": "Data transformations\nWe often transform data to make it closer to being normally-distributed. This allows us to use more powerful statistical tests on the same data. One approach is to log-transform the data.\n\nd |&gt;\n  pivot_longer(cols = hour00_rep1:hour14_rep3) |&gt; \n  ggplot(aes(x=??(value), color=name)) +\n  geom_density() +\n  theme_cowplot()\n\n. . .\nWhat is this?\n\nWarning message: Removed 1251 rows containing non-finite values (stat_density())."
  },
  {
    "objectID": "exercises/ex-15.html#pseudocounts",
    "href": "exercises/ex-15.html#pseudocounts",
    "title": "Stats Bootcamp - class 15",
    "section": "Pseudocounts",
    "text": "Pseudocounts\n\\(log_{x}(0)\\) is a common problem. One solution is to add a pseudocount. Since this is read count data, the smallest unit is 1 and so we will add 1 to all the observations before perforing the log transformation. \\(1\\) represents the pseudocount in this case.\n\nd |&gt;\n  pivot_longer(cols = hour00_rep1:hour14_rep3) |&gt; \n  ggplot(aes(x=??(value), color=name)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#correlation-analysis",
    "href": "exercises/ex-15.html#correlation-analysis",
    "title": "Stats Bootcamp - class 15",
    "section": "correlation analysis",
    "text": "correlation analysis\nprepare the data for analysis\n\n# pull counts\nx &lt;-  d |&gt;\n  select_if(is.numeric) |&gt;# keep only the numeric columns\n  mutate_all(funs(log2(1 + .))) |&gt;# log2 transform\n  as.matrix() # matrix\n\nrownames(x) &lt;- d$gene_symbol\n\nx &lt;- t(scale(t(x))) # scale\n\n# pairwise pearson correlation\np &lt;- ???\n\n# heatmap\npheatmap(\n  mat = p,\n  clustering_distance_rows = \"??\",\n  clustering_distance_cols = \"??\",\n  clustering_method = \"??\"\n)"
  },
  {
    "objectID": "exercises/ex-15.html#pca-1",
    "href": "exercises/ex-15.html#pca-1",
    "title": "Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\nPCA is a common dimensionality reduction method that is used to visualize the similarity and differences in your data.\nLet’s watch this fantastic 5 minute video explaining PCA\n\nFor more detailed explanations go here and here."
  },
  {
    "objectID": "exercises/ex-15.html#pca-2",
    "href": "exercises/ex-15.html#pca-2",
    "title": "Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\n\n# pairwise pearson correlation\npc &lt;- \n\nsummary(pc) # summarize the PCs by variance"
  },
  {
    "objectID": "exercises/ex-15.html#pca---prepare-visualization",
    "href": "exercises/ex-15.html#pca---prepare-visualization",
    "title": "Stats Bootcamp - class 15",
    "section": "PCA - prepare visualization",
    "text": "PCA - prepare visualization\n\n# create a dataframe with the importance/explanation of variation for each PC\npca_data_info &lt;- summary(pc)$importance |&gt;as.data.frame()\n\npca_data_info &lt;- round(x = pca_data_info, digits = 3)\n\n# we make a dataframe out of the rotations and will use this to plot\npca_plot_data &lt;- pc$rotation |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ID\") |&gt;\n  separate(\n    ID,\n    into = c(\"time\",\"rep\"),\n    sep = \"_\"\n  )\n\n# recode \"rep\"\npca_plot_data$rep &lt;- recode(\n  pca_plot_data$rep,\n  rep1 = \"A\",\n  rep2 = \"B\",\n  rep3 = \"C\"\n)\n\n# gsub hour\npca_plot_data$time &lt;- gsub(\n  pattern = \"hour\",\n  replacement = \"\",\n  x = pca_plot_data$time\n)\n\nggplot(\n  pca_plot_data, \n  aes(x=PC1, y = PC2, color=time)\n  ) + \n  geom_point() +\n  xlab(paste(\"PC1, %\",100 * pca_data_info[\"Proportion of Variance\",\"PC1\"])) +\n  ylab(paste(\"PC2, %\",100 * pca_data_info[\"Proportion of Variance\",\"PC2\"])) + \n  ggtitle(\"PCA for DUX4 timecourse\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#famous-pca-example",
    "href": "exercises/ex-15.html#famous-pca-example",
    "title": "Stats Bootcamp - class 15",
    "section": "Famous PCA example",
    "text": "Famous PCA example\nUsing gene expression as your measurement, do you think the mouse liver is more similar to a mouse heart or a human liver?\nThe Mouse ENCODE Consortium reported that comparative gene expression data from human and mouse tend to cluster more by species rather than by tissue.\n\nA comparative encyclopedia of DNA elements in the mouse genome\nComparison of the transcriptional landscapes between human and mouse tissues"
  },
  {
    "objectID": "exercises/ex-15.html#some-found-this-hard-to-believe",
    "href": "exercises/ex-15.html#some-found-this-hard-to-believe",
    "title": "Stats Bootcamp - class 15",
    "section": "Some found this hard to believe",
    "text": "Some found this hard to believe\nYoav Gilad’s lab recapitulated the initial result:\n\nThis observation was surprising, as it contradicted much of the comparative gene regulatory data collected previously, as well as the common notion that major developmental pathways are highly conserved across a wide range of species, in particular across mammals."
  },
  {
    "objectID": "exercises/ex-15.html#careful-with-batch-effects",
    "href": "exercises/ex-15.html#careful-with-batch-effects",
    "title": "Stats Bootcamp - class 15",
    "section": "Careful with batch effects",
    "text": "Careful with batch effects\nBut noticed something funny about which samples were sequenced on the same lanes."
  },
  {
    "objectID": "exercises/ex-15.html#accounting-for-batch-effects",
    "href": "exercises/ex-15.html#accounting-for-batch-effects",
    "title": "Stats Bootcamp - class 15",
    "section": "Accounting for batch effects",
    "text": "Accounting for batch effects\n\nHere we show that the Mouse ENCODE gene expression data were collected using a flawed study design, which confounded sequencing batch (namely, the assignment of samples to sequencing flowcells and lanes) with species. When we account for the batch effect, the corrected comparative gene expression data from human and mouse tend to cluster by tissue, not by species."
  },
  {
    "objectID": "exercises/ex-15.html#k-means-clustering-to-look-for-patterns",
    "href": "exercises/ex-15.html#k-means-clustering-to-look-for-patterns",
    "title": "Stats Bootcamp - class 15",
    "section": "K-means clustering to look for patterns",
    "text": "K-means clustering to look for patterns\nGoal: to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. –Wiki\nK-means"
  },
  {
    "objectID": "exercises/ex-15.html#k-means-data-preparation",
    "href": "exercises/ex-15.html#k-means-data-preparation",
    "title": "Stats Bootcamp - class 15",
    "section": "K-Means data preparation",
    "text": "K-Means data preparation\n\nRows are observations (individuals) and columns are variables\nAny missing value in the data must be removed or estimated.\nThe data must be standardized (i.e., scaled) to make variables comparable."
  },
  {
    "objectID": "exercises/ex-15.html#scaling-or-z-score",
    "href": "exercises/ex-15.html#scaling-or-z-score",
    "title": "Stats Bootcamp - class 15",
    "section": "Scaling or z-score",
    "text": "Scaling or z-score\n{%20}\n\\(x\\) = observation\\(\\mu\\) = population mean\\(\\sigma\\) = population sd\nWe will be using this function on each row. This will allow comparison of relative changes across a row, for all rows."
  },
  {
    "objectID": "exercises/ex-15.html#k-means-clustering",
    "href": "exercises/ex-15.html#k-means-clustering",
    "title": "Stats Bootcamp - class 15",
    "section": "K-Means clustering",
    "text": "K-Means clustering\n\nComputing k-means clustering in R (pheatmap)\nDetermine appropriate cluster number\nAdd new column with cluster number to initial data"
  },
  {
    "objectID": "exercises/ex-15.html#how-do-we-figure-out-the-optimal-clusters",
    "href": "exercises/ex-15.html#how-do-we-figure-out-the-optimal-clusters",
    "title": "Stats Bootcamp - class 15",
    "section": "How do we figure out the optimal # clusters?",
    "text": "How do we figure out the optimal # clusters?\nThere are many methods, but we will stick with the “elbow” method.\nK-means is minimizing the total within cluster sum of squares (wss).\nWe pick the cluster where that drop in total reaches diminishing returns -&gt; the elbow."
  },
  {
    "objectID": "exercises/ex-15.html#lets-cluster-once-to-see",
    "href": "exercises/ex-15.html#lets-cluster-once-to-see",
    "title": "Stats Bootcamp - class 15",
    "section": "Let’s cluster once to see",
    "text": "Let’s cluster once to see\n\nset.seed(33)\ntmp &lt;- pheatmap(\n  mat = x,\n  clustering_distance_rows = \"euclidean\",\n  clustering_method = \"ward.D2\",\n  kmeans_k = ??,\n  cluster_cols = FALSE,\n  scale = \"none\"\n)\n\n\ntmp$kmeans$tot.withinss"
  },
  {
    "objectID": "exercises/ex-15.html#functions-in-r",
    "href": "exercises/ex-15.html#functions-in-r",
    "title": "Stats Bootcamp - class 15",
    "section": "Functions in R",
    "text": "Functions in R"
  },
  {
    "objectID": "exercises/ex-15.html#create-function-to-calculate-wss",
    "href": "exercises/ex-15.html#create-function-to-calculate-wss",
    "title": "Stats Bootcamp - class 15",
    "section": "Create function to calculate wss",
    "text": "Create function to calculate wss\n\nwss &lt;- function(knum) {\n  ph &lt;- pheatmap(\n    mat = x,\n    kmeans_k = ??,\n    scale = \"none\",\n    cluster_cols = FALSE,\n    clustering_distance_rows = \"euclidean\",\n    clustering_method = \"ward.D2\",\n    silent = TRUE\n  )\n  return(ph$kmeans$tot.withinss)\n}\n\nwss(6)"
  },
  {
    "objectID": "exercises/ex-15.html#find-the-elbow",
    "href": "exercises/ex-15.html#find-the-elbow",
    "title": "Stats Bootcamp - class 15",
    "section": "find the elbow",
    "text": "find the elbow\n\ntibble(wss=map_vec(2:15,wss),\n       k=2:15) |&gt;\n  ggplot(., aes(x=k, y=wss)) +\n  geom_point() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-15.html#final-clustering",
    "href": "exercises/ex-15.html#final-clustering",
    "title": "Stats Bootcamp - class 15",
    "section": "Final clustering",
    "text": "Final clustering\n\nset.seed(33)\nc &lt;- pheatmap(\n  mat = x,\n  clustering_distance_rows = \"euclidean\",\n  clustering_method = \"ward.D2\",\n  kmeans_k = 7,\n  cluster_cols = F,\n  scale = \"none\"\n)\n\ncg &lt;- tibble(\n  Cluster=c$kmeans$cluster,\n  gene_symbol=names(c$kmeans$cluster)\n)\n\ncd &lt;- left_join(d, cg, by=\"gene_symbol\")"
  },
  {
    "objectID": "exercises/ex-15.html#which-clusters-contains-dux4-targets",
    "href": "exercises/ex-15.html#which-clusters-contains-dux4-targets",
    "title": "Stats Bootcamp - class 15",
    "section": "Which cluster(s) contains DUX4 targets?",
    "text": "Which cluster(s) contains DUX4 targets?\nFisher’s Exact Test and the Hypergeometric Distribution\n\n# list of genes by dux4 targeting\nduxList &lt;- split(cd$gene_symbol, cd$??)\n\n# list of genes by clustering\nclustList &lt;- split(cd$gene_symbol, as.factor(cd$??))\n\n# calculate all overlaps between lists\ngom.duxclust &lt;- newGOM(??List,\n                       ??List,\n                       genome.size = ??)\n\n\ngetMatrix(gom.duxclust, \"pval\") |&gt;\n  t() |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"clust\") |&gt;\n  as.tibble() |&gt;\n  arrange(target)"
  },
  {
    "objectID": "exercises/ex-15.html#lets-calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "href": "exercises/ex-15.html#lets-calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "title": "Stats Bootcamp - class 15",
    "section": "Let’s calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling",
    "text": "Let’s calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling\nIn order to do this, you will need to:\n\nIdentify which cluster is the most enriched for DUX4 targets.\n\nDetermine how many genes are in the cluster. You will need to know this to figure out how many genes to sample from the whole data set.\nDetermine how many of the genes in the cluster are DUX4 targets. This is the metric that you are interested in comparing between the null distribution and your observation.\n\n\nGenerate 1000 random sample of the proper size from all genes and find out how many of them are DUX4 targets.\nVisualize the distribution of DUX4 targets in these 1000 random (your null distribution) and overlay the number of DUX4 targets you observed in the cluster that was most enriched for DUX4 targets."
  },
  {
    "objectID": "exercises/ex-13.html",
    "href": "exercises/ex-13.html",
    "title": "Stats Bootcamp - class 13",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt; \n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-13.html#prepare-mouse-biochem-data",
    "href": "exercises/ex-13.html#prepare-mouse-biochem-data",
    "title": "Stats Bootcamp - class 13",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt; \n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-13.html#association-between-mouse-weight-and-tot_cholesterol",
    "href": "exercises/ex-13.html#association-between-mouse-weight-and-tot_cholesterol",
    "title": "Stats Bootcamp - class 13",
    "section": "Association between mouse \\(weight\\) and \\(tot\\_cholesterol\\)\n",
    "text": "Association between mouse \\(weight\\) and \\(tot\\_cholesterol\\)\n\n\nggscatter()\n\nwe previously established these are normal enough &gt; \\(\\mathcal{H}_0\\) is no (linear) relationship between \\(tot\\_cholesterol\\) and \\(weight\\)\n\n\nb |&gt; \n  cor_test(??, ??,\n           method = \"??\"\n           )\n\nP value well below 0.05\n\n\\(\\mathcal{H}_0\\) is no relationship between \\(tot\\_cholesterol\\) and \\(weight\\) NOT WELL SUPPORTED\n\nSo there is a (linear) relationship between \\(tot\\_cholesterol\\) and \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-13.html#visualize-pearson-correlation",
    "href": "exercises/ex-13.html#visualize-pearson-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Visualize Pearson correlation",
    "text": "Visualize Pearson correlation\n\nggscatter(data = b,\n          y = \"weight\",\n          x = \"tot_cholesterol\"\n          ) + \n  stat_cor(method = \"pearson\",\n           label.x = 1,\n           label.y = 30)"
  },
  {
    "objectID": "exercises/ex-13.html#manual-calculation-of-pearson-correlation",
    "href": "exercises/ex-13.html#manual-calculation-of-pearson-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Manual calculation of Pearson correlation",
    "text": "Manual calculation of Pearson correlation\n\\(Corr(x,y) = \\displaystyle \\frac {\\sum_{i=1}^{n} (x_{i} - \\overline{x})(y_{i} - \\overline{y})}{\\sum_{i=1}^{n} \\sqrt(x_{i} - \\overline{x})^2 \\sqrt(y_{i} - \\overline{y})^2}\\)\n\n# mean total cholesterol\nm_chol &lt;- \n\n# average weight\nm_weight &lt;- \n\n# difference from mean total cholesterol\ndiff_chol &lt;- \n\n# difference from mean total weight\ndiff_weight &lt;-\n\n# follow formula above\nmanual_pearson &lt;- \n\nmanual_pearson"
  },
  {
    "objectID": "exercises/ex-13.html#spearman-correlation-nonparametric",
    "href": "exercises/ex-13.html#spearman-correlation-nonparametric",
    "title": "Stats Bootcamp - class 13",
    "section": "Spearman Correlation (nonparametric)",
    "text": "Spearman Correlation (nonparametric)\nSpearman’s rank correlation coefficientor Spearman’s ρ, named after Charles Spearman is a nonparametric measure of rank correlation (statistical dependence between the rankings of two variables). It assesses how well the relationship between two variables can be described using a monotonic function.\nMore info here.\n\nb |&gt; \n  cor_test(weight, tot_cholesterol,\n           method = \"??\"\n           )\n\nP value well below 0.05\n\n\\(\\mathcal{H}_0\\) is no relationship between \\(tot\\_cholesterol\\) and \\(weight\\) NOT WELL SUPPORTED"
  },
  {
    "objectID": "exercises/ex-13.html#visualize-spearman-correlation",
    "href": "exercises/ex-13.html#visualize-spearman-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Visualize Spearman correlation",
    "text": "Visualize Spearman correlation\n\nggscatter(data = b,\n          y = \"weight\",\n          x = \"tot_cholesterol\"\n          ) + \n  stat_cor(method = \"spearman\",\n           label.x = 1,\n           label.y = 30)"
  },
  {
    "objectID": "exercises/ex-13.html#lets-create-a-hypothetical-example",
    "href": "exercises/ex-13.html#lets-create-a-hypothetical-example",
    "title": "Stats Bootcamp - class 13",
    "section": "Let’s create a hypothetical example",
    "text": "Let’s create a hypothetical example\ncreate tibble \\(d\\) with variables \\(x\\) and \\(y\\)\n\\(x\\), 1:50\n\\(y\\), which is \\(x^{10}\\)\n\nd &lt;- tibble(\n  x=??,\n  y=??)\n\n. . .\nscatter plot\n\nggscatter(data = d,\n          x = \"x\",\n          y = \"y\")\n\n\nPearson\n\nd |&gt; \n  cor_test(x, y,\n           method = \"pearson\"\n           ) |&gt;\n  select(cor)\n\n. . .\nSpearman\n\nd |&gt; \n  cor_test(x, y,\n           method = \"spearman\"\n           ) |&gt;\n  select(cor)"
  },
  {
    "objectID": "exercises/ex-13.html#additional-examples-with-correlation",
    "href": "exercises/ex-13.html#additional-examples-with-correlation",
    "title": "Stats Bootcamp - class 13",
    "section": "Additional examples with correlation",
    "text": "Additional examples with correlation\ncompare 1 variable to all other quantitative variables\n\\(weight\\)\n\nb |&gt;\n  cor_test(??) |&gt;\n  gt()\n\nrelationship between \\(weight\\) and \\(tot\\_cholesterol\\) by \\(sex\\)\n\nb |&gt;\n\n  gt()"
  },
  {
    "objectID": "exercises/ex-13.html#appropriate-statistical-test-cheatsheet",
    "href": "exercises/ex-13.html#appropriate-statistical-test-cheatsheet",
    "title": "Stats Bootcamp - class 13",
    "section": "Appropriate statistical test cheatsheet",
    "text": "Appropriate statistical test cheatsheet"
  },
  {
    "objectID": "exercises/ex-13.html#regression",
    "href": "exercises/ex-13.html#regression",
    "title": "Stats Bootcamp - class 13",
    "section": "Regression",
    "text": "Regression\nWe are going to change our frame work to learn about regression. The nice thing is that everything we learn for regression is applicable to all the tests we just learned."
  },
  {
    "objectID": "exercises/ex-13.html#the-simplicity-underlying-common-tests",
    "href": "exercises/ex-13.html#the-simplicity-underlying-common-tests",
    "title": "Stats Bootcamp - class 13",
    "section": "The simplicity underlying common tests",
    "text": "The simplicity underlying common tests\nMost of the common statistical models (t-test, correlation, ANOVA; etc.) are special cases of linear models or a very close approximation. This simplicity means that there is less to learn. It all comes down to:\n\n\\(y = a \\cdot x + b\\)\n\nThis needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model."
  },
  {
    "objectID": "exercises/ex-13.html#equation-for-a-line",
    "href": "exercises/ex-13.html#equation-for-a-line",
    "title": "Stats Bootcamp - class 13",
    "section": "Equation for a line",
    "text": "Equation for a line\nRemember:\\(y = a \\cdot x + b\\)\nOR\\(y = b + a \\cdot x\\)\n\\(a\\) is the SLOPE (2) \\(b\\) is the y-intercept (1)\n\nd &lt;- tibble(x=c(-1,3),\n            y=c(-1,6)\n             )\n\nggplot(data=d, aes(x=x,y=y)) + \n  geom_blank() +\n  geom_abline(intercept = 1,\n              slope = 2,\n              col = \"red\") +\n  theme_linedraw()"
  },
  {
    "objectID": "exercises/ex-13.html#stats-equation-for-a-line",
    "href": "exercises/ex-13.html#stats-equation-for-a-line",
    "title": "Stats Bootcamp - class 13",
    "section": "Stats equation for a line",
    "text": "Stats equation for a line\nModel:\n\\(y\\) equals the intercept (\\(\\beta_0\\)) pluss a slope (\\(\\beta_1\\)) times \\(x\\).\n\\(y = \\beta_0 + \\beta_1 x \\qquad \\qquad \\mathcal{H}_0: \\beta_1 = 0\\)\n… which is the same as \\(y = b + a \\cdot x\\).\nThe short hand for this in R: y ~ 1 + x\nR interprets this as:\ny = 1*number + x*othernumber\nThe task of t-tests, lm, etc., is simply to find the numbers that best predict \\(y\\)."
  },
  {
    "objectID": "exercises/ex-13.html#stats-equation-for-a-line-1",
    "href": "exercises/ex-13.html#stats-equation-for-a-line-1",
    "title": "Stats Bootcamp - class 13",
    "section": "Stats equation for a line",
    "text": "Stats equation for a line\nAll you need is an intercept (\\(\\beta_0\\)) and a slope (\\(\\beta_1\\)) to get a line:\n\nggplot(data=d, aes(x=x,y=y)) + \n  geom_blank() +\n  geom_abline(intercept = 1,\n              slope = 2,\n              col = \"red\") +\n  theme_linedraw()\n\n\n\n\n\\(\\beta_0\\) = 1 (the y-intercept), \\(\\beta_1\\) = 2 (the slope)\n\\(y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x\\)\n\\(y = 1 \\cdot 1 + 2 \\cdot x\\)\n\\(y = 1 + 2x\\)\n\nOur mission: FIND THE BEST \\(\\beta\\) coefficients"
  },
  {
    "objectID": "exercises/ex-13.html#linear-regression",
    "href": "exercises/ex-13.html#linear-regression",
    "title": "Stats Bootcamp - class 13",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nSTEP 1: Make a scatter plot visualize the linear relationship between x and y.\nSTEP 2: Perform the regression\nSTEP 3: Look at the \\(R^2\\), \\(F\\)-value and \\(p\\)-value\nSTEP 4: Visualize fit and errors\nSTEP 5: Calculate \\(R^2\\), \\(F\\)-value and \\(p\\)-value ourselves"
  },
  {
    "objectID": "exercises/ex-13.html#step-1-can-mouse-cholesterol-levels-explain-mouse-weight",
    "href": "exercises/ex-13.html#step-1-can-mouse-cholesterol-levels-explain-mouse-weight",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 1: Can mouse cholesterol levels explain mouse weight?",
    "text": "STEP 1: Can mouse cholesterol levels explain mouse weight?\nPlot \\(weight\\) (y, response variable) and \\(tot_cholesterol\\) (x, explanatory variable)\n\nggplot(data = ??,\n       aes(y = ??,\n           x = ??)) +\n  geom_point(size=.5) +\n  scale_color_manual() +\n  theme_linedraw()"
  },
  {
    "objectID": "exercises/ex-13.html#step-2-do-the-regression",
    "href": "exercises/ex-13.html#step-2-do-the-regression",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 2: Do the regression",
    "text": "STEP 2: Do the regression\nKeep calm and fit a line! Remember: \\(y = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x\\)\nlinear model equation: \\(weight = \\beta_0 \\cdot 1 + \\beta_1 \\cdot tot\\_cholesterol\\)\n\n\\(\\mathcal{H}_0:\\) \\(tot\\_cholesterol\\) does NOT explain \\(weight\\) Null Hypothesis: \\(\\mathcal{H}_0: \\beta_1 = 0\\)\n\n\\(weight = \\beta_0 \\cdot 1 + 0 \\cdot tot\\_cholesterol\\) \\(weight = \\beta_0 \\cdot 1\\)\n\n\\(\\mathcal{H}_1:\\) Mouse \\(tot\\_cholesterol\\) does explain \\(weight\\)\n\n\\(weight = \\beta_0 \\cdot 1 + \\beta_1 \\cdot tot\\_cholesterol\\)\nThe cool thing here is that we can assess and compare our null and alternative hypothesis by learning and examining the model coefficients (namely the slope). Ultimately, we are comparing a complex model (with cholesterol) to a simple model (without cholesterol).\nhttps://statisticsbyjim.com/regression/interpret-constant-y-intercept-regression/"
  },
  {
    "objectID": "exercises/ex-13.html#step-4-look-at-the-r2-f-value-and-p-value",
    "href": "exercises/ex-13.html#step-4-look-at-the-r2-f-value-and-p-value",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 4: Look at the \\(R^2\\), \\(F\\)-value and \\(p\\)-value",
    "text": "STEP 4: Look at the \\(R^2\\), \\(F\\)-value and \\(p\\)-value\n\n# fitting a line\nfit_WvC &lt;- lm(\n  data = ??,\n  formula = ??)\n\n\n# base R summary of fit\nsummary(fit_WvC)\n\nThat’s a lot of info, but how would I access it? Time to meet your new best friend:\nBroom"
  },
  {
    "objectID": "exercises/ex-13.html#tidying-output",
    "href": "exercises/ex-13.html#tidying-output",
    "title": "Stats Bootcamp - class 13",
    "section": "Tidying output",
    "text": "Tidying output\ninformation about the model fit\n\n??(fit_WvC) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\ninformation about the intercept and coefficients\n\n??(fit_WvC)|&gt;\n  gt() |&gt;\n  fmt_number(columns =estimate:statistic, decimals = 3)\n\nsave the intercept and slope into variable to use later\n\nchol_intercept &lt;- \n\nchol_slope &lt;- \n\n\n\nfor every 1 unit increase in cholesterol there is a 1.85 unit increase weight\n\n\nggplot(data = b,\n       aes(y = weight,\n           x = tot_cholesterol)) +\n  geom_smooth(method = \"lm\") +\n  geom_point(size=.5) +\n  scale_color_manual() +\n  theme_linedraw()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "exercises/ex-13.html#collecting-residuals-and-other-information",
    "href": "exercises/ex-13.html#collecting-residuals-and-other-information",
    "title": "Stats Bootcamp - class 13",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\nb_WvC &lt;- ??(fit_WvC, data = b)\n\nb_WvC"
  },
  {
    "objectID": "exercises/ex-13.html#what-are-residuals",
    "href": "exercises/ex-13.html#what-are-residuals",
    "title": "Stats Bootcamp - class 13",
    "section": "What are Residuals\n",
    "text": "What are Residuals\n\nResiduals, \\(e\\) — the difference between the observed value of the response variable \\(y\\) and the explanatory value \\(\\widehat{y}\\) is called the residual. Each data point has one residual. Specifically, it is the distance on the y-axis between the observed \\(y_{i}\\) and the fit line.\n\\(e = y_{i} - \\widehat{y}\\)\nResiduals with large absolute values indicate the data point is NOT well explained by the model."
  },
  {
    "objectID": "exercises/ex-13.html#step-5-visualize-fit-and-errors",
    "href": "exercises/ex-13.html#step-5-visualize-fit-and-errors",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 5: Visualize fit and errors",
    "text": "STEP 5: Visualize fit and errors\nVisualize the residuals OR the error around the fit\n\nggplot(data = b_WvC,\n       aes(x = tot_cholesterol, y = weight)) +\n  geom_point(size=1, aes(color = .resid)) + \n  geom_abline(intercept = pull(chol_intercept),\n              slope = pull(chol_slope),\n              col = \"red\") +\n  scale_color_gradient2(low = \"blue\", \n                        mid = \"black\",\n                        high = \"yellow\") + \n  geom_segment(aes(xend = tot_cholesterol,\n                   yend = .fitted),\n               alpha = .1) + # plot line representing residuals\n  theme_linedraw() \n\n\nVisualize the total error OR the error around the null. So no cholesterol fit, just the mean of y.\n\navg_weight &lt;- mean(b_WvC$weight)"
  },
  {
    "objectID": "exercises/ex-13.html#step-6-calculate-r2-f-value-p-value-ourselves",
    "href": "exercises/ex-13.html#step-6-calculate-r2-f-value-p-value-ourselves",
    "title": "Stats Bootcamp - class 13",
    "section": "STEP 6: Calculate \\(R^2\\), \\(F\\)-value, \\(p\\)-value ourselves",
    "text": "STEP 6: Calculate \\(R^2\\), \\(F\\)-value, \\(p\\)-value ourselves"
  },
  {
    "objectID": "exercises/ex-13.html#what-is-r2",
    "href": "exercises/ex-13.html#what-is-r2",
    "title": "Stats Bootcamp - class 13",
    "section": "What is \\(R^2\\)\n",
    "text": "What is \\(R^2\\)\n\n\\(R^2\\) — the coefficient of determination, which is the proportion of the variance in the response variable that is predictable from the explanatory variable(s).\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\\(SS_{fit}\\) — sum of squared errors around the least-squares fit\n\\(SS_{fit} = \\sum_{i=1}^{n} (data - line)^2 = \\sum_{i=1}^{n} (y_{i} - (\\beta_0 \\cdot 1+ \\beta_1 \\cdot x)^2\\)\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\\(SS_{null} = \\sum_{i=1}^{n} (data - mean)^2 = \\sum_{i=1}^{n} (y_{i} - \\overline{y})^2\\)"
  },
  {
    "objectID": "exercises/ex-13.html#calculate-r2",
    "href": "exercises/ex-13.html#calculate-r2",
    "title": "Stats Bootcamp - class 13",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\\(SS_{fit}\\) — sum of squared errors around the least-squares fit\n\nss_fit &lt;- ??\nss_fit\n\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\nss_null &lt;- ??\nss_null \n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\nrsq &lt;- 1- ??\n\nglance(fit_WvC) |&gt; select(r.squared)\n\n. . .\nBTW this is the same \\(R\\) as from the Pearson correlation, just squared:\n\nb |&gt; \n  cor_test(weight,tot_cholesterol,\n           method = \"pearson\") |&gt;\n  mutate(r2 = cor^2) |&gt;\n  pull(r2) |&gt;\n  round(2)"
  },
  {
    "objectID": "exercises/ex-13.html#interpret-r2",
    "href": "exercises/ex-13.html#interpret-r2",
    "title": "Stats Bootcamp - class 13",
    "section": "Interpret \\(R^2\\)\n",
    "text": "Interpret \\(R^2\\)\n\nThere is a 13 % reduction in the variance when we take mouse \\(cholesterol\\) into account\nOR\\(cholesterol\\) explains 13% of variation in mouse \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-13.html#what-is-the-f-statistic",
    "href": "exercises/ex-13.html#what-is-the-f-statistic",
    "title": "Stats Bootcamp - class 13",
    "section": "What is the F-statistic\n",
    "text": "What is the F-statistic\n\nF-statistic — based on the ratio of two variances: the explained variance (due to the model) and the unexplained variance (residuals).\n\\(F = \\displaystyle \\frac{SS_{fit}/(p_{fit}-p_{null})} {SS_{null}/(n-p_{fit})}\\)\n\\(p_{fit}\\) — number of parameters (coefficients) in the fit line\n\\(p_{null}\\) — number of parameters (coefficients) in the mean line\n\\(n\\) — number of data points"
  },
  {
    "objectID": "exercises/ex-13.html#calculate-the-f-statistic",
    "href": "exercises/ex-13.html#calculate-the-f-statistic",
    "title": "Stats Bootcamp - class 13",
    "section": "Calculate the F-statistic\n",
    "text": "Calculate the F-statistic\n\n\\(F = \\displaystyle \\frac{SS_{null} - SS_{fit}/(p_{fit}-p_{null})} {SS_{fit}/(n-p_{fit})}\\)\n\npfit &lt;- ??\npnull &lt;- ??\nn &lt;- ??\n\nf &lt;- ??\n\n\nf\n\nglance(fit_WvC) |&gt; select(statistic)"
  },
  {
    "objectID": "exercises/ex-13.html#p-values",
    "href": "exercises/ex-13.html#p-values",
    "title": "Stats Bootcamp - class 13",
    "section": "P-values",
    "text": "P-values\nYou don’t really need to know what the \\(F-statistic\\) is unless you want to calculate the p-value. In this case we need to generate a null distribution of \\(F-statistic\\) values to compare to our observed \\(F-statistic\\).\nTherefore, we will randomize the \\(tot_cholesterol\\) and \\(weight\\) and then calculate the \\(F-statistic\\).\n\n\nWe will do this many many times to generate a null distribution of \\(F-statistic\\)s.\n\nThe p-value will be the probability of obtaining an \\(F-statistic\\) in the null distribution at least as extreme as our observed \\(F-statistic\\)."
  },
  {
    "objectID": "exercises/ex-13.html#lets-get-started",
    "href": "exercises/ex-13.html#lets-get-started",
    "title": "Stats Bootcamp - class 13",
    "section": "Let’s get started",
    "text": "Let’s get started\n\n# set up an empty tibble to hold our null distribution\nfake_biochem &lt;- tribble()\n\n# we will perform 100 permutations\nmyPerms &lt;- 100\n\nfor (i in 1:myPerms) {\n  tmp &lt;- bind_cols(\n    b_WvC[sample(nrow(b_WvC)), \"weight\"],\n    b_WvC[sample(nrow(b_WvC)),\"tot_cholesterol\"],\n    \"perm\"=factor(rep(i,nrow(b_WvC)))\n    )\n\n  fake_biochem &lt;- bind_rows(fake_biochem,tmp)\n  rm(tmp)\n\n}\n\n\n# let's look at permutations 1 and 2\nggplot(fake_biochem |&gt; filter(perm %in% c(1:2)), aes(x=weight, y=tot_cholesterol, color=perm)) +\n  geom_point(size=.1) +\n  theme_minimal()"
  },
  {
    "objectID": "exercises/ex-13.html#run-100-linear-models",
    "href": "exercises/ex-13.html#run-100-linear-models",
    "title": "Stats Bootcamp - class 13",
    "section": "Run 100 linear models!",
    "text": "Run 100 linear models!\nNow we will calculate and extract linear model results for each permutation individually using nest, mutate, and map functions\n\nfake_biochem_lms &lt;- fake_biochem |&gt;\n  nest(data = -perm) |&gt;\n  mutate(\n    fit = map(data, ~ lm(weight ~ tot_cholesterol, data = .x)),\n    glanced = map(fit, glance)\n  ) |&gt;\n  unnest(glanced)"
  },
  {
    "objectID": "exercises/ex-13.html#visualize-the-null",
    "href": "exercises/ex-13.html#visualize-the-null",
    "title": "Stats Bootcamp - class 13",
    "section": "Visualize the null",
    "text": "Visualize the null\nLet’s take a look at the null distribution of F-statistics from the randomized values\n\nggplot(fake_biochem_lms,\n       aes(x = statistic)) +\ngeom_density(color=\"red\") +\ntheme_minimal()\n\n\nremember that the \\(F-statistic\\) we observed was 255!\n\nggplot(fake_biochem_lms, aes(x = statistic)) +\nxlim(0,f*1.1) +\ngeom_density(color=\"red\") +\ngeom_vline(xintercept = f, color = \"blue\") +\n#  scale_x_log10() +\ntheme_minimal() \n\nIn our 100 randoized simulations, we never see an F-statistic as extreme as the one we observed in the actual data. Therefore:\n\nP &lt; 0.01 or 1/100\n\nReminder, our calculate P value was:"
  },
  {
    "objectID": "exercises/ex-13.html#how-to-find-the-best-least-squares-fit",
    "href": "exercises/ex-13.html#how-to-find-the-best-least-squares-fit",
    "title": "Stats Bootcamp - class 13",
    "section": "How to find the best (least squares) fit?",
    "text": "How to find the best (least squares) fit?\n\nRotate the line of fit\n\nFind the fit that minimizes the Sum of Squared Residuals or \\(SS_{fit}\\)\n\nThis is the derivative (slope of tangent at best point = 0) of the function describing the \\(SS_{fit}\\) and the next rotation is 0."
  },
  {
    "objectID": "exercises/ex-13.html#references",
    "href": "exercises/ex-13.html#references",
    "title": "Stats Bootcamp - class 13",
    "section": "References",
    "text": "References\nDifferences between correlation and regression\nalso more differences between correlation and regression.\nCommon statistical tests are linear models from Jonas Lindeløv\nStatquest\nStats gobbledygook\nLinear Regression Assumptions and Diagnostics in R: Essentials\nPRINCIPLES OF STATISTICS from GraphPad/SAS.\nStatquest: how to go from F-statistic to p-value\nStatQuest: Fitting a line to data, aka least squares, aka linear regression.\nStatQuest: Gradient Descent, Step-by-Step"
  },
  {
    "objectID": "exercises/ex-11.html",
    "href": "exercises/ex-11.html",
    "title": "Stats Bootcamp - class 11",
    "section": "",
    "text": "Learn types of variables\nCalculate and visualize summary statistics\nProperties of data distributions\nCentral limit theorem"
  },
  {
    "objectID": "exercises/ex-11.html#learning-objectives",
    "href": "exercises/ex-11.html#learning-objectives",
    "title": "Stats Bootcamp - class 11",
    "section": "",
    "text": "Learn types of variables\nCalculate and visualize summary statistics\nProperties of data distributions\nCentral limit theorem"
  },
  {
    "objectID": "exercises/ex-11.html#quantitative-variables",
    "href": "exercises/ex-11.html#quantitative-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Quantitative Variables",
    "text": "Quantitative Variables\nDiscrete variable: numeric variables that have a countable number of values between any two values - integer in R (e.g., number of mice, read counts).\nContinuous variable: numeric variables that have an infinite number of values between any two values - numeric in R (e.g., normalized expression values, fluorescent intensity)."
  },
  {
    "objectID": "exercises/ex-11.html#categorical-variables",
    "href": "exercises/ex-11.html#categorical-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Categorical Variables",
    "text": "Categorical Variables\nNominal variable: (unordered) random variables have categories where order doesn’t matter - factor in R (e.g., country, type of gene, genotype).\nOrdinal variable: (ordered) random variables have ordered categories - order of levels in R ( e.g. grade of tumor)."
  },
  {
    "objectID": "exercises/ex-11.html#distributions-and-probabilities",
    "href": "exercises/ex-11.html#distributions-and-probabilities",
    "title": "Stats Bootcamp - class 11",
    "section": "Distributions and probabilities",
    "text": "Distributions and probabilities\nA distribution in statistics is a function that shows the possible values for a variable and how often they occur.\nWe can visualize this with a histogram or density plots as we did earlier.\nWe are going to start with simulated data and then use Palmer Penguins later."
  },
  {
    "objectID": "exercises/ex-11.html#create-a-normal-distribution",
    "href": "exercises/ex-11.html#create-a-normal-distribution",
    "title": "Stats Bootcamp - class 11",
    "section": "Create a normal distribution",
    "text": "Create a normal distribution\nAssume that the test scores of a college entrance exam fits a normal distribution. Furthermore, the mean test score is 76, and the standard deviation is 13.8.\n\nd &lt;- tibble(n1=rnorm(n = ??, mean = ??, sd = ??))\n\nhead(d)"
  },
  {
    "objectID": "exercises/ex-11.html#visualize-a-normal-distribution",
    "href": "exercises/ex-11.html#visualize-a-normal-distribution",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualize a normal distribution",
    "text": "Visualize a normal distribution\nfirst we will look at a histogram n1\n\nggplot(data = ??, \n       aes(x=??)\n       ) +\n  geom_??() +\n  theme_cowplot() \n\n\nnext a density plot\n\nggplot(data = d, \n       aes(x=n1)\n       ) +\n  geom_??() +\n  geom_vline(xintercept = ??) + # draw mean\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#determine-the-probability-of-a-given-value",
    "href": "exercises/ex-11.html#determine-the-probability-of-a-given-value",
    "title": "Stats Bootcamp - class 11",
    "section": "Determine the probability of a given value",
    "text": "Determine the probability of a given value\nProbability is used to estimate how probable a sample is based on a given distribution.\nProbability refers to the area under curve (AUC) on the distribution curve. The higher the value, the more probable that the data come from this distribution.\nWhat is the probability of students scoring 85 or more in the exam?\n\ns &lt;- 85\npnorm(??, mean=76, sd=13.8, lower.tail = F) \n\n. . .\nWhat is the probability of students scoring 85 or less in the exam?\n\npnorm(s, mean=76, sd=13.8, lower.tail = T) \n\n\nProb of 85 or more is equivalent to the area under the curve to the right of 85.\n\nggplot(data = d, \n       aes(x=n1)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = s) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#determine-the-likelihood-of-a-given-value",
    "href": "exercises/ex-11.html#determine-the-likelihood-of-a-given-value",
    "title": "Stats Bootcamp - class 11",
    "section": "Determine the likelihood of a given value",
    "text": "Determine the likelihood of a given value\nLikelihood is used to estimate how good a model fits the data. Likelihood refers to a specific point on the distribution curve. The lower the likelihood, the worse the model fits the data.\nWhat is the likelihood of students scoring 85 on the exam?\n\nl &lt;- dnorm(s, mean=76, sd=13.8) \nl\n\n\nThe likelihood is the y-axis value on the curve when th x-axis = 85.\n\nggplot(data = d, \n       aes(x=n1)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = s) +\n  geom_hline(yintercept = l) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#now-to-real-messy-data",
    "href": "exercises/ex-11.html#now-to-real-messy-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Now to real (messy!) data",
    "text": "Now to real (messy!) data\nWe will use the Palmer Penguins dataset\n\npenguins_raw \n\n# A tibble: 344 × 17\n   studyName `Sample Number` Species         Region Island Stage `Individual ID`\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;          \n 1 PAL0708                 1 Adelie Penguin… Anvers Torge… Adul… N1A1           \n 2 PAL0708                 2 Adelie Penguin… Anvers Torge… Adul… N1A2           \n 3 PAL0708                 3 Adelie Penguin… Anvers Torge… Adul… N2A1           \n 4 PAL0708                 4 Adelie Penguin… Anvers Torge… Adul… N2A2           \n 5 PAL0708                 5 Adelie Penguin… Anvers Torge… Adul… N3A1           \n 6 PAL0708                 6 Adelie Penguin… Anvers Torge… Adul… N3A2           \n 7 PAL0708                 7 Adelie Penguin… Anvers Torge… Adul… N4A1           \n 8 PAL0708                 8 Adelie Penguin… Anvers Torge… Adul… N4A2           \n 9 PAL0708                 9 Adelie Penguin… Anvers Torge… Adul… N5A1           \n10 PAL0708                10 Adelie Penguin… Anvers Torge… Adul… N5A2           \n# ℹ 334 more rows\n# ℹ 10 more variables: `Clutch Completion` &lt;chr&gt;, `Date Egg` &lt;date&gt;,\n#   `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;\n\n\n. . .\nYikes! Some of these column names have horrible formatting e.g. spaces, slashes, parenthesis. These characters can be misinterpreted by R. Also, long/wonky names makes coding annoying."
  },
  {
    "objectID": "exercises/ex-11.html#lets-tidy-the-names",
    "href": "exercises/ex-11.html#lets-tidy-the-names",
    "title": "Stats Bootcamp - class 11",
    "section": "Let’s tidy the names",
    "text": "Let’s tidy the names\n\npenguins_raw |&gt; colnames()\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\n. . .\njanitor package to the rescue.\n. . .\n. . .\nCreate a new object pen that has nice clean variable names. And get rid of any variable that is the same for all observations (not useful).\n\npen &lt;- penguins_raw |&gt;\n  clean_names() |&gt;\n  janitor::remove_constant()"
  },
  {
    "objectID": "exercises/ex-11.html#lets-inspect-the-data",
    "href": "exercises/ex-11.html#lets-inspect-the-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Let’s inspect the data",
    "text": "Let’s inspect the data\n\npen |&gt;\n  str()\n\ntibble [344 × 15] (S3: tbl_df/tbl/data.frame)\n $ study_name       : chr [1:344] \"PAL0708\" \"PAL0708\" \"PAL0708\" \"PAL0708\" ...\n $ sample_number    : num [1:344] 1 2 3 4 5 6 7 8 9 10 ...\n $ species          : chr [1:344] \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" \"Adelie Penguin (Pygoscelis adeliae)\" ...\n $ island           : chr [1:344] \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ individual_id    : chr [1:344] \"N1A1\" \"N1A2\" \"N2A1\" \"N2A2\" ...\n $ clutch_completion: chr [1:344] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ date_egg         : Date[1:344], format: \"2007-11-11\" \"2007-11-11\" ...\n $ culmen_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ culmen_depth_mm  : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: num [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : num [1:344] 3750 3800 3250 NA 3450 ...\n $ sex              : chr [1:344] \"MALE\" \"FEMALE\" \"FEMALE\" NA ...\n $ delta_15_n_o_oo  : num [1:344] NA 8.95 8.37 NA 8.77 ...\n $ delta_13_c_o_oo  : num [1:344] NA -24.7 -25.3 NA -25.3 ...\n $ comments         : chr [1:344] \"Not enough blood for isotopes.\" NA NA \"Adult not sampled.\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   studyName = col_character(),\n  ..   `Sample Number` = col_double(),\n  ..   Species = col_character(),\n  ..   Region = col_character(),\n  ..   Island = col_character(),\n  ..   Stage = col_character(),\n  ..   `Individual ID` = col_character(),\n  ..   `Clutch Completion` = col_character(),\n  ..   `Date Egg` = col_date(format = \"\"),\n  ..   `Culmen Length (mm)` = col_double(),\n  ..   `Culmen Depth (mm)` = col_double(),\n  ..   `Flipper Length (mm)` = col_double(),\n  ..   `Body Mass (g)` = col_double(),\n  ..   Sex = col_character(),\n  ..   `Delta 15 N (o/oo)` = col_double(),\n  ..   `Delta 13 C (o/oo)` = col_double(),\n  ..   Comments = col_character()\n  .. )\n\n\n\nLet’s select a few of these columns to keep and get rid of NAs\n\np &lt;- pen |&gt; \n  select(species, island, culmen_length_mm, flipper_length_mm, body_mass_g, sex) |&gt; \n  drop_na()\n\n. . .\nclean species names\n\nunique(p$species)\n\n[1] \"Adelie Penguin (Pygoscelis adeliae)\"      \n[2] \"Gentoo penguin (Pygoscelis papua)\"        \n[3] \"Chinstrap penguin (Pygoscelis antarctica)\"\n\np &lt;- p |&gt;\n  mutate(species = str_remove(species, pattern = \" [P|p]en.*\")\n         )"
  },
  {
    "objectID": "exercises/ex-11.html#visualizing-quantitative-variables",
    "href": "exercises/ex-11.html#visualizing-quantitative-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualizing quantitative variables",
    "text": "Visualizing quantitative variables\nhistogram of body mass\n\nggplot(data = ??, \n       aes(x=??)\n       ) +\n  geom_histogram() +\n  theme_cowplot()\n\n\ndensity plot of body mass\n\nggplot(data = p, \n       aes(x=body_mass_g)\n       ) +\n  geom_??() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#visualizing-categorical-variables",
    "href": "exercises/ex-11.html#visualizing-categorical-variables",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualizing categorical variables",
    "text": "Visualizing categorical variables\nbarplot - 1 category\n\nggplot(data = p, aes(x = island, fill = island)) +\n    geom_bar() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#barplot---categories-island-vs-sex",
    "href": "exercises/ex-11.html#barplot---categories-island-vs-sex",
    "title": "Stats Bootcamp - class 11",
    "section": "barplot - categories (island vs sex)",
    "text": "barplot - categories (island vs sex)\nstacked:\n\nggplot(data = p, aes(x = island, fill = sex)) +\n  geom_bar() +\n  theme_cowplot()\n\n\n\n\n\nproportion\n\nggplot(data = p, aes(x = island, fill = sex)) +\n  geom_bar(position = \"fill\") +\n  theme_cowplot()\n\n\n\n\n\nper category\n\nggplot(data = p, aes(x = island, fill = sex)) +\n  geom_bar(position = \"dodge\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#descriptive-statistics-for-continuous-data",
    "href": "exercises/ex-11.html#descriptive-statistics-for-continuous-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Descriptive statistics for continuous data",
    "text": "Descriptive statistics for continuous data\n\nn: # observations/individuals or sample size\nmean (\\(\\mu\\)): sum of all observations divided by # of observations, \\(\\mu = \\displaystyle \\frac {\\sum x_i} {n}\\)\n\nmedian: the “middle” value of a data set. Not as sensitive to outliers as the mean."
  },
  {
    "objectID": "exercises/ex-11.html#descriptive-statistics-for-body-weight",
    "href": "exercises/ex-11.html#descriptive-statistics-for-body-weight",
    "title": "Stats Bootcamp - class 11",
    "section": "Descriptive statistics for body weight",
    "text": "Descriptive statistics for body weight\nLet’s look at the distribution again\n\nggplot(data = p, \n       aes(x=body_mass_g)\n       ) +\n  geom_density() +\n  theme_cowplot()\n\n\n\n\n. . .\nn\n\nlength(p$body_mass_g)\n\n[1] 333\n\n\n. . .\nmean\n\nmean(p$body_mass_g)\n\n[1] 4207.057\n\n\n. . .\nmedian\n\nmedian(p$body_mass_g)\n\n[1] 4050\n\n\n\nviz mean + median\n\nggplot(data = p, \n       aes(x=body_mass_g)\n       ) +\n  geom_density() +\n#  geom_vline() +\n#  geom_vline() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#other-descriptive-statistics",
    "href": "exercises/ex-11.html#other-descriptive-statistics",
    "title": "Stats Bootcamp - class 11",
    "section": "Other descriptive statistics",
    "text": "Other descriptive statistics\nMin: minimum value.\nMax: maximum value.\nq1, q3: the first and the third quartile, respectively.\nIQR: interquartile range measures the spread of the middle half of your data (q3-q1).\nQuick way to get all these stats:\n\np |&gt;\n  get_summary_stats(body_mass_g, type = \"common\")\n\n# A tibble: 1 × 10\n  variable        n   min   max median   iqr  mean    sd    se    ci\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 body_mass_g   333  2700  6300   4050  1225 4207.  805.  44.1  86.8\n\n\n. . . get mean, median\n\np |&gt;\n  get_summary_stats(body_mass_g,\n                    show = c(\"??\",\"??\")\n                    )"
  },
  {
    "objectID": "exercises/ex-11.html#statistics-describing-spread-of-values",
    "href": "exercises/ex-11.html#statistics-describing-spread-of-values",
    "title": "Stats Bootcamp - class 11",
    "section": "Statistics describing spread of values",
    "text": "Statistics describing spread of values\nVariance: the average of the squared differences from the mean\n\\(\\sigma^2 = \\displaystyle \\frac {\\sum (x_{i} - \\mu)^2}{n}\\)\nStandard Deviation: square root of the variance\n\\(\\sigma = \\sqrt {\\displaystyle \\frac {\\sum (x_{i} - \\mu)^2}{n}}\\)\n\nThe variance measures the mathematical dispersion of the data relative to the mean. However, it is more difficult to apply in a real-world sense because the values used to calculate it were squared. \n\nThe standard deviation, as the square root of the variance, is in the same units as the original values, which makes it much easier to work with and interpret w/respect to the mean."
  },
  {
    "objectID": "exercises/ex-11.html#other-stats-describing-spread-of-data",
    "href": "exercises/ex-11.html#other-stats-describing-spread-of-data",
    "title": "Stats Bootcamp - class 11",
    "section": "Other stats describing spread of data",
    "text": "Other stats describing spread of data\nConfidence Interval (ci): a range of values that you can be 95% (or x%) certain contains the true population mean. Gets into inferential statistics."
  },
  {
    "objectID": "exercises/ex-11.html#get-more-descriptive-stats-easily",
    "href": "exercises/ex-11.html#get-more-descriptive-stats-easily",
    "title": "Stats Bootcamp - class 11",
    "section": "Get more descriptive stats easily",
    "text": "Get more descriptive stats easily\n\np |&gt;\n  get_summary_stats(body_mass_g, show = c(\"mean\",\"median\",\"sd\")) \n\n# A tibble: 1 × 5\n  variable        n  mean median    sd\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 body_mass_g   333 4207.   4050  805.\n\n\n. . .\nby species\n\np |&gt;\n  group_by(species) |&gt;\n  get_summary_stats(body_mass_g, show = c(\"mean\",\"median\",\"sd\"))\n\n# A tibble: 3 × 6\n  species   variable        n  mean median    sd\n  &lt;chr&gt;     &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie    body_mass_g   146 3706.   3700  459.\n2 Chinstrap body_mass_g    68 3733.   3700  384.\n3 Gentoo    body_mass_g   119 5092.   5050  501.\n\n\n\nby species and island\n\np |&gt;\n  group_by(species,island) |&gt;\n  get_summary_stats(body_mass_g, show = c(\"mean\",\"median\",\"sd\")) \n\n# A tibble: 5 × 7\n  species   island    variable        n  mean median    sd\n  &lt;chr&gt;     &lt;chr&gt;     &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie    Biscoe    body_mass_g    44 3710.   3750  488.\n2 Adelie    Dream     body_mass_g    55 3701.   3600  449.\n3 Adelie    Torgersen body_mass_g    47 3709.   3700  452.\n4 Chinstrap Dream     body_mass_g    68 3733.   3700  384.\n5 Gentoo    Biscoe    body_mass_g   119 5092.   5050  501."
  },
  {
    "objectID": "exercises/ex-11.html#normal-distribution",
    "href": "exercises/ex-11.html#normal-distribution",
    "title": "Stats Bootcamp - class 11",
    "section": "Normal distribution",
    "text": "Normal distribution\nThe mean, mode, and median are all equal.\nThe distribution is symmetric about the mean—half the values fall below the mean and half above the mean.\nThe distribution can be described by two values: the mean and the standard deviation."
  },
  {
    "objectID": "exercises/ex-11.html#bell-curve-or-standard-normal",
    "href": "exercises/ex-11.html#bell-curve-or-standard-normal",
    "title": "Stats Bootcamp - class 11",
    "section": "Bell curve or standard normal:",
    "text": "Bell curve or standard normal:\nIs a special normal distribution where the mean is 0 and the standard deviation is 1."
  },
  {
    "objectID": "exercises/ex-11.html#normal-distribution-metrics",
    "href": "exercises/ex-11.html#normal-distribution-metrics",
    "title": "Stats Bootcamp - class 11",
    "section": "Normal distribution metrics",
    "text": "Normal distribution metrics\nSkewness is a measure of the asymmetry around the mean. 0 for bell curve."
  },
  {
    "objectID": "exercises/ex-11.html#normal-distribution-metrics-1",
    "href": "exercises/ex-11.html#normal-distribution-metrics-1",
    "title": "Stats Bootcamp - class 11",
    "section": "Normal distribution metrics",
    "text": "Normal distribution metrics\nKurtosis is a measure of the “flatness” of the distribution."
  },
  {
    "objectID": "exercises/ex-11.html#is-my-data-normally-distributed",
    "href": "exercises/ex-11.html#is-my-data-normally-distributed",
    "title": "Stats Bootcamp - class 11",
    "section": "Is my data normal(ly distributed)?",
    "text": "Is my data normal(ly distributed)?\nLet’s look at the test score distribution again\n\nggplot(data = d,\n       aes(x = n1)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#qq-plot",
    "href": "exercises/ex-11.html#qq-plot",
    "title": "Stats Bootcamp - class 11",
    "section": "QQ-plot",
    "text": "QQ-plot\nquantile-quantile plot to compare an empirical distribution to a theoretical distribution.\nQuantile is the fraction (or percent) of points below the given value. For example, the 0.2 (or 20%) quantile is the point at which 20% percent of the data fall below and 80% fall above that value.\n\nggplot(data = d,\n       aes(sample = n1)) +\n  geom_qq() +\n  geom_qq_line() + \n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#shapiro-wilk-normality-test",
    "href": "exercises/ex-11.html#shapiro-wilk-normality-test",
    "title": "Stats Bootcamp - class 11",
    "section": "Shapiro-Wilk Normality Test",
    "text": "Shapiro-Wilk Normality Test\nShapiro-Wilk test is a hypothesis test that evaluates whether a data set is normally distributed. /\nIt evaluates data from a sample with the null hypothesis that the data set is normally distributed. /\nA large p-value indicates the data set is normally distributed, a low p-value indicates that it isn’t normally distributed.\n\nd |&gt;\n  shapiro_test(n1)"
  },
  {
    "objectID": "exercises/ex-11.html#back-to-penguin-body-mass",
    "href": "exercises/ex-11.html#back-to-penguin-body-mass",
    "title": "Stats Bootcamp - class 11",
    "section": "Back to penguin body mass",
    "text": "Back to penguin body mass\nDistribution\n\nggplot(data = p,\n       aes(x = body_mass_g)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#qq-plot-body-mass",
    "href": "exercises/ex-11.html#qq-plot-body-mass",
    "title": "Stats Bootcamp - class 11",
    "section": "QQ-plot body mass",
    "text": "QQ-plot body mass\n\nggplot(data = p,\n       aes(sample = body_mass_g)) +\n  geom_qq() +\n  geom_qq_line() + \n  theme_cowplot()\n\n\n\n\nHmmm…"
  },
  {
    "objectID": "exercises/ex-11.html#shapiro-wilk-body-mass",
    "href": "exercises/ex-11.html#shapiro-wilk-body-mass",
    "title": "Stats Bootcamp - class 11",
    "section": "Shapiro-Wilk body mass",
    "text": "Shapiro-Wilk body mass\n\np |&gt;\n  shapiro_test(??)  \n\nThat does not look normal!"
  },
  {
    "objectID": "exercises/ex-11.html#penguin-body-mass-by-species",
    "href": "exercises/ex-11.html#penguin-body-mass-by-species",
    "title": "Stats Bootcamp - class 11",
    "section": "Penguin body mass by species?",
    "text": "Penguin body mass by species?\nDistribution\n\nggplot(data = p,\n       aes(x = body_mass_g, color = species)) +\n  geom_density() +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#qq-plot-body-weight",
    "href": "exercises/ex-11.html#qq-plot-body-weight",
    "title": "Stats Bootcamp - class 11",
    "section": "QQ-plot body weight",
    "text": "QQ-plot body weight\n\nggplot(data = p,\n       aes(sample = body_mass_g, color = species)) +\n  geom_qq() +\n  geom_qq_line() + \n  theme_cowplot()\n\n\n\n\nThat looks better…"
  },
  {
    "objectID": "exercises/ex-11.html#shapiro-wilk-body-weight-by-species",
    "href": "exercises/ex-11.html#shapiro-wilk-body-weight-by-species",
    "title": "Stats Bootcamp - class 11",
    "section": "Shapiro-Wilk body weight by species",
    "text": "Shapiro-Wilk body weight by species\n\np |&gt;\n  group_by(??) |&gt;\n  shapiro_test(??)  \n\nOk so Chinstrap and Gentoo look normal. Not sure about Adelie. We may want to consider using non-parametric test to compare mean body weights between Adelie vs Chinstrap or Gentoo."
  },
  {
    "objectID": "exercises/ex-11.html#central-limit-theorem",
    "href": "exercises/ex-11.html#central-limit-theorem",
    "title": "Stats Bootcamp - class 11",
    "section": "Central limit theorem",
    "text": "Central limit theorem\nThe central limit theorem states that if you take sufficiently large samples from a population, the samples’ means will be normally distributed, even if the population isn’t normally distributed.\nBack to coin flips!! 50 flips, one round.\n\nn &lt;- 50\n\n# make a hundred fair and unfair flips\nf &lt;- tibble(fair=rbinom(n = n, size = 1, prob = .5),\n       unfair=rbinom(n = n, size = 1, prob = .2)) |&gt; \n    pivot_longer(cols = c(\"fair\",\"unfair\"), names_to = \"cheating\", values_to = \"flips\")"
  },
  {
    "objectID": "exercises/ex-11.html#flip-distributions",
    "href": "exercises/ex-11.html#flip-distributions",
    "title": "Stats Bootcamp - class 11",
    "section": "flip distributions",
    "text": "flip distributions\nLook at the distribution of fair flips\n\nggplot(data = f |&gt; filter(cheating==\"fair\"), \n       aes(x=flips)\n       ) +\n  geom_histogram() +\n  theme_cowplot()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLook at the distribution of unfair flips\n\nggplot(data = f |&gt; filter(cheating==\"unfair\"), \n       aes(x=flips)\n       ) +\n  geom_histogram() +\n  theme_cowplot()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "exercises/ex-11.html#now-lets-sample-means",
    "href": "exercises/ex-11.html#now-lets-sample-means",
    "title": "Stats Bootcamp - class 11",
    "section": "Now lets sample means",
    "text": "Now lets sample means\nlet’s do 100 round of 50 flips and take the average of each round.\nremember the size that i told you to ignore last class!\n\nr &lt;- 100\n\nrbinom(n = n, size = r, prob = .5)/r\n\n [1] 0.45 0.57 0.44 0.40 0.54 0.56 0.55 0.48 0.56 0.42 0.49 0.47 0.55 0.49 0.41\n[16] 0.47 0.48 0.55 0.57 0.40 0.48 0.53 0.48 0.48 0.54 0.57 0.53 0.51 0.44 0.45\n[31] 0.51 0.51 0.53 0.47 0.49 0.43 0.53 0.54 0.54 0.63 0.41 0.61 0.51 0.45 0.46\n[46] 0.55 0.45 0.54 0.47 0.49\n\n\n\nfmean &lt;- tibble(\n  fair=rbinom(n = n, size = r, prob = .5)/r,\n  unfair=rbinom(n = n, size = r, prob = .2)/r) |&gt;\n  pivot_longer(cols = c(\"fair\",\"unfair\"),\n               names_to = \"cheating\",\n               values_to = \"flips\"\n               )"
  },
  {
    "objectID": "exercises/ex-11.html#sampled-flip-mean-distributions",
    "href": "exercises/ex-11.html#sampled-flip-mean-distributions",
    "title": "Stats Bootcamp - class 11",
    "section": "sampled flip mean distributions",
    "text": "sampled flip mean distributions\nLook at the distribution of fair flips\n\nggplot(data = fmean |&gt; filter(cheating==\"fair\"), \n       aes(x=flips)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = .5) +\n  xlim(0,1) +\n  theme_cowplot()\n\n\n\n\nLook at the distribution of unfair flips\n\nggplot(data = fmean |&gt; filter(cheating==\"unfair\"), \n       aes(x=flips)\n       ) +\n  geom_density() +\n  geom_vline(xintercept = .2) + \n  xlim(0,1) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-11.html#but-is-it-normal",
    "href": "exercises/ex-11.html#but-is-it-normal",
    "title": "Stats Bootcamp - class 11",
    "section": "but is it normal?",
    "text": "but is it normal?\n\nfmean |&gt;\n  group_by(cheating) |&gt;\n  shapiro_test(flips)\n\n# A tibble: 2 × 4\n  cheating variable statistic      p\n  &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 fair     flips        0.961 0.0949\n2 unfair   flips        0.960 0.0882\n\n\nyup!"
  },
  {
    "objectID": "exercises/ex-11.html#what-about-the-mean-sd-with-different-parameters",
    "href": "exercises/ex-11.html#what-about-the-mean-sd-with-different-parameters",
    "title": "Stats Bootcamp - class 11",
    "section": "What about the mean + sd with different parameters?",
    "text": "What about the mean + sd with different parameters?\n10 fair and unfair flips\n20 and 80 times\n\nfair10 &lt;- tibble(\n  r20=rbinom(n = 10, size = 20, prob = .5)/20,\n  r80=rbinom(n = 10, size = 80, prob = .5)/80,\n  type=rep(\"fair10\")\n  )\n\n\nunfair10 &lt;- tibble(\n  r20=rbinom(n = 10, size = 20, prob = .2)/20,\n  r80=rbinom(n = 10, size = 80, prob = .2)/80,\n  type=rep(\"unfair10\")\n  )\n\n\nput it all together\n\nall &lt;- bind_rows(fair10, unfair10) |&gt;\n  pivot_longer(cols = c(\"r20\",\"r80\"),\n             names_to = \"r\",\n             values_to = \"f\"\n             )"
  },
  {
    "objectID": "exercises/ex-11.html#visualize",
    "href": "exercises/ex-11.html#visualize",
    "title": "Stats Bootcamp - class 11",
    "section": "Visualize",
    "text": "Visualize\n\nggplot(all , aes(x=r, y=f, color=r)) +\n  geom_jitter() +\n  stat_summary(fun.y=mean, geom=\"point\", shape=18,\n                 size=3, color=\"black\") +\n  ylim(-0.05,1.05) +\n   facet_grid(~type) +\n  geom_hline(yintercept = .5, linetype = \"dashed\") +\n  geom_hline(yintercept = .2, linetype = \"dashed\") +\n  theme_cowplot()\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\n. . .\n\nall |&gt; \n  group_by(type,r) |&gt;\n  get_summary_stats(show = c(\"mean\",\"sd\"))\n\n# A tibble: 4 × 6\n  type     r     variable     n  mean    sd\n  &lt;chr&gt;    &lt;chr&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 fair10   r20   f           10 0.535 0.1  \n2 fair10   r80   f           10 0.527 0.059\n3 unfair10 r20   f           10 0.205 0.09 \n4 unfair10 r80   f           10 0.206 0.049"
  },
  {
    "objectID": "exercises/ex-11.html#references",
    "href": "exercises/ex-11.html#references",
    "title": "Stats Bootcamp - class 11",
    "section": "References",
    "text": "References\n\nThe Normal Distribution, Confidence Intervals, and Their Deceptive Simplicity\nCentral limit theorem\nHistograms, Clearly Explained\nThe Main Ideas behind Probability Distributions\nThe Normal Distribution, Clearly Explained!!!\nProbability vs Likelihood"
  },
  {
    "objectID": "exercises/ex-09.html",
    "href": "exercises/ex-09.html",
    "title": "Exercises 9",
    "section": "",
    "text": "A yeast gene expression experiment\nNext, we’ll examine some gene expression data from the budding yeast S. cerevisiae. We’ll roughly follow the analysis strategy taken by David Robinson in his blog Variance Explained.\nThe data come from:\n\nBrauer MJ, Huttenhower C, Airoldi EM, Rosenstein R, Matese JC, Gresham D, Boer VM, Troyanskaya OG, Botstein D. Coordination of growth rate, cell cycle, stress response, and metabolic activity in yeast. Mol Biol Cell. 2008 [Link]\n\nThey used chemostats to control the growth rate of cells under different nutrient-limited conditions.\nIn this experiment, cells were grown in different media limited for (one of) glucose, uracil, leucine, sulfate, phosphate, or ammonia. Over a series of fixed, equilibrium growth rates (established by the dilution rate of fresh media), cells were harvested and gene expression was measured by genome-wide microarrays.\nThis is a well organized experiment (so it’s useuful for teaching / learning), but there’s nothing particularly special about the setup.\n\nWe could be measuring protein or metabolite levels instead of gene expression, or analyzing cell features from images taken of the cells.\nWe might be adding an increasing amount of a drug candidate instead of nutrient deprivation\nWe might be altering the growth density of mammalian cells (by plating) instead of controlling growth rate in a chemostat.\n\nLoad libraries\nLoad libraries you’ll need for the analysis below.\nLoad the data\nA raw version of the gene expression data are in:\n\ndata/brauer_gene_exp_wide.tsv.gz\n\nIn addition, another tibbles contains related information:\n\ndata/yeast_go_terms.tsv.gz\n\nLoad each of the above files and inspect.\n\nbrauer_gene_exp_wide &lt;- ___ \nyeast_go_terms &lt;- ___\n\nTidy the data\nAre these data tidy?\n\nbrauer_gene_exp_tidy &lt;-\n  pivot_longer(\n    data = ___,\n    cols = ___,\n    names_to = \"___\",\n    values_to = \"___\"\n  ) |&gt;\n  separate(\n    ___,\n    into = c(\"___\", \"___\"),\n    sep = 1,\n    convert = TRUE\n  )\n\nNext, we want to update the nutrient abbreviations so they’re easier to remember.\n\nnutrient_abbrs &lt;- tribble(\n  ~ nutrient_abbr, ~ nutrient,\n  \"G\", \"Glucose\",\n  \"L\", \"Leucine\",\n  \"P\", \"Phosphate\",\n  \"S\", \"Sulfate\",\n  \"N\", \"Ammonia\",\n  \"U\", \"Uracil\"\n)\n\n# now, we need to *join* the tibbles\nbrauer_gene_exp_tidy &lt;-\n  left_join(___, ___) |&gt;\n  # drop the nutrient abbreviation \n  select(___)\n\nNext, we want the common gene names, which contain useful information for filtering and grouping. These are in yeast_go_terms, so we need to join.\n\n# need a tibble that maps systematic\n# common names\nname_map &lt;- select(\n  yeast_go_terms,\n  ___, ___ \n)\n\n# we need to *join* again . . .\nbrauer_gene_exp_tidy &lt;-\n  left_join(___, ___) |&gt;\n  # reorganize so that systematic and common names come first\n  select(___)\n\nFinally, we’ll drop all rows with NA expression values, and arrange the tibble.\n\nbrauer_gene_exp_tidy &lt;-\n  # drop rows where `exp` is `NA`\n  drop_na(___, ___) |&gt;\n  # arrange by common name, nutrient, and rate\n  arrange(___) \n\nHeatmap of gene expression values\nHeatmaps are a useful approach to visualize thousands of data points, orgnaized by experimental variables to show patterns in the data.\nWe’ll use the ComplexHeatmap package from Bioconductor, which provides a flexible framework for generating heatmaps.\n\nbrauer_mat_dat &lt;-\n  brauer_gene_exp |&gt;\n  unite(___, ___) |&gt;\n  pivot_wider(\n    names_from = ___,\n    values_from = ___\n  )\n\nbrauer_mat &lt;-\n  # remove name columns, just need the data\n  select(___, ___) |&gt;\n  as.matrix()\n\n# Inspect the matrix above.\n\nComplexHeatmap::Heatmap(___)\n\nExpression of select genes associated with nutrient metabolism\nExamine the genes (common_name) that start with LEU.\n\nleu_genes_tbl &lt;- brauer_gene_exp_tidy |&gt;\n  filter(str_detect(___, \"___\"))\n\nggplot(\n  leu_genes_tbl,\n  aes(\n    x = ___,\n    y = ___,\n    color = ___ \n  )\n) +\n  geom_point() + \n  geom_smooth(method = 'lm', se = FALSE) +\n  facet_wrap(~ ___) +\n  theme_cowplot() +\n  scale_color_brewer(palette = \"Dark2\")\n\nModeling the relationship between gene expression and growth rate\nOne gene\nLet’s look specifically at a linear model of the data for LEU1 under leucine starvation.\n\nleu1_tbl &lt;- leu_genes_tbl |&gt;\n  filter(common_name == \"___\" & nutrient == \"___\")\n\nggplot(leu1_tbl, aes(___, ___)) +\n  geom_point(size = 3) +\n  theme_cowplot()\n\nLet’s take a look at the linear model of these data.\n\nmod &lt;- lm(exp ~ rate, data = leu1_tbl)\nsummary(mod)\n\nThe relevant information (rate, intercept, p.value) for the model is not easily accessed.\nWe can use the broom library to tidy the model information.\n\nlibrary(broom)\nbroom::tidy(mod)\n\nAll genes\nDoing this for one gene is interesting, but really we’d like models for all of the conditions so that we can compare between them to identify interesting patterns.\nThe following code chunk will do the following:\n\nnest data for model fitting into a new column data\n\nfit linear models to the data column using purrr::map()\n\ntidy the linear models using broom::tidy()\n\nunnest the model coefficients\n\n\nlinear_model_tbl &lt;-\n  brauer_gene_exp_tidy |&gt;\n  group_by(systematic_name, common_name, nutrient) |&gt;\n  nest() |&gt;\n  # look at the data up to the `nest()` call\n  mutate(\n    model = purrr::map(\n      data,\n      ~ lm(exp ~ rate, data = .)\n    )\n  ) |&gt;\n  mutate(\n    model_tidy = purrr::map(\n      model,\n      broom::tidy\n    )\n  ) |&gt;\n  select(-model, -data) |&gt;\n  unnest(cols = c(model_tidy))\n\nNote that we now have slope and intercept terms for each group we specified.\n\nthe intercept indicates how highly a gene is expressed when starved of a nutrient.\nthe rate indicates how much a gene’s expression responds to increasing nutrient (i.e., growth rate).\nFurther analysis\nAt this point, you can ask questions like the following:\n\nHow do other groups of metabolic genes respond to nutrient deprivation? Start with the ‘PHO’, ‘URA’, and ‘SUL’ genes. Comment on features that stand out, both within and across nutrient deprivation conditions.\nWhat if you include and group by the GO terms in the yeast_go_terms tibble instead of gene name? I.e., you could detect the string leucine in the biological process and group by those instead of gene name (you’d need to join the tidy tibble with the GO information first).\nAre there other genes that behave like LEU1 under leucine starvation? I.e., a strong negative slope in one condition, and positive slopes in the others?"
  },
  {
    "objectID": "exercises/ex-07.html",
    "href": "exercises/ex-07.html",
    "title": "R Bootcamp - Day 7",
    "section": "",
    "text": "Accessing data in vectors (Exercise)\nother tidyverse packages (stringr & forcats)\ndplyr table joins (Exercise)\nggplot2 scale functions\nggplot2 multi-panel figures (Exercise)\nggplot2 saving figures"
  },
  {
    "objectID": "exercises/ex-07.html#class-7-outline",
    "href": "exercises/ex-07.html#class-7-outline",
    "title": "R Bootcamp - Day 7",
    "section": "",
    "text": "Accessing data in vectors (Exercise)\nother tidyverse packages (stringr & forcats)\ndplyr table joins (Exercise)\nggplot2 scale functions\nggplot2 multi-panel figures (Exercise)\nggplot2 saving figures"
  },
  {
    "objectID": "exercises/ex-07.html#using-and",
    "href": "exercises/ex-07.html#using-and",
    "title": "R Bootcamp - Day 7",
    "section": "Using [, [[, and $\n",
    "text": "Using [, [[, and $\n\n[ can return a range, [[ returns a single value."
  },
  {
    "objectID": "exercises/ex-07.html#vector-selection-with-logic",
    "href": "exercises/ex-07.html#vector-selection-with-logic",
    "title": "R Bootcamp - Day 7",
    "section": "vector selection with logic",
    "text": "vector selection with logic\none-step filtering.\ntwo-step filtering. same result.\nalso can use with is.na() to identify / exclude NA values in a vector.\nUse sum() to figure out how many are TRUE."
  },
  {
    "objectID": "exercises/ex-07.html#string-operations-with-stringr",
    "href": "exercises/ex-07.html#string-operations-with-stringr",
    "title": "R Bootcamp - Day 7",
    "section": "string operations with stringr",
    "text": "string operations with stringr\nstringr provides several useful functions for operating on strings.\nSee the stringr cheatsheet\nstr_c() is similar to paste and paste0 but the behavior is more consistent."
  },
  {
    "objectID": "exercises/ex-07.html#forcats-operations-for-factors",
    "href": "exercises/ex-07.html#forcats-operations-for-factors",
    "title": "R Bootcamp - Day 7",
    "section": "forcats operations for factors",
    "text": "forcats operations for factors\nforcats provides several utilities for working with factors.\nSee the forcats cheatsheet"
  },
  {
    "objectID": "exercises/ex-07.html#use-forcats-to-reorder-aspects-of-plots",
    "href": "exercises/ex-07.html#use-forcats-to-reorder-aspects-of-plots",
    "title": "R Bootcamp - Day 7",
    "section": "Use forcats to reorder aspects of plots",
    "text": "Use forcats to reorder aspects of plots\nSee the FAQ on rordering in ggplot2"
  },
  {
    "objectID": "exercises/ex-07.html#dplyr-cheatsheet",
    "href": "exercises/ex-07.html#dplyr-cheatsheet",
    "title": "R Bootcamp - Day 7",
    "section": "dplyr cheatsheet",
    "text": "dplyr cheatsheet\nLook at “combine variables” and “combine cases” at the top."
  },
  {
    "objectID": "exercises/ex-07.html#tables-for-joining",
    "href": "exercises/ex-07.html#tables-for-joining",
    "title": "R Bootcamp - Day 7",
    "section": "tables for joining",
    "text": "tables for joining"
  },
  {
    "objectID": "exercises/ex-07.html#mutating-joins---visualized",
    "href": "exercises/ex-07.html#mutating-joins---visualized",
    "title": "R Bootcamp - Day 7",
    "section": "mutating joins - visualized",
    "text": "mutating joins - visualized"
  },
  {
    "objectID": "exercises/ex-07.html#joining-tables-by-a-variable---exercise-1",
    "href": "exercises/ex-07.html#joining-tables-by-a-variable---exercise-1",
    "title": "R Bootcamp - Day 7",
    "section": "Joining tables by a variable - Exercise 1",
    "text": "Joining tables by a variable - Exercise 1"
  },
  {
    "objectID": "exercises/ex-07.html#filtering-joins---visualized",
    "href": "exercises/ex-07.html#filtering-joins---visualized",
    "title": "R Bootcamp - Day 7",
    "section": "filtering joins - visualized",
    "text": "filtering joins - visualized"
  },
  {
    "objectID": "exercises/ex-07.html#joining-tables-by-a-variable---exercise-2",
    "href": "exercises/ex-07.html#joining-tables-by-a-variable---exercise-2",
    "title": "R Bootcamp - Day 7",
    "section": "Joining tables by a variable - Exercise 2",
    "text": "Joining tables by a variable - Exercise 2"
  },
  {
    "objectID": "exercises/ex-07.html#other-dplyr-verbs",
    "href": "exercises/ex-07.html#other-dplyr-verbs",
    "title": "R Bootcamp - Day 7",
    "section": "Other dplyr verbs",
    "text": "Other dplyr verbs\nThere are many other dplyr verbs.\n\nWe’ve used rename, count, add_row, add_column, distinct, sample_n, sample_frac, slice, pull\n\n\nCheck out the dplyr cheatsheet to learn more!"
  },
  {
    "objectID": "exercises/ex-07.html#scale-functions-in-ggplot2",
    "href": "exercises/ex-07.html#scale-functions-in-ggplot2",
    "title": "R Bootcamp - Day 7",
    "section": "scale functions in ggplot2",
    "text": "scale functions in ggplot2\n\n\nscale_color_brewer() and scale_fill_brewer() control color and fill aesthetics.\nSee available ggplot2 brewer palettes"
  },
  {
    "objectID": "exercises/ex-07.html#scale-functions-in-ggplot2-1",
    "href": "exercises/ex-07.html#scale-functions-in-ggplot2-1",
    "title": "R Bootcamp - Day 7",
    "section": "scale functions in ggplot2",
    "text": "scale functions in ggplot2"
  },
  {
    "objectID": "exercises/ex-07.html#set-up-a-points-plot",
    "href": "exercises/ex-07.html#set-up-a-points-plot",
    "title": "R Bootcamp - Day 7",
    "section": "Set up a points plot",
    "text": "Set up a points plot"
  },
  {
    "objectID": "exercises/ex-07.html#how-to-combine-multiple-plots-into-a-figure",
    "href": "exercises/ex-07.html#how-to-combine-multiple-plots-into-a-figure",
    "title": "R Bootcamp - Day 7",
    "section": "How to combine multiple plots into a figure?",
    "text": "How to combine multiple plots into a figure?"
  },
  {
    "objectID": "exercises/ex-07.html#we-have-4-legends---can-they-be-condensed",
    "href": "exercises/ex-07.html#we-have-4-legends---can-they-be-condensed",
    "title": "R Bootcamp - Day 7",
    "section": "We have 4 legends - can they be condensed?",
    "text": "We have 4 legends - can they be condensed?\nYes, but it is not exactly straightforward."
  },
  {
    "objectID": "exercises/ex-07.html#saving-plots-exercise-18",
    "href": "exercises/ex-07.html#saving-plots-exercise-18",
    "title": "R Bootcamp - Day 7",
    "section": "Saving plots (Exercise 18)",
    "text": "Saving plots (Exercise 18)\nSaves last plot as 5’ x 5’ file named plot_final.png in working directory.\nMatches file type to file extension."
  },
  {
    "objectID": "exercises/ex-04.html#todays-datasets",
    "href": "exercises/ex-04.html#todays-datasets",
    "title": "R Bootcamp - Day 4",
    "section": "Today’s datasets",
    "text": "Today’s datasets\nIn this class, we will use a data set from ggplot2: diamonds contains thousands of gem prices and qualities.\nThere are many interesting data sets you can install as R packages for learning to manipulate and plot data:\n\nbabynames\ngapminder\npalmerpenguins"
  },
  {
    "objectID": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "href": "exercises/ex-04.html#getting-familiar-with-the-data---exercise-1",
    "title": "R Bootcamp - Day 4",
    "section": "Getting familiar with the data - Exercise 1",
    "text": "Getting familiar with the data - Exercise 1"
  },
  {
    "objectID": "exercises/ex-04.html#the-syntax-of-ggplot",
    "href": "exercises/ex-04.html#the-syntax-of-ggplot",
    "title": "R Bootcamp - Day 4",
    "section": "The syntax of ggplot()\n",
    "text": "The syntax of ggplot()"
  },
  {
    "objectID": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "href": "exercises/ex-04.html#making-a-plot-step-by-step-exercise-2",
    "title": "R Bootcamp - Day 4",
    "section": "Making a plot step-by-step (Exercise 2)",
    "text": "Making a plot step-by-step (Exercise 2)\n\nInitialize a plot with data.\nNext, specify the coordinate system.\nAdd a geom (geom_point).\nMap aesthetics to other variables.\n\nReduce overplotting by adjusting the transparency of points."
  },
  {
    "objectID": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "href": "exercises/ex-04.html#looking-under-the-hood-of-ggplot-exercise-3",
    "title": "R Bootcamp - Day 4",
    "section": "Looking under the hood of ggplot (Exercise 3)",
    "text": "Looking under the hood of ggplot (Exercise 3)"
  },
  {
    "objectID": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "href": "exercises/ex-04.html#ggplot-is-powerfully-simple-for-making-complex-plots",
    "title": "R Bootcamp - Day 4",
    "section": "ggplot is powerfully simple for making complex plots",
    "text": "ggplot is powerfully simple for making complex plots\nWhy can’t I just do this?"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions",
    "href": "exercises/ex-04.html#geom-functions",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions",
    "text": "Geom functions\n\nUse a geom function to represent data points, use the geom aesthetic properties to represent variables.\nEach function returns a plot layer.\nThere are many geoms in ggplot that are specific to plots with 1, 2, or 3 variables\n\nMake a bar plot.\n\nUpdate the bar plot aesthetics.\n\nChange to a density plot.\n\nColor the density plot.\n\nPlot subsets by mapping fill to cut\n\nUse ggridges to plot staggered subsets.\nhttps://wilkelab.org/ggridges/"
  },
  {
    "objectID": "exercises/ex-04.html#geom-functions-for-two-variables",
    "href": "exercises/ex-04.html#geom-functions-for-two-variables",
    "title": "R Bootcamp - Day 4",
    "section": "Geom functions for two variables",
    "text": "Geom functions for two variables\nMake a column plot.\nSame data with a box plot.\n\nBox plot, with fill color by cut.\nViolin plot with fill color by cut."
  },
  {
    "objectID": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "href": "exercises/ex-04.html#continuous-x-continuous-y---exercise-6",
    "title": "R Bootcamp - Day 4",
    "section": "continuous x, continuous y - Exercise 6",
    "text": "continuous x, continuous y - Exercise 6\nSubset diamonds to see points more clearly.\nMake a scatter plot.\nNow add a smoothing line.\nHere we can combine geoms to see points & the fit"
  },
  {
    "objectID": "exercises/ex-02.html",
    "href": "exercises/ex-02.html",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000.\n\nR provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object&lt;80&gt;&lt;99&gt;s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1\n\nSome of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\n\ntail() - shows last 6 rows\n\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\n\nnrow() - number of rows\n\n\nncol() - number of columns\n\n\nnames() or colnames() - both show the names attribute for a data frame\n\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "href": "exercises/ex-02.html#data-sets-for-tidying---exercise-2",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Explore table1, table2, table3, table4a, table4b, and table5, which all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000."
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-3",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "R provides many functions to examine features of a data object\n\nView() - To open the table up in an excel-like interface - not recommended for large tables\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object&lt;80&gt;&lt;99&gt;s data type (low-level)?\nis_tibble() - use is.? to confirm data type\nstr() - what is the structure of the object?\nattributes() - does it have any metadata?\nLet’s explore table1"
  },
  {
    "objectID": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "href": "exercises/ex-02.html#getting-familiar-with-the-data---exercise-4",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "",
    "text": "Some of the useful functions for data.frames / tibbles are as follows:\n\n\nhead() - shows first 6 rows\n\n\ntail() - shows last 6 rows\n\n\ndim() - returns the dimensions of data frame (i.e. number of rows and number of columns)\n\n\nnrow() - number of rows\n\n\nncol() - number of columns\n\n\nnames() or colnames() - both show the names attribute for a data frame\n\nglimpse()"
  },
  {
    "objectID": "exercises/ex-02.html#pivot_wider---exercise-6",
    "href": "exercises/ex-02.html#pivot_wider---exercise-6",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_wider - Exercise 6",
    "text": "pivot_wider - Exercise 6\nWhat will the output look like?\nIf you want to save the output, assign it to a new variable. This new variable will appear in your Environment tab."
  },
  {
    "objectID": "exercises/ex-02.html#pivot_longer---exercise-7",
    "href": "exercises/ex-02.html#pivot_longer---exercise-7",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "pivot_longer - Exercise 7",
    "text": "pivot_longer - Exercise 7\nWhat will the output look like?"
  },
  {
    "objectID": "exercises/ex-02.html#separate---exercise-8",
    "href": "exercises/ex-02.html#separate---exercise-8",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "separate - Exercise 8",
    "text": "separate - Exercise 8\nWhat will the output look like?\nseparate_rows - Exercise 9"
  },
  {
    "objectID": "exercises/ex-02.html#unite---exercise-10",
    "href": "exercises/ex-02.html#unite---exercise-10",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "unite - Exercise 10",
    "text": "unite - Exercise 10"
  },
  {
    "objectID": "exercises/ex-02.html#missing-values",
    "href": "exercises/ex-02.html#missing-values",
    "title": "R Bootcamp - Day 2 - Exercises",
    "section": "Missing values",
    "text": "Missing values"
  },
  {
    "objectID": "course-info/team.html",
    "href": "course-info/team.html",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "Instructor\nE-mail\nSchedule a meeting\n\n\n\n\n\nJay Hesselberth\n\n\n\n\n\nNeel Mukherjee\n\n\n\n\n\nKent Riemondy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\nSchedule a meeting\n\n\n\n\n\nKathryn Walters\n\n\n\n\n\nBrandon Buck"
  },
  {
    "objectID": "course-info/team.html#teaching-team-and-office-hours",
    "href": "course-info/team.html#teaching-team-and-office-hours",
    "title": "MOLB 7950 — Teaching Team",
    "section": "",
    "text": "Instructor\nE-mail\nSchedule a meeting\n\n\n\n\n\nJay Hesselberth\n\n\n\n\n\nNeel Mukherjee\n\n\n\n\n\nKent Riemondy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor\nE-mail\nSchedule a meeting\n\n\n\n\n\nKathryn Walters\n\n\n\n\n\nBrandon Buck"
  },
  {
    "objectID": "course-info/support.html",
    "href": "course-info/support.html",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Mon-Fri afternoons from 1-3pm."
  },
  {
    "objectID": "course-info/support.html#how-to-get-help",
    "href": "course-info/support.html#how-to-get-help",
    "title": "MOLB 7950 — Getting help",
    "section": "",
    "text": "Course discussion will be through the Slack MOLB7950 organization.\nGuidelines for using Slack:\n\nUse dedicated channels for discussion in #class, questions about your #problem-sets, and your #final-project\nYou can ask for help by tagging the TAs in the #class channel. If you post @ta help, someone will start a thread where you can ask a question.\nIf needed, we can talk face-to-face via the /zoom integration.\n\n\n\n\n\nOur TAs will be available Mon-Fri afternoons from 1-3pm."
  },
  {
    "objectID": "course-info/final-projects.html",
    "href": "course-info/final-projects.html",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project."
  },
  {
    "objectID": "course-info/final-projects.html#short-proposal",
    "href": "course-info/final-projects.html#short-proposal",
    "title": "MOLB 7950 – Final Projects",
    "section": "",
    "text": "Please submit a short proposal for your final projects with the following information.\n\nthe names of people you are working with\na description of the data set you will be working worth. This can refer to a publication and/or contain a link to public data available at NCBI GEO.\na hypothesis (tentative) you will be testing\na few bullets on your planned analysis approach.\n\nPlease include this information in a quarto document in a new Posit cloud project."
  },
  {
    "objectID": "course-info/final-projects.html#overview",
    "href": "course-info/final-projects.html#overview",
    "title": "MOLB 7950 – Final Projects",
    "section": "Overview",
    "text": "Overview\n\nFinal projects can involve groups of 1-3 people.\nProjects are choose your own adventure:\n\nThe resource documents contain data sets in from human S. cerevisiae. For example, sub-nucleosomal fragments provide a DNA-based signal to understand chromatin transactions that lead to transcription.\nYou could find a data set on NCBI GEO of interest (e.g., relevant to your thesis work), and work it up with salmon, DEseq, and exploratory analysis. We are happy to help you work through the pseudo-alignment steps.\nYou can start with your own sequencing data (bulk/single-cell RNA seq, DNA sequencing)."
  },
  {
    "objectID": "course-info/final-projects.html#deliverables",
    "href": "course-info/final-projects.html#deliverables",
    "title": "MOLB 7950 – Final Projects",
    "section": "Deliverables",
    "text": "Deliverables\n\nA Quarto document with code, plots, interpretations, and next steps.\nIf you work in a group, list the members of the group at the top of the document, and make it clear which parts are your work by adding your initials to code chunks.\nShort presentations (5-8 minutes) by the groups the week of Nov 1. Presentations should include 1-2 slides of background, a hypothesis for the approach, code output (table or graph) that addresses the hypothesis, and one or more tests of the statistical significance of the observation."
  },
  {
    "objectID": "course-info/final-projects.html#grading-and-rubric",
    "href": "course-info/final-projects.html#grading-and-rubric",
    "title": "MOLB 7950 – Final Projects",
    "section": "Grading and rubric",
    "text": "Grading and rubric\nThe final project will be worth 20% of your grade and we will use the grading scheme outlined in the grading rubric.\nEach individual in a group will be evaluated separately, so contributions must be clearly marked in the document, using e.g. using chunk labels:\n\n```{r}\n#| label: plotting-code-by-jay-h\n#| eval: false\nggplot(mtcars, aes(hp, mpg)) + geom_point()\n```"
  },
  {
    "objectID": "course-info/problem-sets.html",
    "href": "course-info/problem-sets.html",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run"
  },
  {
    "objectID": "course-info/problem-sets.html#problem-set-overview",
    "href": "course-info/problem-sets.html#problem-set-overview",
    "title": "MOLB 7950 — Problem Sets",
    "section": "",
    "text": "We reinforce concepts with problem sets assigned at the end of each class. During the main blocks, problem sets on Mon and Wed should take ~60 minutes to complete. Problems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete. Together the problem sets constitute 60% of your grade.\n\n\n\nProblem sets are distributed as Posit Cloud assignments. You will work on problem sets in an Rmarkdown document in the assignment. When complete, complete your assignment by submitting the URL from your Posit Cloud assignment into the assignment submission on Canvas. We will grade your problem directly in the Posit Cloud assignment.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\n\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run"
  },
  {
    "objectID": "course-info/syllabus.html",
    "href": "course-info/syllabus.html",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 28 - Nov 1\n📍 Classes will be held in-person in AHSB 2200\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions."
  },
  {
    "objectID": "course-info/syllabus.html#course-overview",
    "href": "course-info/syllabus.html#course-overview",
    "title": "MOLB 7950 Syllabus",
    "section": "",
    "text": "MOLB 7950 is a hands-on tutorial of skills and theory needed to process, analyze, and visualize output from large biological data sets. We emphasize the R statistical computing environment.\n🗓️ Class will run from Aug 28 - Nov 1\n📍 Classes will be held in-person in AHSB 2200\n🕘 Class time is 9:00-10:30am\nMOLB 7950 is a three credit hour course.\nThe course is divided into blocks:\n\n\nTHe Bootcamp block covers R programming and introduces important statistical concepts and approaches. We will also cover data types you will encounter during biological data analysis and approaches for their analysis.\nDuring the bootcamp block, we will meet everyday for 90 minutes to cover fundamental concepts you will need throughout the course.\n\n\n\nAfter Bootcamp, will cover experimental approaches used to analyze DNA and RNA. Each block spans ~4 weeks, with each week focused on a particular type of experiment (see below). Each block covers statistical concepts needed for rigorous analysis and analysis approaches to process raw data to results (tables and figures) using reproducible coding techniques.\nIn most weeks we will discuss and analyze data from a publication. You are responsible for reading the week’s material before class begins on Monday.\n\n\n\nThe DNA block covers genome sequencing for identifying mutations, and two approaches for analyzing chromatin state (ChIP-seq and MNase-seq).\nThe RNA block covers RNA-seq, alternative splicing, differential gene expression, and RNA:protein interactions."
  },
  {
    "objectID": "course-info/syllabus.html#schedule",
    "href": "course-info/syllabus.html#schedule",
    "title": "MOLB 7950 Syllabus",
    "section": "Schedule",
    "text": "Schedule\nClasses begin on August 28 and end on November 1. Dates are from the Fall 2023 Academic Calendar.\nDuring the Bootcamp block, classes will be held every day, Mon-Fri from 9:00-10:30am.\nDuring the DNA & RNA blocks, we will have in-class exercises and discussion on Mon-Wed-Fri 9:00-10:30am."
  },
  {
    "objectID": "course-info/syllabus.html#location",
    "href": "course-info/syllabus.html#location",
    "title": "MOLB 7950 Syllabus",
    "section": "Location",
    "text": "Location\nClasses will be held in-person in AHSB 2201. All classes will be recorded and made available through Canvas."
  },
  {
    "objectID": "course-info/syllabus.html#policies",
    "href": "course-info/syllabus.html#policies",
    "title": "MOLB 7950 Syllabus",
    "section": "Policies",
    "text": "Policies\n\nAttendance\nClass attendance is a firm expectation; frequent absences or tardiness are considered cause for a grade reduction.\nif you are sick, please let us know (e-mail Jay and Neel) and stay home.\nAnticipated absences outside of sickness should be reported to the instructors of a given block as soon as possible to make plans for possible accommodation.\nWe will record all lectures on Panopto and they will be available online through Canvas.\n\n\nLate and missed work\nWe have a late work policy for homework assignments:\n\nIf a problem set set is late but within 24 hours of due date/time, the grade will be reduced by 50%\nIf a problem set is returned any later, no credit will be given.\nAll regrade requests must be discussed with the professor within one week of receiving your grade. There will be no grade changes after the final project.\n\n\n\nDiversity & Inclusiveness\nOur view is that students from all diverse backgrounds and perspectives will be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class iss a resource, strength, and benefit.\n\n\nDisability Policy\nStudents with disabilities who need accommodations are encouraged to contact the Office of Disability, Access & Inclusion as soon as possible to ensure that accommodations are implemented in a timely fashion.\n\n\nHonor code\nAcademic dishonesty will not be tolerated and is grounds for dismissal from the class with a failing grade (“F”). For other information, please consult the Graduate Student Handbook.\nChatGPT will probably be able to answer most coding questions you ask of it. While it is useful for fleshing out an initial approach from pseudocode, we do not recommend using it, as these conceptual approaches are an essential foundation for buildling expertise in bioinformatic analysis."
  },
  {
    "objectID": "course-info/syllabus.html#problem-sets",
    "href": "course-info/syllabus.html#problem-sets",
    "title": "MOLB 7950 Syllabus",
    "section": "Problem Sets",
    "text": "Problem Sets\n\nProblem sets will be assigned at the end of each class.\nYou can use external resources but must explicitly cite where you have obtained code (both code you used directly and “paraphrased” code / code used as inspiration). Any reused code that is not explicitly cited will be treated as plagiarism.\nYou can discuss the content of assignments with others in this class. If you do so, you must acknowledge your collaborator(s) at the top of your assignment, for example: “Collaborators: Hillary and Bernie”. Failure to acknowledge collaborators will result in a grade of 0. You may not copy code and/or answers directly from another student. If you copy other work, both parties will receive a grade of 0.\nThe problem set with the lowest score for each student will be dropped.\nRather than copying someone’s work, ask for help. You are not alone in this course!"
  },
  {
    "objectID": "course-info/syllabus.html#professionalism",
    "href": "course-info/syllabus.html#professionalism",
    "title": "MOLB 7950 Syllabus",
    "section": "Professionalism",
    "text": "Professionalism\n\nPlease refrain from texting or using your computer for anything other than coursework during class."
  },
  {
    "objectID": "course-info/syllabus.html#assignments-and-grading",
    "href": "course-info/syllabus.html#assignments-and-grading",
    "title": "MOLB 7950 Syllabus",
    "section": "Assignments and Grading",
    "text": "Assignments and Grading\nThe course measures learning through daily problem sets, a final project, and your participation.\n\n\n\nType\n% of grade\n\n\n\n\nProblem Sets\n60\n\n\nFinal Project\n20\n\n\nParticipation\n20\n\n\n\nGrades will be assigned as follows:\n\n\n\nPercent total points\nGrade\n\n\n\n\n&gt;= 95\nA\n\n\n&gt;= 90\nA-\n\n\n&gt;= 85\nB+\n\n\n&gt;= 80\nB\n\n\n\n\nProblem sets\nWe reinforce concepts with problem sets assigned at the end of class that should take ~60 minutes to complete.\nProblems sets assigned on Friday will be more substantial, requiring ~1-2 hours to complete.\nTogether the problem sets constitute 60% of your grade.\n\n\n\n\n\n\n\n\n\n\nAssigned\nDue\nGrades By\nWho grades\nTime to complete (approx)\n\n\n\n\nMon @ 12pm\nTues @ 5pm\nWed @ 5pm\nInstructors / TAs\n60 min\n\n\nTue @ 12pm\nWed @ 5pm\nThurs @ 5pm\nInstructors / TAs\n60 min\n\n\nWed @ 12pm\nThurs @ 5pm\nFri @ 5pm\nInstructors / TAs\n60 min\n\n\nThurs @ 12pm\nFri @ 5pm\nTues @ 5pm\nInstructors / TAs\n60 min\n\n\nFri @ 12pm\nMon @ 5pm\nWed @ 5pm\nInstructors / TAs\n1-2 hr\n\n\n\n\n\nFinal projects\nFinal projects can be completed in groups of 1-3 people. Projects will involve analysis of existing public data sets and end with a short presentation the last week of class. The final project constitutes 20% of your grade.\n\n\nGrading Rubrics\n\nProblem Set Rubric\nProblem sets are worth 60% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds Improvement\n\n\n\n\nCoding style\nStudent has gone beyond what was expected and required, coding manual is followed, code is well commented\nCoding style lacks refinement and has some errors, but code is readable and has some comments\nMany errors in coding style, little attention paid to making the code human readable\n\n\nCoding strategy\nComplicated problem broken down into sub-problems that are individually much simpler. Code is efficient, correct, and minimal. Code uses appropriate data structure (list, data frame, vector/matrix/array). Code checks for common errors\nCode is correct, but could be edited down to leaner code. Some “hacking” instead of using suitable data structure. Some checks for errors.\nCode tackles complicated problem in one big chunk. Code is repetitive and could easily be functionalized. No anticipation of errors.\n\n\nPresentation: graphs\nGraph(s) carefully tuned for desired purpose. One graph illustrates one point\nGraph(s) well chosen, but with a few minor problems: inappropriate aspect ratios, poor labels.\nGraph(s) poorly chosen to support questions.\n\n\nPresentation: tables\nTable(s) carefully constructed to make it easy to perform important comparisons. Careful styling highlights important features.\nTable(s) generally appropriate but possibly some minor formatting deficiencies.\nTable(s) with too many, or inconsistent, decimal places. Table(s) not appropriate for questions and findings. Major display problems.\n\n\nAchievement, mastery, cleverness, creativity\nStudent has gone beyond what was expected and required, e.g., extraordinary effort, additional tools not addressed by this course, unusually sophisticated application of tools from course.\nTools and techniques from the course are applied very competently and, perhaps,somewhat creatively. Chosen task was acceptable, but fairly conservative in ambition.\nStudent does not display the expected level of mastery of the tools and techniques in this course. Chosen task was too limited in scope.\n\n\nEase of access for instructor, compliance with course conventions for submitted work\nAccess as easy as possible, code runs!\nSatisfactory\nNot an earnest effort to reduce friction and comply with conventions and/or code does not run\n\n\n\n\n\nParticipation rubric\nAttendance & participation is worth 20% of your grade. Values in parentheses represent point values for each level from 20 points total. This rubric will be assessed at the end of the semester.\n\n\n\n\n\n\n\n\n\nCriteria\nExpert\nCompetent\nNeeds improvement\n\n\n\n\nAttendance (physically present for class, or coordinating with instructor when absent)\nAttends class regularly (5)\nAttends most classes (4)\nAttends some classes (0-3)\n\n\nPreparation (activities required for in-class participation, like surveys and software installation)\nCompletes requested activities prior to class (5)\nCompletes most requested activities prior to class, sometimes needs to finish during class (4)\nRarely completes requested activities prior to class, often takes class time to complete (0-3)\n\n\nEngagement (in-class activities like coding exercises and discussion)\nActively engages in class activities (10)\nSometimes engages in class activities (8)\nDoesn’t engage in class activities (0-7)"
  },
  {
    "objectID": "course-info/syllabus.html#related-coursework",
    "href": "course-info/syllabus.html#related-coursework",
    "title": "MOLB 7950 Syllabus",
    "section": "Related coursework",
    "text": "Related coursework\nIn previous iterations of this course, we taught command-line (bash, grep, awk, etc) and Python programming. These skills are useful, but for consistency we opted to focus on R programming and RStudio as an analysis environment.\nAMC also offers shorter workshops on specific analysis strategies that you might find helpful.\n\nBMSC 7810: Practical biological data analysis with R/RStudio (RBI fellows)\nMOLB 7900: Practical Computational Biology for Biologists — Python (Taliaferro and Ramachandran)\nMOLB 7910: Practical Computational Biology for Biologists — R/R Studio (Jagannathan and Mukherjee)"
  },
  {
    "objectID": "course-info/syllabus.html#acknowldgements-attribution",
    "href": "course-info/syllabus.html#acknowldgements-attribution",
    "title": "MOLB 7950 Syllabus",
    "section": "Acknowldgements & Attribution",
    "text": "Acknowldgements & Attribution\n\nInstructor contributions\nSeveral people have contributed to course development over the past several years.\n\nSujatha Jagannathan contributed the original R bootcamp material.\nSrinivas Ramachandran contributed material for the DNA block, including lecture material and examples for yeast chromatin accessibility and factor mapping.\nMatt Taliaferro contributed material for the RNA block, including lecture material and examples for RNA expression and splicing analysis.\nKent Riemondy and Kristen Wells contributed material for single-cell RNA sequencing.\nJay Hesselberth and Neel Mukherjee revamped much of this material in Fall 2023.\n\n\n\nExternal resources\nWe have borrowed from several (open licensed) resources for course content, including:\n\nStats 545 at UBC, particularly their grading rubrics\nCourses from Mine Çetinkaya-Rundel, particularly inspiration for quarto websites"
  },
  {
    "objectID": "exercises/ex-01.html",
    "href": "exercises/ex-01.html",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#rstudio---exercise-1",
    "href": "exercises/ex-01.html#rstudio---exercise-1",
    "title": "R Bootcamp - Day 1",
    "section": "",
    "text": "We are using RStudio through Posit Cloud for the class.\nLook at RStudio panels one at a time.\nEnvironment, History, Console, Files, Plots, Packages, Help, etc.\n\nSee menu:\nHelp &gt; Cheat Sheets &gt; RStudio IDE Cheat Sheet"
  },
  {
    "objectID": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "href": "exercises/ex-01.html#r-as-a-calculator---exercise-2",
    "title": "R Bootcamp - Day 1",
    "section": "R as a calculator - Exercise 2",
    "text": "R as a calculator - Exercise 2\n\nR can function like an advanced calculator\n\n\nTry simple math.\nAssign a numeric value to an object.\n\n\n&lt;- and = are assignment operators.\nBy convention, R programmers use &lt;-.\n\nx &lt;- 1 reads “set the value of x to 1”.\n\n. . .\n= and == are two different operators.\n\na = is used for assignment (e.g., x = 1)\na == tests for equivalence (e.g. x == 1 says “does x equal 1?”)"
  },
  {
    "objectID": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "href": "exercises/ex-01.html#functions-and-arguments---exercise-3",
    "title": "R Bootcamp - Day 1",
    "section": "Functions and arguments - Exercise 3",
    "text": "Functions and arguments - Exercise 3"
  },
  {
    "objectID": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "href": "exercises/ex-01.html#writing-a-simple-function---exercise-4",
    "title": "R Bootcamp - Day 1",
    "section": "Writing a simple function - Exercise 4",
    "text": "Writing a simple function - Exercise 4"
  },
  {
    "objectID": "exercises/ex-01.html#data-types---exercise-5",
    "href": "exercises/ex-01.html#data-types---exercise-5",
    "title": "R Bootcamp - Day 1",
    "section": "Data types - Exercise 5",
    "text": "Data types - Exercise 5\n\nThere are many data types in R.\nWe’ll mainly use numeric, character, and logical."
  },
  {
    "objectID": "exercises/ex-01.html#vectors---exercise-6",
    "href": "exercises/ex-01.html#vectors---exercise-6",
    "title": "R Bootcamp - Day 1",
    "section": "Vectors - Exercise 6",
    "text": "Vectors - Exercise 6\nLet’s create some vectors.\n\nThe c function combines values together (e.g., c(1,2,3))\n\n. . ."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames",
    "href": "exercises/ex-01.html#data-frames",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames",
    "text": "Data frames\n\nA data.frame is a rectangle, where each column is a vector, and each row is a slice across vectors.\ndata.frame columns are vectors, and can have different types (numeric, character, factor, etc.).\nA data.frame is constructed with data.frame()."
  },
  {
    "objectID": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "href": "exercises/ex-01.html#data-frames-tibbles---exercise-7",
    "title": "R Bootcamp - Day 1",
    "section": "Data frames & tibbles - Exercise 7",
    "text": "Data frames & tibbles - Exercise 7\nCreate a data.frame and tibble.\nNow echo the contents of df and tbl to the console and inspect"
  },
  {
    "objectID": "exercises/ex-01.html#r-packages---exercise-8",
    "href": "exercises/ex-01.html#r-packages---exercise-8",
    "title": "R Bootcamp - Day 1",
    "section": "R packages - Exercise 8",
    "text": "R packages - Exercise 8\nLet’s do the following to explore R packages:\n\nLook at the “Environment” panel in Rstudio\nExplore Global Environment\nExplore the contents of a package"
  },
  {
    "objectID": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "href": "exercises/ex-01.html#quarto-exercise---exercise-9",
    "title": "R Bootcamp - Day 1",
    "section": "Quarto Exercise - Exercise 9",
    "text": "Quarto Exercise - Exercise 9\nLet’s do the following to explore Quarto documents:\n\nCreate a new Quarto document\nRender the document to see the output"
  },
  {
    "objectID": "exercises/ex-01.html#problem-sets-and-submission",
    "href": "exercises/ex-01.html#problem-sets-and-submission",
    "title": "R Bootcamp - Day 1",
    "section": "Problem sets and submission",
    "text": "Problem sets and submission\nYour first problem set is in problem-sets/ps-01.qmd"
  },
  {
    "objectID": "exercises/ex-03.html",
    "href": "exercises/ex-03.html",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#todays-datasets---exercise-1",
    "href": "exercises/ex-03.html#todays-datasets---exercise-1",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "",
    "text": "Explore these data sets:\n\ndplyr::starwars\n\ndplyr::band_members, dplyr::band_instruments, dplyr::band_instruments2"
  },
  {
    "objectID": "exercises/ex-03.html#arrange---exercise-2",
    "href": "exercises/ex-03.html#arrange---exercise-2",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "arrange - Exercise 2",
    "text": "arrange - Exercise 2"
  },
  {
    "objectID": "exercises/ex-03.html#filter---exercise-3",
    "href": "exercises/ex-03.html#filter---exercise-3",
    "title": "R Bootcamp - Day 3 - Exercises",
    "section": "filter - Exercise 3",
    "text": "filter - Exercise 3\nfilter by membership\n\n# filter based on skin color\n\nConditions can be combined using & (and), | (or).\n\n# filter on skin and eye color\n\nselect - Exercise 4\nmutate (& pipe |&gt;)- Exercise 5\n\n# create a new column to display height in meters\n\n# using the pipe to feed data into multiple functions sequentially\n\n# mutate allows you to refer to columns that you&lt;e2&gt;&lt;80&gt;&lt;99&gt;ve just created\n\n# output needs to be saved into a new dataframe since dplyr does not \"change\" the original dataframe\n\n# using if_else clauses with mutate\n\nrowwise operations (if time permits)\n\n# let's input data (same one used in yesterday's problem set)\n# data &lt;- read_csv(file = \"data/data_transcript_exp_subset.csv\")\n\n# calculate mean for each time point using mutate in a rowwise fashion!\n\nsummarise - Exercise 6\ngroup_by + summarize - Exercise 7"
  },
  {
    "objectID": "exercises/ex-05.html",
    "href": "exercises/ex-05.html",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#class-4-5-outline",
    "href": "exercises/ex-05.html#class-4-5-outline",
    "title": "R Bootcamp - Day 5",
    "section": "",
    "text": "Introduce ggplot2 & today’s data sets (Exercise 1)\nUnderstand the basics of ggplot2 (Exercise 2, 3)\nGeom functions (Exercise 4-8)\nGeom_point properties (Exercise 9)\nPosition adjustments (Exercise 10)\nCoordinate and Scale Functions (Exercise 11)\nZooming into a plot (Exercise 12)\n\n\n\nFaceting (Exercise 13)\nThemes (Exercise 14)\nLabels & Legends (Exercise 15)\nAdding lines to plots (Exercise 16)\nMaking multi-panel figures (Exercise 17)\nSaving a plot (Exercise 18)"
  },
  {
    "objectID": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "href": "exercises/ex-05.html#shape-size-fill-color-and-transparency---exercise-9",
    "title": "R Bootcamp - Day 5",
    "section": "shape, size, fill, color, and transparency - Exercise 9",
    "text": "shape, size, fill, color, and transparency - Exercise 9\nGet a diamonds subset.\nNote that aesthetics can also be defined within a geom.\nThis is useful if you use two different geoms that share an aesthetic."
  },
  {
    "objectID": "exercises/ex-05.html#position-adjustments---exercise-10",
    "href": "exercises/ex-05.html#position-adjustments---exercise-10",
    "title": "R Bootcamp - Day 5",
    "section": "Position adjustments - Exercise 10",
    "text": "Position adjustments - Exercise 10\nA stacked bar chart.\nDodged bars are easier to read (proportions are clearer)"
  },
  {
    "objectID": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "href": "exercises/ex-05.html#coordinate-and-scale-functions---exercise-11",
    "title": "R Bootcamp - Day 5",
    "section": "Coordinate and Scale Functions - Exercise 11",
    "text": "Coordinate and Scale Functions - Exercise 11\nLogarithmic axes - 1\nNote the difference between axis labels in these two examples.\n\nLogarithmic axes - 2\n\nFlipping coordinate system (swapping x and y)\n\nNow flip the axis.\nBrief aside: ggplot can handle on-the-fly data transformations.\nHere we log-transform carat and convert USD to CAD."
  },
  {
    "objectID": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "href": "exercises/ex-05.html#zooming-into-a-plot---exercise-12",
    "title": "R Bootcamp - Day 5",
    "section": "Zooming into a plot - Exercise 12",
    "text": "Zooming into a plot - Exercise 12\nWe might want to change the limits of x or y axes to zoom in."
  },
  {
    "objectID": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "href": "exercises/ex-05.html#faceting-to-plot-subsets-of-data-into-separate-panels---exercise-13",
    "title": "R Bootcamp - Day 5",
    "section": "Faceting to plot subsets of data into separate panels - Exercise 13",
    "text": "Faceting to plot subsets of data into separate panels - Exercise 13\nA density plot we’ve seen before.\nWhich variables can we use to subdivide the data?\n\nFaceted by cut\nLet’s also use facet_grid() to facet by two variables.\nFaceted by clarity and cut.\n\nScatter plot with facets."
  },
  {
    "objectID": "exercises/ex-05.html#themes---exercise-14",
    "href": "exercises/ex-05.html#themes---exercise-14",
    "title": "R Bootcamp - Day 5",
    "section": "Themes - Exercise 14",
    "text": "Themes - Exercise 14\nScatter plot with default theme.\nChange the theme with theme_bw().\nMy go-to is cowplot::theme_cowplot().\nIt implements much of the advice in the “Dataviz” book, i.e.. YOUR LABELS ARE TOO SMALL.\nWe’re not going to cover it, but you can also customize pre-existing themes."
  },
  {
    "objectID": "exercises/ex-05.html#labels-legends---exercise-15",
    "href": "exercises/ex-05.html#labels-legends---exercise-15",
    "title": "R Bootcamp - Day 5",
    "section": "Labels & Legends - Exercise 15",
    "text": "Labels & Legends - Exercise 15\nUse labs() to add / change plot labels."
  },
  {
    "objectID": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "href": "exercises/ex-05.html#how-to-add-a-line-to-a-plot-exercise-16",
    "title": "R Bootcamp - Day 5",
    "section": "How to add a line to a plot? (Exercise 16)",
    "text": "How to add a line to a plot? (Exercise 16)\n\nAlso try:"
  },
  {
    "objectID": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "href": "exercises/ex-05.html#how-to-combine-multiple-plots-into-a-figure-exercise-17",
    "title": "R Bootcamp - Day 5",
    "section": "How to combine multiple plots into a figure? (Exercise 17)",
    "text": "How to combine multiple plots into a figure? (Exercise 17)\nWe have 4 legends - can they be condensed?\nYes, but it is not exactly straightforward.\nneed to scroll below"
  },
  {
    "objectID": "exercises/ex-05.html#saving-plots-exercise-18",
    "href": "exercises/ex-05.html#saving-plots-exercise-18",
    "title": "R Bootcamp - Day 5",
    "section": "Saving plots (Exercise 18)",
    "text": "Saving plots (Exercise 18)\nSaves last plot as 5’ x 5’ file named “plot_final.png” in working directory.\nMatches file type to file extension."
  },
  {
    "objectID": "exercises/ex-08.html",
    "href": "exercises/ex-08.html",
    "title": "Exercises 8",
    "section": "",
    "text": "Putting it all together\nFor the next two classes we’ll combine everything we’ve learned to process and visualize data from some some biological experiments. These exercises will illustrate a complete analysis pipeline – from data tidying to manipulation and visualization – using tools from the tidyverse.\n\nLibraries\nLoad the libraries you need for analysis below.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(cowplot)\n\nA quantitative PCR experiment\nHere is the experimental setup:\n\nTwo cell lines (wt and mut) were treated with a drug that induces interferon expression\nAfter specific time points, cells were harvested and actin and interferon mRNA were analyzed by quantitative PCR (with 3 technical replicates), with a control containing no reverse transcriptase.\n\nLoad the data\nThese data are in two TSV files:\n\ndata/qpcr_names.tsv.gz\ndata/qpcr_data.tsv.gz\n\nLoad these data sets and inspect.\n\nqpcr_names &lt;- read_tsv(here(\"data/qpcr_names.tsv.gz\"))\n\nRows: 8 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (13): row, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nqpcr_data &lt;- read_tsv(here(\"data/qpcr_data.tsv.gz\"))\n\nRows: 8 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): row\ndbl (12): 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote the shape of the data and the names of the rows and columns. Do they remind you of anything?\n\nTidy the data\nGiven the experimental setup and the shape of the tibbles, you should be able to answer: Are these data tidy?\n\nWhat are the variables in the data?\nAre the variables the column names?\n\n\nqpcr_data_long &lt;-\n  pivot_longer(qpcr_data, -row, names_to = \"col\")\n\nqpcr_names_long &lt;- \n  pivot_longer(qpcr_names, -row, names_to = \"col\") |&gt;\n  separate(\n    value,\n    into = c(\"gt\", \"time\", \"gene\", \"rt\", \"rep\"),\n    sep = \"_\"\n  )\n\nMerge the data\nNote the structure of the tidied data. What columns (variables) are shared by both tibbles?\nHow we can join the data from these two tibbles, linking the sample identifiers with their gene expression values?\n\nqpcr_tidy &lt;-\n  left_join(qpcr_names_long, qpcr_data_long) |&gt;\n  # we don't need row & col anymore.\n  # the -RT samples are all 0, so we can drop those, too\n  filter(rt == \"+\") |&gt;\n  select(-(row:col), -rt)\n\nJoining with `by = join_by(row, col)`\n\n\nSummarize the data\nCalculate the mean and standard deviation across replicates.\nDo this two ways:\n\nCalculate the statistics for each gene separately.\nCalculate a ratio of interferon to actin levels for each sample before calculating the mean and standard deviation of the ratios.\n\n\nqpcr_summary &lt;-\n  group_by(\n    qpcr_tidy,\n    gt, time, gene) |&gt;\n  summarize(\n    exp_mean = mean(value),\n    exp_sd = sd(value)\n  ) |&gt;\n  arrange(gt, time, gene)\n\n`summarise()` has grouped output by 'gt', 'time'. You can override using the\n`.groups` argument.\n\n\nPlot the data\nNow we can plot the summary statistics. We’ll use ggplot2::geom_pointrange() to represent the mean and standard deviation.\nYou’ll need to fill in the blanks (___) below.\n\nggplot(\n  qpcr_summary,\n  aes(\n    x = ___,\n    y = ___,\n    color = ___\n  ),\n) +\n  geom_pointrange(\n    aes(\n      ymin = ___,\n      ymax = ___ \n    ),\n    # position = ___\n  )\n\nInspect the above plot. How might you improve it?\nCopy the above chunk and add functions that modify the plot’s look and feel.\n\nFacet the plot to see differences between the genotypes.\nUpdate the theme using cowplot.\nUpdate the x, y, and title labels (ggplot2::labs()).\nUpdate the colors with a nicer palette (ggplot2::scale_*).\nFix the position of the geoms by updating their position aesthetic.\nInterpret the plot\n\nWhat can you say about the expression of ACTIN and IFN?\nWhat can you say about the mutant and wild-type cells?"
  },
  {
    "objectID": "exercises/ex-10.html",
    "href": "exercises/ex-10.html",
    "title": "Stats Bootcamp - class 10",
    "section": "",
    "text": "Flip a coin 5 times with equal prob of H or T\nAgain\n. . .\nSet a seed\n\n#\n\n\n#"
  },
  {
    "objectID": "exercises/ex-10.html#lets-flip-a-fair-coin",
    "href": "exercises/ex-10.html#lets-flip-a-fair-coin",
    "title": "Stats Bootcamp - class 10",
    "section": "",
    "text": "Flip a coin 5 times with equal prob of H or T\nAgain\n. . .\nSet a seed\n\n#\n\n\n#"
  },
  {
    "objectID": "exercises/ex-10.html#lets-flip-an-unfair-coin",
    "href": "exercises/ex-10.html#lets-flip-an-unfair-coin",
    "title": "Stats Bootcamp - class 10",
    "section": "Let’s flip an unfair coin",
    "text": "Let’s flip an unfair coin\nFlip a coin 5 times with equal prob of H or T\nAgain"
  },
  {
    "objectID": "exercises/ex-10.html#lets-summarize-the-flipping-results",
    "href": "exercises/ex-10.html#lets-summarize-the-flipping-results",
    "title": "Stats Bootcamp - class 10",
    "section": "Let’s summarize the flipping results",
    "text": "Let’s summarize the flipping results\nFlip a fair coin 10\nFlip a fair coin 10 and calculate mean\nAgain\n. . .\nUnfair coin\nUnfair coin, again"
  },
  {
    "objectID": "exercises/ex-10.html#lets-go-wild-flipping",
    "href": "exercises/ex-10.html#lets-go-wild-flipping",
    "title": "Stats Bootcamp - class 10",
    "section": "Let’s go wild flipping",
    "text": "Let’s go wild flipping\nFlip a fair coin 10 times and calculate mean. Then do 5 rounds of that experiment.\n. . .\nSame thing for an unfair coin."
  },
  {
    "objectID": "exercises/ex-10.html#tidy-and-visualize-flips",
    "href": "exercises/ex-10.html#tidy-and-visualize-flips",
    "title": "Stats Bootcamp - class 10",
    "section": "Tidy and visualize flips",
    "text": "Tidy and visualize flips\nmake a dataframe with means and accompanying info\n. . .\nplot it"
  },
  {
    "objectID": "exercises/ex-10.html#play-around-some-more",
    "href": "exercises/ex-10.html#play-around-some-more",
    "title": "Stats Bootcamp - class 10",
    "section": "Play around some more",
    "text": "Play around some more"
  },
  {
    "objectID": "exercises/ex-12.html",
    "href": "exercises/ex-12.html",
    "title": "Stats Bootcamp - class 12",
    "section": "",
    "text": "We are going to use ggpubr rather than ggplot2 - Don’t tell Jay ;)\n\n\nIt has great visualization for the stats on the plots.\nDifferent syntax!!\n\nmust use double quotes around “variable names”\n\n\n\n\nDue to reviewer #3, we will pivot to a more “physiologically relevant” data set biochem that consists of mouse measurements.\n\n. . ."
  },
  {
    "objectID": "exercises/ex-12.html#two-changes",
    "href": "exercises/ex-12.html#two-changes",
    "title": "Stats Bootcamp - class 12",
    "section": "",
    "text": "We are going to use ggpubr rather than ggplot2 - Don’t tell Jay ;)\n\n\nIt has great visualization for the stats on the plots.\nDifferent syntax!!\n\nmust use double quotes around “variable names”\n\n\n\n\nDue to reviewer #3, we will pivot to a more “physiologically relevant” data set biochem that consists of mouse measurements.\n\n. . ."
  },
  {
    "objectID": "exercises/ex-12.html#prepare-mouse-biochem-data",
    "href": "exercises/ex-12.html#prepare-mouse-biochem-data",
    "title": "Stats Bootcamp - class 12",
    "section": "Prepare mouse biochem data",
    "text": "Prepare mouse biochem data\n\n# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt; \n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-12.html#compare-mean-of-a-variable-to-a-known-value",
    "href": "exercises/ex-12.html#compare-mean-of-a-variable-to-a-known-value",
    "title": "Stats Bootcamp - class 12",
    "section": "Compare mean of a variable to a known value",
    "text": "Compare mean of a variable to a known value\n\\(y\\) is independent of \\(x\\)\n\\(y\\) is continuous\n\\(x\\) is constant\nParametric: One-sample t-test\nt_test(y ~ 1, mu = x)\nNonparametric: Wilcoxon signed-rank\nwilcox_test(y ~ 1, mu = x)\n\nExamine and specify the variable(s)\nDeclare null hypothesis \\(\\mathcal{H}_0\\)\n\nCalculate test-statistic, exact p-value\n\nThink did the expression of my gene change…"
  },
  {
    "objectID": "exercises/ex-12.html#examine-and-specify-the-variables",
    "href": "exercises/ex-12.html#examine-and-specify-the-variables",
    "title": "Stats Bootcamp - class 12",
    "section": "1. Examine and specify the variable(s)",
    "text": "1. Examine and specify the variable(s)\nLet’s explore mouse \\(weight\\)\n\nggdensity(\n  data = b,\n  x = \"??\",\n  add = \"mean\",\n  rug = TRUE\n  )\n\n. . .\nlet’s see some summary stats\n\nb |&gt; \n  get_summary_stats(\n    ??,\n    type = \"common\",\n    show = c(\"mean\",\"median\",\"sd\")\n    )"
  },
  {
    "objectID": "exercises/ex-12.html#is-it-normally-distributed",
    "href": "exercises/ex-12.html#is-it-normally-distributed",
    "title": "Stats Bootcamp - class 12",
    "section": "Is it normally distributed?",
    "text": "Is it normally distributed?\n\nggqqplot(\n  data = b,\n  x = \"??\"\n  )\n\nLooks reasonable\n. . .\n\nb |&gt; \n  ??_test(weight)\n\nYikes!\nNo easy answers…gotta make a call. We’ll try both."
  },
  {
    "objectID": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0",
    "href": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0",
    "title": "Stats Bootcamp - class 12",
    "section": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n",
    "text": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\nSince this is a one-way test, we don’t need to worry if the groups have equal variance (only 1 group). But, we need a standard to compare against. I asked google, how much does a mouse weigh in grams?\nAnswer: 20-35 g, I’m going with \\(27.5 g\\) as our standard.\n\n\\(\\mathcal{H}_0\\) is that the mean of mouse \\(weight\\) can be explained by \\(27.5\\)\n\n\\(weight\\) is the response variable\n\\(27.5\\) is the explanatory variable"
  },
  {
    "objectID": "exercises/ex-12.html#calculate-test-statistic-exact-p-value",
    "href": "exercises/ex-12.html#calculate-test-statistic-exact-p-value",
    "title": "Stats Bootcamp - class 12",
    "section": "3. Calculate test-statistic, exact p-value",
    "text": "3. Calculate test-statistic, exact p-value\nNonparametric test:\n\nx &lt;- 27.5 # standard from google\n\nb |&gt;\n  ??_test(weight ~ 1, mu = ??) |&gt;\n  gt()\n\n. . .\nParametric test:\n\nx &lt;- 27.5 # standard from google\n\nb |&gt;\n  ??_test(weight ~ 1, mu = ??) |&gt;\n  gt()\n\n. . .\nP values are well below 0.05\n\n\\(\\mathcal{H}_0\\) is that the mean of mouse \\(weight\\) can be explained by \\(27.5\\) is NOT WELL SUPPORTED\n\nSo \\(27.5 g\\) not able to describe weight\nNot surprising since our mean mouse weight is 20.2. Don’t believe everything you read on the internet."
  },
  {
    "objectID": "exercises/ex-12.html#compare-mean-of-two-groups",
    "href": "exercises/ex-12.html#compare-mean-of-two-groups",
    "title": "Stats Bootcamp - class 12",
    "section": "Compare mean of two groups",
    "text": "Compare mean of two groups\n\\(y\\) is independent of \\(x\\)\n\\(y\\) is continuous\n\\(x\\) is categorical with 2 groups (factor w/2 levels)\nParametric: Student’s t-test\nt_test(y ~ x) more here\nneed to pay attention to: var.equal paired\nNonparametric: Wilcoxon signed-rank\nwilcox_test(y ~ x) more here\nneed to pay attention to: paired\n\nExamine and specify the variable(s)\nDeclare null hypothesis \\(\\mathcal{H}_0\\)\n\nCalculate test-statistic, exact p-value"
  },
  {
    "objectID": "exercises/ex-12.html#tangent-on-students-t-test",
    "href": "exercises/ex-12.html#tangent-on-students-t-test",
    "title": "Stats Bootcamp - class 12",
    "section": "Tangent on Student’s t-test",
    "text": "Tangent on Student’s t-test\nThe T-Distribution, also known as Student’s t-distribution, gets its name from William Sealy Gosset who first published it in English in 1908 in the scientific journal Biometrika using his pseudonym “Student” because his employer preferred staff to use pen names when publishing scientific papers instead of their real name, so he used the name “Student” to hide his identity."
  },
  {
    "objectID": "exercises/ex-12.html#guinness-brewery-in-dublin",
    "href": "exercises/ex-12.html#guinness-brewery-in-dublin",
    "title": "Stats Bootcamp - class 12",
    "section": "Guinness Brewery in Dublin",
    "text": "Guinness Brewery in Dublin"
  },
  {
    "objectID": "exercises/ex-12.html#examine-and-specify-the-variables-1",
    "href": "exercises/ex-12.html#examine-and-specify-the-variables-1",
    "title": "Stats Bootcamp - class 12",
    "section": "1. Examine and specify the variable(s)",
    "text": "1. Examine and specify the variable(s)\nWe will compare mouse \\(weight\\) by \\(sex\\).\n\\(weight\\) is the response variable\n\\(sex\\) is the explanatory variable\n\\(y\\) ~ \\(x\\)\n\\(weight\\) ~ \\(sex\\)\n\nggdensity(\n  data = b,\n  color = \"sex\",\n  x = \"weight\",\n  add = \"mean\",\n  rug = TRUE\n  )\n\n\nI want the response variable on the \\(y\\) axis and the explanatory variable on the \\(x\\) axis.\nViolin plot\n\nggviolin(\n  data = b,\n  y = \"??\",\n  x = \"??\",\n  fill = \"??\",\n  add = \"mean_sd\"\n  )\n\n. . .\n\nb |&gt; \n  group_by(??) |&gt;\n  get_summary_stats(\n    ??,\n    type = \"common\",\n    show = c(\"mean\",\"median\",\"sd\")\n    )"
  },
  {
    "objectID": "exercises/ex-12.html#is-it-normally-distributed-1",
    "href": "exercises/ex-12.html#is-it-normally-distributed-1",
    "title": "Stats Bootcamp - class 12",
    "section": "Is it normally distributed?",
    "text": "Is it normally distributed?\n\nggqqplot(\n  data = b,\n  x = \"??\",\n  color = \"??\"\n  )\n\n. . .\n\nb |&gt; \n  group_by(sex) |&gt;\n  ??_test(weight) |&gt;\n  gt()\n\nLooks reasonable"
  },
  {
    "objectID": "exercises/ex-12.html#equal-variance",
    "href": "exercises/ex-12.html#equal-variance",
    "title": "Stats Bootcamp - class 12",
    "section": "Equal variance?",
    "text": "Equal variance?\n\nb |&gt; \n  ??_test(weight~sex) |&gt;\n  gt()\n\nOK - so we can use t-test, but variance is not equal."
  },
  {
    "objectID": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-1",
    "href": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-1",
    "title": "Stats Bootcamp - class 12",
    "section": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n",
    "text": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\n\\(\\mathcal{H}_0\\) is that \\(sex\\) cannot explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-1",
    "href": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-1",
    "title": "Stats Bootcamp - class 12",
    "section": "3. Calculate test-statistic, exact p-value",
    "text": "3. Calculate test-statistic, exact p-value\nNonparametric test:\n\nb |&gt;\n  ??_test(?? ~ ??, ref.group = \"F\") |&gt;\n  gt()\n\n. . .\nParametric test:\n\nx &lt;- 27.5 # standard from google\n\nb |&gt;\n  ??_test(weight ~ sex,\n         var.equal = ??,\n         ref.group = \"F\") |&gt;\n  gt()\n\n. . .\nP values are well below 0.05\n\n\\(\\mathcal{H}_0\\) is that \\(sex\\) cannot explain \\(weight\\) is NOT WELL SUPPORTED\n\n\\(sex\\) can explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#visualize-the-result",
    "href": "exercises/ex-12.html#visualize-the-result",
    "title": "Stats Bootcamp - class 12",
    "section": "Visualize the result",
    "text": "Visualize the result\n\n# save statistical test result\nstatres &lt;- b |&gt;\n  t_test(weight ~ sex,\n         var.equal = F, \n         ref.group = \"F\")\n\n\nggviolin(\n  data = b,\n  y = \"weight\",\n  x = \"sex\",\n  fill = \"sex\",\n  add = \"mean_sd\"\n  ) +\n  stat_pvalue_manual(\n    ??,\n    label = \"p\",\n    y.position = 34 \n    ) +\n  ylim(10,35)"
  },
  {
    "objectID": "exercises/ex-12.html#compare-means-of-three-or-more-groups",
    "href": "exercises/ex-12.html#compare-means-of-three-or-more-groups",
    "title": "Stats Bootcamp - class 12",
    "section": "Compare means of three or more groups",
    "text": "Compare means of three or more groups\n\\(y\\) is independent of \\(x\\)\n\\(y\\) is continuous\n\\(x\\) is 2 or more groups of categorical data\nParametric: ANOVA\nanova_test(y ~ group) more info\nNonparametric: Kruskal-Wallis test\nkruskal_test(y ~ group) more info\n\nExamine and specify the variable(s)\nDeclare null hypothesis \\(\\mathcal{H}_0\\)\n\nCalculate test-statistic, exact p-value"
  },
  {
    "objectID": "exercises/ex-12.html#examine-and-specify-the-variables-2",
    "href": "exercises/ex-12.html#examine-and-specify-the-variables-2",
    "title": "Stats Bootcamp - class 12",
    "section": "1. Examine and specify the variable(s)",
    "text": "1. Examine and specify the variable(s)\nWe will compare mouse \\(weight\\) by \\(family\\).\n\\(weight\\) is the response variable\n\\(family\\) is the explanatory variable\n\\(y\\) ~ \\(x\\)\n\\(weight\\) ~ \\(family\\)\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\"B1.5:E1.4(4) B1.5:A1.4(5)\",\n            \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n            \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n            \"D5.4:G2.3(4) D5.4:C4.3(4)\")\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels() \n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref =\"B1\")"
  },
  {
    "objectID": "exercises/ex-12.html#visualize-the-variables",
    "href": "exercises/ex-12.html#visualize-the-variables",
    "title": "Stats Bootcamp - class 12",
    "section": "Visualize the variable(s)",
    "text": "Visualize the variable(s)\nI want the response variable on the \\(y\\) axis and the explanatory variable on the \\(x\\) axis.\nBoxplot\n\nggboxplot(\n  data = bfam,\n  y = \"??\",\n  x = \"??\",\n  fill = \"??\"\n  )\n\n. . .\n\nbfam |&gt; \n  group_by(??) |&gt;\n  get_summary_stats(\n    ??,\n    type = \"common\",\n    show = c(\"mean\",\"median\",\"sd\")\n    )"
  },
  {
    "objectID": "exercises/ex-12.html#is-it-normally-distributed-2",
    "href": "exercises/ex-12.html#is-it-normally-distributed-2",
    "title": "Stats Bootcamp - class 12",
    "section": "Is it normally distributed?",
    "text": "Is it normally distributed?\n\nggqqplot(\n  data = bfam,\n  x = \"weight\",\n  color = \"??\"\n  )\n\n. . .\n\nbfam |&gt; \n  group_by(family) |&gt;\n  ??_test(weight) |&gt;\n  gt()\n\nLooks reasonable"
  },
  {
    "objectID": "exercises/ex-12.html#equal-variance-1",
    "href": "exercises/ex-12.html#equal-variance-1",
    "title": "Stats Bootcamp - class 12",
    "section": "Equal variance?",
    "text": "Equal variance?\n\nbfam |&gt; \n  ??_test(??~??) |&gt;\n  gt()\n\nOK - so we can use anova!"
  },
  {
    "objectID": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-2",
    "href": "exercises/ex-12.html#declare-null-hypothesis-mathcalh_0-2",
    "title": "Stats Bootcamp - class 12",
    "section": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n",
    "text": "2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\n\\(\\mathcal{H}_0\\) is that \\(family\\) cannot explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-2",
    "href": "exercises/ex-12.html#calculate-test-statistic-exact-p-value-2",
    "title": "Stats Bootcamp - class 12",
    "section": "3. Calculate test-statistic, exact p-value",
    "text": "3. Calculate test-statistic, exact p-value\nParametric test:\n\nbfam |&gt;\n  ??_test(weight ~ ??) |&gt;\n  gt()\n\n. . .\nNonparametric test:\n\nbfam |&gt;\n  ??_test(weight ~ family) |&gt;\n  gt()\n\n. . .\nP values are well below 0.05\n\n\\(\\mathcal{H}_0\\) is that \\(family\\) cannot explain \\(weight\\) is NOT WELL SUPPORTED\n\n\\(family\\) can explain \\(weight\\)"
  },
  {
    "objectID": "exercises/ex-12.html#visualize-the-result-1",
    "href": "exercises/ex-12.html#visualize-the-result-1",
    "title": "Stats Bootcamp - class 12",
    "section": "Visualize the result",
    "text": "Visualize the result\n\n# save statistical test result\nstatres &lt;- bfam |&gt;\n  anova_test(weight ~ sex)\n\n\nggboxplot(\n  data = bfam,\n  y = \"weight\",\n  x = \"family\",\n  fill = \"family\"\n  ) + \n  stat_anova_test()"
  },
  {
    "objectID": "exercises/ex-12.html#multiple-pairwise-comparisons",
    "href": "exercises/ex-12.html#multiple-pairwise-comparisons",
    "title": "Stats Bootcamp - class 12",
    "section": "Multiple pairwise comparisons",
    "text": "Multiple pairwise comparisons\nQuick aside\n\n# save statistical test result\npairwise &lt;- bfam |&gt;\n  t_test(weight ~ family, ref.group = \"??\") \n\n\nggboxplot(bfam,\n          x = \"family\",\n          y = \"weight\",\n          fill = \"weight\",\n          ) +\n  stat_pvalue_manual(\n    pairwise,\n    label = \"p.adj\", \n    y.position = c(30, 32, 34)\n    ) +\n  ylim(10,38)\n\nNotice that not all pairwise differences are significant, yet the ANOVA is significant."
  },
  {
    "objectID": "exercises/ex-12.html#appropriate-statistical-test-cheatsheet",
    "href": "exercises/ex-12.html#appropriate-statistical-test-cheatsheet",
    "title": "Stats Bootcamp - class 12",
    "section": "Appropriate statistical test cheatsheet",
    "text": "Appropriate statistical test cheatsheet"
  },
  {
    "objectID": "exercises/ex-12.html#references",
    "href": "exercises/ex-12.html#references",
    "title": "Stats Bootcamp - class 12",
    "section": "References",
    "text": "References\nLegal analogy\nStatQuest: P Values, clearly explained\nStatQuest: How to calculate p-values\nThe Curious Tale of William Sealy Gosset"
  },
  {
    "objectID": "exercises/ex-14.html",
    "href": "exercises/ex-14.html",
    "title": "Stats Bootcamp - class 14",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename sex to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt; \n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-14.html#prepare-mouse-biochem-data",
    "href": "exercises/ex-14.html#prepare-mouse-biochem-data",
    "title": "Stats Bootcamp - class 14",
    "section": "",
    "text": "# we are reading the data directly from the internet\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1,6,9,14,15,24:28)]\nbiochem &lt;- biochem[,keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\",\"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename sex to sex\nb &lt;- inner_join(biochem, weight, by=\"subject_name\") |&gt; \n  na.omit() |&gt;\n  rename(sex=gender)"
  },
  {
    "objectID": "exercises/ex-14.html#learning-objectives",
    "href": "exercises/ex-14.html#learning-objectives",
    "title": "Stats Bootcamp - class 14",
    "section": "Learning objectives",
    "text": "Learning objectives\n\n\nFormulate and Execute null hypothesis testing\n\nIdentify and Perform the proper statistical test for data type/comparison\n\nCalculate and Interpret p-values"
  },
  {
    "objectID": "exercises/ex-14.html#random-variables",
    "href": "exercises/ex-14.html#random-variables",
    "title": "Stats Bootcamp - class 14",
    "section": "Random variables",
    "text": "Random variables\nResponse Variable ( y - aka dependent or outcome variable): this variable is predicted or its variation is explained by the explanatory variable. In an experiment, this is the outcome that is measured following manipulation of the explanatory variable.\nExplanatory Variable ( x - aka independent or predictor variable): explains variations in the response variable. In an experiment, it is manipulated by the researcher."
  },
  {
    "objectID": "exercises/ex-14.html#the-simplicity-underlying-common-tests",
    "href": "exercises/ex-14.html#the-simplicity-underlying-common-tests",
    "title": "Stats Bootcamp - class 14",
    "section": "The simplicity underlying common tests",
    "text": "The simplicity underlying common tests\nMost of the common statistical models (t-test, correlation, ANOVA; etc.) are special cases of linear models or a very close approximation. This simplicity means that there is less to learn. It all comes down to:\n\n\\(y = a \\cdot x + b\\)\n\nThis needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model."
  },
  {
    "objectID": "exercises/ex-14.html#stats-equation-for-a-line",
    "href": "exercises/ex-14.html#stats-equation-for-a-line",
    "title": "Stats Bootcamp - class 14",
    "section": "Stats equation for a line",
    "text": "Stats equation for a line\nModel:\n\\(y\\) equals the intercept (\\(\\beta_0\\)) pluss a slope (\\(\\beta_1\\)) times \\(x\\).\n\\(y = \\beta_0 + \\beta_1 x \\qquad \\qquad \\mathcal{H}_0: \\beta_1 = 0\\)\n… which is the same as \\(y = b + a \\cdot x\\).\nThe short hand for this in R: y ~ 1 + x\nR interprets this as:\ny = 1*number + x*othernumber\nThe task of t-tests, lm, etc., is simply to find the numbers that best predict \\(y\\)."
  },
  {
    "objectID": "exercises/ex-14.html#appropriate-statistical-test-cheatsheet",
    "href": "exercises/ex-14.html#appropriate-statistical-test-cheatsheet",
    "title": "Stats Bootcamp - class 14",
    "section": "Appropriate statistical test cheatsheet",
    "text": "Appropriate statistical test cheatsheet"
  },
  {
    "objectID": "exercises/ex-14.html#comparing-means-between-two-groups",
    "href": "exercises/ex-14.html#comparing-means-between-two-groups",
    "title": "Stats Bootcamp - class 14",
    "section": "Comparing means between two groups",
    "text": "Comparing means between two groups\nWe will compare mouse \\(weight\\) by \\(sex\\).\n\n# plot weight by sex\np_ws &lt;- ggplot(b,\n               aes(x = sex, y = weight)) +\n  geom_jitter(size=1) +\n  geom_hline(yintercept = mean(b$weight),\n             color = \"red\") +\n  theme_cowplot()\n\n\n# plot weight by sex with mean weight and mean weight by sex  \np_ws2 &lt;- ggplot(b,\n                aes(x = sex, y = weight)) +\n  geom_jitter(size=1) +\n  geom_hline(yintercept = mean(b$weight),\n             color = \"red\") +\n stat_summary(fun = \"mean\", geom = \"point\",  fill = \"blue\", shape = 23, size=3) +\n  theme_cowplot()\n\nplot_grid(p_ws, p_ws2, ncol = 2, labels = c(\"weight\",\"weight by sex\"), scale = c(1,1))"
  },
  {
    "objectID": "exercises/ex-14.html#step-1-can-mouse-sex-explain-mouse-weight",
    "href": "exercises/ex-14.html#step-1-can-mouse-sex-explain-mouse-weight",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 1: Can mouse sex explain mouse weight?",
    "text": "STEP 1: Can mouse sex explain mouse weight?\nModel: \\(y_{i} = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x_{i}\\)\nNull Hypothesis: \\(\\mathcal{H}_0: \\beta_1 = 0\\)\n\\(\\mathcal{H}_0:\\) mouse \\(sex\\) does NOT explain \\(weight\\)\nAlternative Hypothesis: \\(\\mathcal{H}_1: \\beta_1 \\neq 0\\)\n\\(\\mathcal{H}_1:\\) mouse \\(sex\\) does explain \\(weight\\)\nImportant: \\(x_{i}\\) is an indicator (0 or 1) saying whether data point i was sampled from one or the other group (female or male).\nWe will explore this in more detail soon."
  },
  {
    "objectID": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results",
    "href": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_ws &lt;- \n\nFit summary:\n\n??(fit_ws) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\nCoefficient summary:\n\n??(fit_ws) |&gt;\n  gt() |&gt;\n  fmt_number(columns =estimate:statistic, decimals = 3)"
  },
  {
    "objectID": "exercises/ex-14.html#collecting-residuals-and-other-information",
    "href": "exercises/ex-14.html#collecting-residuals-and-other-information",
    "title": "Stats Bootcamp - class 14",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\n#augment\nb_ws &lt;- \n\n\n# mean weight\navg_w &lt;-\n\n# mean weight female\navg_wf &lt;- \n\n\n# mean weight male\navg_wm &lt;-"
  },
  {
    "objectID": "exercises/ex-14.html#step-3-visualize-the-error-around-fit",
    "href": "exercises/ex-14.html#step-3-visualize-the-error-around-fit",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 3: Visualize the error around fit",
    "text": "STEP 3: Visualize the error around fit\n\n# plot of data with mean and colored by residuals\n\np_ws &lt;- ggplot(b_ws,\n               aes(x = sex, y = weight)) +\n  geom_point(position = position_jitter(),\n             aes(color = .resid)) +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\n    geom_hline(yintercept = ??,\n               color = \"darkgrey\") +\n  geom_segment(aes(x=.5, xend=1.5,\n                   y=??, yend=??),\n               color=\"red\") +\n    geom_segment(aes(x=1.5, xend=2.5,\n                     y=??), yend=??,\n                 color=\"red\") +\n  theme_cowplot()\n  \np_ws"
  },
  {
    "objectID": "exercises/ex-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "href": "exercises/ex-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 3: Visualize the error around the null (mean weight)",
    "text": "STEP 3: Visualize the error around the null (mean weight)\n\np_w &lt;- ggplot(b_ws,\n               aes(x = sex, y = weight)) +\n  geom_point(position = position_jitter(),\n             aes(color = weight-avg_w)) +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\n    geom_hline(yintercept = avg_w,\n               color = \"darkgrey\") +\n  theme_cowplot()\n  \np_w"
  },
  {
    "objectID": "exercises/ex-14.html#compare-fit-error-to-null-error-graphically",
    "href": "exercises/ex-14.html#compare-fit-error-to-null-error-graphically",
    "title": "Stats Bootcamp - class 14",
    "section": "Compare fit error to null error graphically",
    "text": "Compare fit error to null error graphically\n\nplot_grid(p_ws, p_w, ncol = 2, labels = c(\"weight by sex\",\"weight by intercept\"))\n\nWe are fitting 2 lines to the data. For the weight by sex model of the fit (left), we fit 2 lines. For the weight by null model (right) we fit 1 line."
  },
  {
    "objectID": "exercises/ex-14.html#exceptions-mice-with-highest-residuals",
    "href": "exercises/ex-14.html#exceptions-mice-with-highest-residuals",
    "title": "Stats Bootcamp - class 14",
    "section": "Exceptions: mice with highest residuals",
    "text": "Exceptions: mice with highest residuals"
  },
  {
    "objectID": "exercises/ex-14.html#matrices-interlude-begin",
    "href": "exercises/ex-14.html#matrices-interlude-begin",
    "title": "Stats Bootcamp - class 14",
    "section": "Matrices Interlude Begin\n",
    "text": "Matrices Interlude Begin\n\n\nHow do we go from 2 fit lines to 1 equation\n\nSince we don’t want to calculate any of this by hand, the framework needs to be flexible such that a computer can execute for different flavors of comparison (cont y vs cont x, cont y vs 2 or more categorical x, …)."
  },
  {
    "objectID": "exercises/ex-14.html#lets-focus-on-just-a-few-mice",
    "href": "exercises/ex-14.html#lets-focus-on-just-a-few-mice",
    "title": "Stats Bootcamp - class 14",
    "section": "Let’s focus on just a few mice",
    "text": "Let’s focus on just a few mice\nRemember that:\\(weight\\) is \\(y\\)\\(F_{avg}\\) is the average \\(weight\\) of \\(females\\)\\(M_{avg}\\) is the average \\(weight\\) of \\(males\\)\n. . .\nA048054885, female\\(y_{85}= 1 \\cdot F_{avg} + 0 \\cdot M_{avg} + residual_{85}\\)\nA067109771, female\\(y_{71}= 1 \\cdot F_{avg} + 0 \\cdot M_{avg} + residual_{71}\\)\n. . .\nA066822351, male\\(y_{51}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{51}\\)\nA048274362, male\\(y_{62}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{62}\\)"
  },
  {
    "objectID": "exercises/ex-14.html#lets-focus-on-just-a-few-mice-1",
    "href": "exercises/ex-14.html#lets-focus-on-just-a-few-mice-1",
    "title": "Stats Bootcamp - class 14",
    "section": "Let’s focus on just a few mice",
    "text": "Let’s focus on just a few mice\n\nb_ws |&gt; \n  filter(subject_name %in% c(\"A048054885\",\"A067109771\",\"A066822351\",\"A048274362\")) |&gt;\n  select(subject_name, weight, sex, .fitted, .resid) |&gt;\n  arrange(sex) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-14.html#need-a-volunteer",
    "href": "exercises/ex-14.html#need-a-volunteer",
    "title": "Stats Bootcamp - class 14",
    "section": "Need a volunteer",
    "text": "Need a volunteer\nMe: Ooohh my, imagine how tedious it would be to do this for all mice…Volunteer: Wait a sec…isn’t there a way to formulate this as a matrix algebra problem.Me: You’re right - I’m so glad you asked! Let’s conjur matrix-magic to solve this problem..\n. . .\n\\(f_{avg} = \\beta_0\\) is the average \\(weight\\) of \\(female\\) mice\\(m_{avg} = \\beta_1\\) is the average \\(weight\\) of \\(male\\) mice\n. . .\n\\(\\begin{bmatrix} y_{85} \\\\ y_{71} \\\\ y_{51} \\\\y_{62} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} e_{85} \\\\ e_{71} \\\\ e_{51} \\\\e_{62} \\end{bmatrix}\\)\n. . .\nSo basically this looks like the same equation for fitting a line we’ve been discussing, just w/a few more dimensions :)\nThis is a conceptual peak into the underbelly of how the \\(\\beta\\) cofficients and least squares is performed using matrix operations (linear algebra). If you are interested in learning more see references at the end of the slides.\nMatrices Interlude FIN"
  },
  {
    "objectID": "exercises/ex-14.html#calculate-r2",
    "href": "exercises/ex-14.html#calculate-r2",
    "title": "Stats Bootcamp - class 14",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\\(SS_{fit}\\) — sum of squared errors around the least-squares fit\n\nss_fit &lt;- \n\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\nss_null &lt;- \n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\nrsq &lt;- ??\n\n\nglance(fit_ws) |&gt; select(r.squared)\n\nWoohoo!!"
  },
  {
    "objectID": "exercises/ex-14.html#compare-to-traditional-t-test",
    "href": "exercises/ex-14.html#compare-to-traditional-t-test",
    "title": "Stats Bootcamp - class 14",
    "section": "Compare to traditional t-test",
    "text": "Compare to traditional t-test\n\nb |&gt; \n  ?? |&gt;\n  select(-c(n1,n2,df)) |&gt;\n  gt()\n\n\ntidy(fit_ws) |&gt;\n  select(term, estimate, statistic, p.value) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-14.html#prep-data-for-fams",
    "href": "exercises/ex-14.html#prep-data-for-fams",
    "title": "Stats Bootcamp - class 14",
    "section": "prep data for fams",
    "text": "prep data for fams\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\"B1.5:E1.4(4) B1.5:A1.4(5)\",\n            \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n            \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n            \"D5.4:G2.3(4) D5.4:C4.3(4)\")\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels() \n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref =\"B1\")"
  },
  {
    "objectID": "exercises/ex-14.html#step-1-can-family-explain-weight",
    "href": "exercises/ex-14.html#step-1-can-family-explain-weight",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 1: Can family explain weight?",
    "text": "STEP 1: Can family explain weight?\nANOVA -&gt; comparing means of 3 or more groups.\nLet’s compare the \\(weight\\) by \\(family\\), but only for a few selected families.\n\nggplot(data = ??,\n       aes(??)) +\n  geom_jitter(width = .2) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-14.html#what-does-the-model-look-like",
    "href": "exercises/ex-14.html#what-does-the-model-look-like",
    "title": "Stats Bootcamp - class 14",
    "section": "What does the model look like?",
    "text": "What does the model look like?\nModel: \\(y_{i} = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x_{i}\\)\nNull Hypothesis: \\(\\mathcal{H}_0: \\beta_1 = 0\\)\n\\(\\mathcal{H}_0:\\) mouse \\(family\\) does NOT explain \\(weight\\)\nAlternative Hypothesis: \\(\\mathcal{H}_1: \\beta_1 \\neq 0\\)\n\\(\\mathcal{H}_1:\\) mouse \\(family\\) does explain \\(weight\\)\nImportant: \\(x_{i}\\) is an indicator (0 or 1) saying which group point \\(i\\) was sampled from using the matrix encoding of 0s and 1s.\nBelow is an example depicting 6 observations with 2 from each of 3 families:\n\\(\\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ y_{3} \\\\y_{4} \\\\y_{5} \\\\y_{5} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} e_{1} \\\\ e_{2} \\\\ e_{3} \\\\e_{4} \\\\e_{5} \\\\e_{6} \\end{bmatrix}\\)"
  },
  {
    "objectID": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-1",
    "href": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-1",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_wf &lt;- ??\n\nFit summary:\n\nglance(fit_wf) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\nCoefficient summary:\n\ntidy(fit_wf) |&gt;\n  gt() |&gt;\n  fmt_number(columns =estimate:statistic, decimals = 3)"
  },
  {
    "objectID": "exercises/ex-14.html#collecting-residuals-and-other-information-1",
    "href": "exercises/ex-14.html#collecting-residuals-and-other-information-1",
    "title": "Stats Bootcamp - class 14",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information\n\n#augment\nb_wf &lt;- \n\n# mean weight per fam\nmean_B1 &lt;- fit_wf$coefficients[??]\n\nmean_A1 &lt;- mean_B1 +\n  fit_wf$coefficients[??]\n\nmean_D5 &lt;- mean_B1 +\n  fit_wf$coefficients[??]\n\nmean_F1 &lt;- mean_B1 +\n  fit_wf$coefficients[??]"
  },
  {
    "objectID": "exercises/ex-14.html#step-3-visualize-the-error-around-fit-1",
    "href": "exercises/ex-14.html#step-3-visualize-the-error-around-fit-1",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 3: Visualize the error around fit",
    "text": "STEP 3: Visualize the error around fit\n\nggplot(b_wf,\n       aes(x = family, y = weight)) +\n  geom_point(position = position_jitter(),\n             aes(color = .resid)) +\n  scale_color_gradient2(low = \"blue\",\n                        mid = \"black\",\n                        high = \"yellow\") +\ngeom_segment(aes(x=.5, xend=1.5, y=mean_B1, yend=mean_B1), color=\"red\") +\n  geom_segment(aes(x=1.5, xend=2.5, y=mean_A1, yend=mean_A1), color=\"red\") +\n  geom_segment(aes(x=2.5, xend=3.5, y=mean_D5, yend=mean_D5), color=\"red\") +\n  geom_segment(aes(x=3.5, xend=4.5, y=mean_F1, yend=mean_F1), color=\"red\") +\n  geom_segment(aes(x=.5, xend=4.5, y=mean(weight), yend=mean(weight)), color=\"black\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-14.html#compare-to-traditional-anova",
    "href": "exercises/ex-14.html#compare-to-traditional-anova",
    "title": "Stats Bootcamp - class 14",
    "section": "Compare to traditional ANOVA",
    "text": "Compare to traditional ANOVA\n\nbfam |&gt; \n  ?? |&gt;\n  gt()\n\n\ntidy(fit_wf) |&gt;\n  select(term, estimate, statistic, p.value) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-14.html#comparing-2-groups-of-2-continuous-variables",
    "href": "exercises/ex-14.html#comparing-2-groups-of-2-continuous-variables",
    "title": "Stats Bootcamp - class 14",
    "section": "Comparing 2 groups of 2 continuous variables",
    "text": "Comparing 2 groups of 2 continuous variables\nANCOVA, Analysis of Covariance. ANOVA with more than one independent variable. What is the impact of mouse age on mouse weight for males vs females.\n\nggplot(data = b, aes(y = weight, x = age, color=sex)) +\n  geom_point(size=.5) +\n  geom_smooth(method=lm) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-2",
    "href": "exercises/ex-14.html#step-2-fit-linear-model-and-examine-results-2",
    "title": "Stats Bootcamp - class 14",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\n\nfit_wa_sex &lt;- lm(formula = weight ~ 1 + age + sex, data = b)\nb_wa_sex &lt;- augment(fit_ws, data = b)\n\nFit summary:\n\nglance(fit_wa_sex) |&gt;\n  gt() |&gt;\n  fmt_number(columns = r.squared:statistic, decimals = 3)\n\nCompare to traditional:\n\naov(formula = weight ~ 1 + age + sex, data = b) |&gt;\n  glance()"
  },
  {
    "objectID": "exercises/ex-14.html#references",
    "href": "exercises/ex-14.html#references",
    "title": "Stats Bootcamp - class 14",
    "section": "References",
    "text": "References\nLinear Models Pt.3 - Design Matrices\nA Matrix Formulation of the Multiple Regression Model\nDoing and reporting your first ANOVA and ANCOVA in R40f2ef"
  },
  {
    "objectID": "exercises/ex-16.html",
    "href": "exercises/ex-16.html",
    "title": "Mapping chromatin structure and transactions",
    "section": "",
    "text": "library(valr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nx &lt;- tribble(\n  ~chrom, ~start, ~end,\n  \"chr1\", 25, 50,\n  \"chr1\", 100, 125\n)\n\ny &lt;- tribble(\n  ~chrom, ~start, ~end,\n  \"chr1\", 30,     75\n)"
  },
  {
    "objectID": "exercises/ex-16.html#bed_intersect-example",
    "href": "exercises/ex-16.html#bed_intersect-example",
    "title": "Mapping chromatin structure and transactions",
    "section": "",
    "text": "library(valr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nx &lt;- tribble(\n  ~chrom, ~start, ~end,\n  \"chr1\", 25, 50,\n  \"chr1\", 100, 125\n)\n\ny &lt;- tribble(\n  ~chrom, ~start, ~end,\n  \"chr1\", 30,     75\n)"
  },
  {
    "objectID": "exercises/ex-16.html#valr-example",
    "href": "exercises/ex-16.html#valr-example",
    "title": "Mapping chromatin structure and transactions",
    "section": "valr example",
    "text": "valr example\nYou can use read_bed() and related functions to load genome annotations and signals.\n\nsnps &lt;- read_bed(\n  valr_example(\"hg19.snps147.chr22.bed.gz\"),\n  n_fields = 6\n)\n\nWarning: The `n_fields` argument of `read_bed()` is deprecated as of valr 0.6.9.\ni fields are now determined automatically from the file\n\ngenes &lt;- read_bed(\n  valr_example(\"genes.hg19.chr22.bed.gz\"),\n  n_fields = 6\n)"
  },
  {
    "objectID": "exercises/ex-16.html#what-is-in-snps-and-genes",
    "href": "exercises/ex-16.html#what-is-in-snps-and-genes",
    "title": "Mapping chromatin structure and transactions",
    "section": "What is in snps and genes?",
    "text": "What is in snps and genes?"
  },
  {
    "objectID": "exercises/ex-16.html#interval-manipulation",
    "href": "exercises/ex-16.html#interval-manipulation",
    "title": "Mapping chromatin structure and transactions",
    "section": "Interval manipulation",
    "text": "Interval manipulation\nLet’s find and characterize intergenic SNPs. We’ll use the tools bed_substract() and bed_closest(). Take a look and their examples in the documentation to see what they do.\n. . .\nTake a look at the intergenic and nearby objects in the console."
  },
  {
    "objectID": "exercises/ex-16.html#interval-manipulation-1",
    "href": "exercises/ex-16.html#interval-manipulation-1",
    "title": "Mapping chromatin structure and transactions",
    "section": "Interval manipulation",
    "text": "Interval manipulation\nNow that you have overlaps and distances between SNPs and genes, you can go back to dplyr tools to generate reports."
  },
  {
    "objectID": "exercises/ex-16.html#bed_map-example",
    "href": "exercises/ex-16.html#bed_map-example",
    "title": "Mapping chromatin structure and transactions",
    "section": "\nbed_map() example",
    "text": "bed_map() example\nCopy / paste these into your console.\n\nx &lt;- tribble(\n  ~chrom, ~start, ~end,\n  \"chr1\", 100,    250,\n  \"chr2\", 250,    500\n)\n\ny &lt;- tribble(\n  ~chrom, ~start, ~end, ~value,\n  \"chr1\", 100,    250,  10,\n  \"chr1\", 150,    250,  20,\n  \"chr2\", 250,    500,  500\n)"
  },
  {
    "objectID": "exercises/ex-16.html#bed_map-example-continued",
    "href": "exercises/ex-16.html#bed_map-example-continued",
    "title": "Mapping chromatin structure and transactions",
    "section": "\nbed_map() example continued",
    "text": "bed_map() example continued\nFirst examine the intersecting intervals."
  },
  {
    "objectID": "exercises/ex-18.html",
    "href": "exercises/ex-18.html",
    "title": "Chromatin accessibility II",
    "section": "",
    "text": "Last class we saw what the different methods to profile chromatin accessibility can tell us about general chromatin structure and possible regulation at specific regions in a small portion of a chromosome.\nWe also want to make sure these conclusions are valid throughout the genome, and today we’ll discuss two approaches for this: metaplots and heatmaps."
  },
  {
    "objectID": "exercises/ex-18.html#genomewide-chromatin-analysis-with-metaplots-and-heatmaps",
    "href": "exercises/ex-18.html#genomewide-chromatin-analysis-with-metaplots-and-heatmaps",
    "title": "Chromatin accessibility II",
    "section": "",
    "text": "Last class we saw what the different methods to profile chromatin accessibility can tell us about general chromatin structure and possible regulation at specific regions in a small portion of a chromosome.\nWe also want to make sure these conclusions are valid throughout the genome, and today we’ll discuss two approaches for this: metaplots and heatmaps."
  },
  {
    "objectID": "exercises/ex-18.html#setting-up-regions-for-a-meta-plot",
    "href": "exercises/ex-18.html#setting-up-regions-for-a-meta-plot",
    "title": "Chromatin accessibility II",
    "section": "Setting up regions for a meta-plot",
    "text": "Setting up regions for a meta-plot\nWe need to set up some windows for analyzing signal relative to each TSS. This is an important step that will ultimately impact our interpretations.\nIn genomic meta-plots, you first decide on a window size relevant to the some points of refernce in the genome you are measuring.\nThese reference points could be:\n\ntranscription start or end sites\nboundaries of exons and introns\nenhancers\ncentromeres and telomeres\n\nThe window size should be relevant the reference points, such that small- or large-scale features are emphasized in the plot. Moreover, the window typically spans some distance both up- and downstream of the reference points.\nOnce the window size has been decided, the next step is to make “sub-windows” around a reference point. If gene features are involved, we also need to take strand into account.\n(The state of genome annotation directly influences the quality of the meta-plot or heatmap.)\nFor small features like transcription factor binding sites (8-20 bp), you might set up smaller windows (maybe 1 bp) at a distance ~20 bp up- and downstream of a reference point.\nFor larger features like nucleosome positions or chromatin domains, you might set up larger windows (~200 bp) at distances up to ~10 kbp up- and downstream of a set of reference points."
  },
  {
    "objectID": "exercises/ex-18.html#metaplot-workflow",
    "href": "exercises/ex-18.html#metaplot-workflow",
    "title": "Chromatin accessibility II",
    "section": "Metaplot workflow",
    "text": "Metaplot workflow\n\n\nMetaplot workflow overview"
  },
  {
    "objectID": "exercises/ex-18.html#chromatin-accessibility-around-transcription-start-sites-tsss",
    "href": "exercises/ex-18.html#chromatin-accessibility-around-transcription-start-sites-tsss",
    "title": "Chromatin accessibility II",
    "section": "Chromatin accessibility around transcription start sites (TSSs)",
    "text": "Chromatin accessibility around transcription start sites (TSSs)\n\nregion_size_total &lt;- 1500\nregion_size_half &lt;- region_size_total / 2\nwin_size &lt;- 10\n\n# need a function that generates a sequence of numbers\nwin_coords &lt;- ___(\n  -region_size_half,\n  region_size_half,\n  win_size\n)\n\nNext, we’ll use two valr functions to expand the window of the reference point (bed_slop()) and then break those windows into evenly spaced intervals (bed_makewindows()).\n\nyeast_tss |&gt;\n  bed_???(genome, both = region_size_half) |&gt;\n  bed_???(win_size = win_size)\n\nAt this point, we also address the fact that the TSS data are stranded. Can someone describe what the issue is here, based on the figure above?\n\ntss_win_tbl &lt;-\n  yeast_tss |&gt;\n  bed_slop(genome, both = region_size_half) |&gt;\n  bed_makewindows(win_size = win_size) |&gt;\n  mutate(\n    win_coord = case_when(\n      strand == \"-\" ~ rev(win_coords),\n      .default = win_coords\n    ),\n    .by = name\n  ) |&gt;\n  select(-.win_id, -score, -strand)\n\nThis next step uses valr bed_map(), to calculate the total signal for each window by intersecting signals from the bigWig files.\n\nacc_tbl &lt;-\n  acc_tbl |&gt;\n  mutate(\n    tss_win_sum = purrr::map(\n      big_wig,\n      ~ bed_map(\n        tss_win_tbl,\n        .x,\n        win_signal = sum(score)\n      )\n    )\n  )\n\nOnce we have the values from bed_map(), we can group by win_coord and calculate a summary statistic for each window.\nRemember that win_coord is the same relative position for each TSS, so these numbers represent a composite signal a the same position across all TSS.\n\ntss_meta_tbl &lt;-\n  select(acc_tbl, sample_type, tss_win_sum) |&gt;\n  unnest(cols = c(tss_win_sum)) |&gt;\n  summarize(\n    win_mean = mean(win_signal, na.rm = TRUE),\n    win_sd = sd(win_signal, na.rm = TRUE),\n    .by = c(win_coord, sample_type)\n  ) |&gt;\n  replace_na(list(win_mean = 0, win_sd = 0))"
  },
  {
    "objectID": "exercises/ex-18.html#meta-plot-of-signals-around-tsss",
    "href": "exercises/ex-18.html#meta-plot-of-signals-around-tsss",
    "title": "Chromatin accessibility II",
    "section": "Meta-plot of signals around TSSs",
    "text": "Meta-plot of signals around TSSs\nFinally, let’s plot the data relative to TSS for each of the windows.\n\nn_tss &lt;- length(unique(yeast_tss$name))\n\nggplot(\n  tss_meta_tbl,\n  aes(\n    x = win_coord,\n    y = win_mean\n  )\n) +\n  geom_line(linewidth = 1, color = \"red\") +\n  facet_wrap(\n    ~sample_type,\n    nrow = 2,\n    scales = \"free_y\"\n  ) +\n  theme_minimal_grid() +\n  theme(\n    axis.text.x = element_text(\n      angle = 45,\n      vjust = 1,\n      hjust = 1\n    )\n  ) +\n  labs(\n    x = \"Position relative to TSS (bp)\",\n    y = \"Signal (mean of window sums)\",\n    title = \"Chromatin accessibility around transcription start sites\",\n    subtitle = glue(\"{n_tss} features on S. cerevisiae chrII\")\n  )"
  },
  {
    "objectID": "exercises/ex-18.html#interpreting-the-meta-plots",
    "href": "exercises/ex-18.html#interpreting-the-meta-plots",
    "title": "Chromatin accessibility II",
    "section": "Interpreting the meta-plots",
    "text": "Interpreting the meta-plots\n\nWhat is the direction of transcription in these meta-plots?\nWhat are the features of chromatin near TSS measured by these different experimental conditions?\nHow do you interpret the increased signal of the +1 nucleosome in the “MNase_Long” condition, relative to e.g. -1, +2, +3, etc.?\nWhat are the differences in ATAC and MNase treatments that lead to these distinctive patterns?"
  },
  {
    "objectID": "exercises/ex-18.html#heatmap-of-signals-around-tsss",
    "href": "exercises/ex-18.html#heatmap-of-signals-around-tsss",
    "title": "Chromatin accessibility II",
    "section": "Heatmap of signals around TSSs",
    "text": "Heatmap of signals around TSSs\nTo generate a heatmap, we need to reformat our data slightly.\nTake a look at acc_tbl and think about how you might reorganize the following way:\n\nrows contain the data for individual loci (i.e., each TSS)\ncolumns are ordered positions relative to the TSS (i.e., most upstream to most downstream)\n\nWe’re going to plot a heatmap of the “MNase_Long” data. There are two ways to get these data.\n\nmnase_tbl &lt;- acc_tbl[acc_tbl$sample_type == \"MNase_Short\", ]$tss_win_sum[[1]]\n\nOr, using dplyr / tidyr:\n\nmnase_tbl &lt;-\n  filter(\n    acc_tbl,\n    sample_type == \"MNase_Long\"\n  ) |&gt;\n    select(-big_wig) |&gt;\n    unnest(cols = c(tss_win_sum))\n\nEither way, now we need to reformat the data.\n\nmnase_tbl_wide &lt;-\n  mnase_tbl |&gt;\n  select(\n    name,\n    win_coord,\n    win_signal\n  ) |&gt;\n  # this step is important to sort + and - windows correctly\n  arrange(name, win_coord) |&gt;\n  replace_na(\n    list(win_signal = 0)\n  ) |&gt;\n  pivot_???(\n    id_cols = name,\n    names_from = \"win_coord\",\n    values_from = \"win_signal\"\n  )\n\nOnce we have the data reformatted, we just convert to a matrix and feed it to ComplexHeatmap::Heatmap().\n\n# drop the name & convert to matrix\nmnase_mtx &lt;-\n  select(mnase_tbl_wide, -name) |&gt;\n  as.___()\n\nComplexHeatmap::___(\n  mnase_mtx,\n  cluster_columns = FALSE,\n  show_row_dend = FALSE,\n  show_column_names = FALSE,\n  show_heatmap_legend = FALSE\n)"
  },
  {
    "objectID": "exercises/ex-18.html#interpreting-meta-plots-and-heatmaps",
    "href": "exercises/ex-18.html#interpreting-meta-plots-and-heatmaps",
    "title": "Chromatin accessibility II",
    "section": "Interpreting meta-plots and heatmaps",
    "text": "Interpreting meta-plots and heatmaps\nIt’s worth considering what meta-plots and heatmaps can and can’t tell you.\n\nWhat are the similarities and differences between heatmaps and meta-plots?\nWhat types of conclusions can you draw from each type of plot?\nWhat are some features of MNase-seq and ATAC-seq that become more clear when looking across many loci at the same time?\nWhat are some hypotheses you can generate based on these plots?"
  },
  {
    "objectID": "exercises/ex-18.html#assessing-the-signfiicance-of-observed-patterns.",
    "href": "exercises/ex-18.html#assessing-the-signfiicance-of-observed-patterns.",
    "title": "Chromatin accessibility II",
    "section": "Assessing the signfiicance of observed patterns.",
    "text": "Assessing the signfiicance of observed patterns.\nOne approach for assessing the signifcance of a pattern (e.g., the density of nucleosomes around transcription start sites), is to randomize the reference points, and use those to remeasure density. This can be done by generating a random set of TSS like:\nn_tss &lt;- length(unique(yeast_tss$name))\nbed_random(genome, length = 1, n = n_tss)\nGiven enough random sites, you will be able to vizulaized what a null distribution of overlaps looks like. If you reframe your question around a response variable (i.e., “how many intact nucleosomes are within 500 bp of a TSS?”) then you can calcuate an empirical p-value using the approaches covered in the bootcamp."
  },
  {
    "objectID": "exercises/ex-18.html#utility-of-metaplots-and-heatmaps-in-practice",
    "href": "exercises/ex-18.html#utility-of-metaplots-and-heatmaps-in-practice",
    "title": "Chromatin accessibility II",
    "section": "Utility of metaplots and heatmaps in practice",
    "text": "Utility of metaplots and heatmaps in practice\nThere are a few specific cases when you should consider using the metaplot / heatmap strategy.\nIf you have data from two different conditions (i.e., plus/minus a transcription factor that might change the state of multiple promoters), you could make a metaplot for each of the plus and minus conditions, to see of common patterns manifest. You might also create a heatmap of the conditions, which might reveal smaller groups of affected genes that would be masked by the metaplot aggregation.\nThe approaches are also useful to compare patterns across types of reference points. For example, you might examine chromatin marks (measured by CUT&TAG) relative to the following: transcription starts, exon starts, exon ends, transcription ends."
  },
  {
    "objectID": "exercises/ex-22.html",
    "href": "exercises/ex-22.html",
    "title": "ex 22",
    "section": "",
    "text": "d &lt;- read_csv(here(\"data\",\"unfilt_counts.csv.gz\")) |&gt; as.matrix()\n\n\ndf &lt;- tibble(variance=??,\n                mean=??)\n\nggplot(??) +\n        geom_point(aes(x=??, y=??)) + \n        scale_y_log10(limits = c(1,1e9)) +\n        scale_x_log10(limits = c(1,1e9)) +\n        geom_abline(intercept = 0, slope = 1, color=\"red\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-22.html#examine-count-data",
    "href": "exercises/ex-22.html#examine-count-data",
    "title": "ex 22",
    "section": "",
    "text": "d &lt;- read_csv(here(\"data\",\"unfilt_counts.csv.gz\")) |&gt; as.matrix()\n\n\ndf &lt;- tibble(variance=??,\n                mean=??)\n\nggplot(??) +\n        geom_point(aes(x=??, y=??)) + \n        scale_y_log10(limits = c(1,1e9)) +\n        scale_x_log10(limits = c(1,1e9)) +\n        geom_abline(intercept = 0, slope = 1, color=\"red\") +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-22.html#estimatesizefactors",
    "href": "exercises/ex-22.html#estimatesizefactors",
    "title": "ex 22",
    "section": "estimateSizeFactors",
    "text": "estimateSizeFactors\n\nd &lt;- read_csv(here(\"data\",\"unfilt_counts.csv.gz\")) |&gt; as.matrix()\n\n# estimate size factors"
  },
  {
    "objectID": "exercises/ex-24.html",
    "href": "exercises/ex-24.html",
    "title": "RNAseq DE",
    "section": "",
    "text": "We are going to imagine that we have only two conditions: DIV0 and DIV7 with DESeq2.\nThe first thing we need to do is read in the data again and move from transcript-level expression values to gene-level expression values with tximport. Let’s use biomaRt to get a table that relates gene and transcript IDs.\n\nmart &lt;- biomaRt::useMart(\n  \"ENSEMBL_MART_ENSEMBL\",\n  dataset = \"mmusculus_gene_ensembl\"\n)\n\nt2g &lt;- biomaRt::getBM(\n  attributes = c(\n    \"ensembl_transcript_id\",\n    \"ensembl_gene_id\",\n    \"external_gene_name\"\n  ),\n  mart = mart\n) |&gt;\n  as_tibble()\n\n# maps systematic to common gene names\ngene_name_map &lt;- t2g |&gt;\n  dplyr::select(-ensembl_transcript_id) |&gt;\n  ??() # kill redundant"
  },
  {
    "objectID": "exercises/ex-24.html#prepare-t2g",
    "href": "exercises/ex-24.html#prepare-t2g",
    "title": "RNAseq DE",
    "section": "",
    "text": "We are going to imagine that we have only two conditions: DIV0 and DIV7 with DESeq2.\nThe first thing we need to do is read in the data again and move from transcript-level expression values to gene-level expression values with tximport. Let’s use biomaRt to get a table that relates gene and transcript IDs.\n\nmart &lt;- biomaRt::useMart(\n  \"ENSEMBL_MART_ENSEMBL\",\n  dataset = \"mmusculus_gene_ensembl\"\n)\n\nt2g &lt;- biomaRt::getBM(\n  attributes = c(\n    \"ensembl_transcript_id\",\n    \"ensembl_gene_id\",\n    \"external_gene_name\"\n  ),\n  mart = mart\n) |&gt;\n  as_tibble()\n\n# maps systematic to common gene names\ngene_name_map &lt;- t2g |&gt;\n  dplyr::select(-ensembl_transcript_id) |&gt;\n  ??() # kill redundant"
  },
  {
    "objectID": "exercises/ex-24.html#prepare-metdata-and-import",
    "href": "exercises/ex-24.html#prepare-metdata-and-import",
    "title": "RNAseq DE",
    "section": "Prepare metdata and import",
    "text": "Prepare metdata and import\nNow we can read in the transcript-level data and collapse to gene-level data with tximport\n\nmetadata &lt;- data.frame(\n  sample_id = list.files(here(\"??\"),\n                         pattern = \"^DIV\"),\n  salmon_dirs = list.files(here(\"??\"),\n                           recursive = T,\n                           pattern = \".gz$\",\n                           full.names = T)\n  ) |&gt;\n  separate(col = sample_id, into = c(\"timepoint\",\"rep\"), sep = \"\\\\.\", remove = F)\n\nmetadata$rep &lt;- gsub(pattern = \"Rep\", replacement = \"\", metadata$rep) \n\nrownames(metadata) &lt;- metadata$sample_id\n\n#keep only samples we want\nmetadata &lt;- metadata |&gt; \n  filter(timepoint %in% c(\"??\",\"??\")) \n\nsalmdir &lt;- metadata$??\nnames(salmdir) &lt;- metadata$??\n\ntxi &lt;- tximport(\n  files = salmdir,\n  type = \"salmon\",\n  tx2gene = t2g,\n  dropInfReps = TRUE,\n  countsFromAbundance = \"lengthScaledTPM\"\n)"
  },
  {
    "objectID": "exercises/ex-24.html#filter-lowly-expressed-genes",
    "href": "exercises/ex-24.html#filter-lowly-expressed-genes",
    "title": "RNAseq DE",
    "section": "Filter lowly expressed genes",
    "text": "Filter lowly expressed genes\n\n# examine distribution of TPMs\nhist(log2(1 + rowSums(txi$abundance)), breaks = 40)\n\n# decide a cutoff\nkeepG &lt;- txi$abundance[log2(1 + rowSums(txi$abundance)) &gt; 4.5,] |&gt;\n  rownames()"
  },
  {
    "objectID": "exercises/ex-24.html#create-deseq-object",
    "href": "exercises/ex-24.html#create-deseq-object",
    "title": "RNAseq DE",
    "section": "Create DESeq object",
    "text": "Create DESeq object\nThere are essentially two steps to using DESeq2. The first involves creating a DESeqDataSet from your data. Luckily, if you have a tximport object, which we do in the form of txi, then this becomes easy.\n\n# metadata$timepoint &lt;- as.factor(metadata$timepoint)\n\nddsTxi &lt;- DESeqDataSetFromTximport(\n  ??,\n  colData = metadata,\n  design = ~??\n)\n\n# keep genes with sufficient expession\nddsTxi &lt;- ddsTxi[??,]"
  },
  {
    "objectID": "exercises/ex-24.html#design-formula",
    "href": "exercises/ex-24.html#design-formula",
    "title": "RNAseq DE",
    "section": "Design formula",
    "text": "Design formula\nYou can see that DESeqDataSetFromTximport wants three things. The first is our tximport object. The second is the dataframe we made that relates samples and conditions (or in this case timepoints). The last is something called a design formula. A design formula contains all of the variables that will go into DESeq2’s model. The formula starts with a tilde and then has variables separated by a plus sign think lm(). It is common practice, and in fact basically required with DESeq2, to put the variable of interest last. In our case, that’s trivial because we only have one: timepoint. So our design formula is very simple:\ndesign = ~ timepoint\nYour design formula should ideally include all of the sources of variation in your data. For example, let’s say that here we thought there was a batch effect with the replicates. Maybe all of the Rep1 samples were prepped and sequenced on a different day than the Rep2 samples and so on. We could potentially account for this in DESeq2’s model with the following forumula:\ndesign = ~ rep + timepoint\nHere, timepoint is still the variable of interest, but we are controlling for differences that arise due to differences in replicates."
  },
  {
    "objectID": "exercises/ex-24.html#run-deseq2",
    "href": "exercises/ex-24.html#run-deseq2",
    "title": "RNAseq DE",
    "section": "Run DESeq2\n",
    "text": "Run DESeq2\n\nWe can see here that DESeq2 is taking the counts produced by tximport for gene quantifications. There are 52346 genes (rows) here and 7 samples (columns). Now using this ddsTxi object, we can run DESeq2.\n\ndds &lt;- DESeq(??)\n\nThere are many useful things in this dds object. Take a look at the vignette for a full explanation. Including info on many more tests and analyses that can be done with DESeq2.\nThe results can be accessed using the results() function. We will use the contrast argument here. DESeq2 reports changes in RNA abundance between two samples as a log2FoldChange. But, it’s often not clear what the numerator and denominator of that fold change ratio…it could be either DIV7/DIV0 or DIV0/DIV7.\nThe lexographically first condition will be the numerator. I find it easier to explicitly specify what the numerator and denominator of this ratio are using the contrast argument. The contrast argument can be used to implement more complicated design formula. Remember our design formula that accounted for potential differences due to Replicate batch effects:\n~ replicate + timepoint\nDESeq2 will account for differences between replicates here to find differences between timepoints."
  },
  {
    "objectID": "exercises/ex-24.html#contrasts-to-get-results",
    "href": "exercises/ex-24.html#contrasts-to-get-results",
    "title": "RNAseq DE",
    "section": "Contrasts to get results",
    "text": "Contrasts to get results\n\n# For contrast, we give three strings: the factor we are interested in, the numerator, and the denominator\nresults(dds, contrast = c(\"timepoint\", \"??\", \"??\"))\n\nThe columns we are most interested in are log2FoldChange and padj.\nlog2FoldChange is self-explanatory. padj is the Benjamini-Hochberg corrected pvalue for a test asking if the expression of this gene is different between the two conditions."
  },
  {
    "objectID": "exercises/ex-24.html#cleanup-results",
    "href": "exercises/ex-24.html#cleanup-results",
    "title": "RNAseq DE",
    "section": "Cleanup results",
    "text": "Cleanup results\nLet’s do a little work on this data frame to make it slightly cleaner and more informative.\n\ndiff &lt;-\n  results(\n    dds,\n    contrast = c(\"timepoint\", \"DIV7\", \"DIV0\")\n  ) |&gt;\n  # Change this into a dataframe\n  ??() |&gt;\n  # Move ensembl gene IDs into their own column\n  ??(var = \"ensembl_gene_id\") |&gt;\n  # drop unused columns\n  dplyr::select(-c(baseMean, lfcSE, stat, pvalue)) |&gt;\n  # Merge this with a table relating ensembl_gene_id with gene symbols\n  inner_join(??) |&gt;\n  # Rename external_gene_name column\n  dplyr::rename(gene = external_gene_name) |&gt;\n  as_tibble()"
  },
  {
    "objectID": "exercises/ex-24.html#how-many-are-significant",
    "href": "exercises/ex-24.html#how-many-are-significant",
    "title": "RNAseq DE",
    "section": "How many are significant",
    "text": "How many are significant\nOK now we have a table of gene expression results. How many genes are significantly up/down regulated between these two timepoints? We will use 0.01 as an FDR (p.adj) cutoff.\n\n# number of upregulated genes\nnrow(filter(diff, padj &lt; ?? & log2FoldChange &gt; ??))\n\n# number of downregulated genes\nnrow(filter(diff, padj &lt; ?? & log2FoldChange &lt; ??))"
  },
  {
    "objectID": "exercises/ex-24.html#volcano-plot-of-differential-expression-results",
    "href": "exercises/ex-24.html#volcano-plot-of-differential-expression-results",
    "title": "RNAseq DE",
    "section": "Volcano plot of differential expression results",
    "text": "Volcano plot of differential expression results\nLet’s make a volcano plot of these results.\n\n# meets the FDR cutoff\ndiff_sig &lt;-\n  mutate(\n    diff,\n    sig = case_when(\n      padj &lt; ?? ~ \"yes\",\n      .default = \"no\"\n    )\n  ) |&gt;\n  # if a gene did not meet expression cutoffs that DESeq2 automatically does, it gets a pvalue of NA\n  drop_na()\n\nggplot(\n  diff_sig,\n  aes(\n    x = ??,\n    y = ??,\n    color = sig\n  )\n) +\n  geom_point(alpha = 0.2) +\n  labs(\n    x = \"DIV7 expression / DIV0 expression, log2\",\n    y = \"-log10(FDR)\"\n  ) +\n  scale_color_manual(\n    values = c(\"black\", \"red\"),\n    labels = c(\"NS\", \"FDR &lt; 0.01\"),\n    name = \"\"\n  ) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-24.html#change-the-lfc-threshold",
    "href": "exercises/ex-24.html#change-the-lfc-threshold",
    "title": "RNAseq DE",
    "section": "Change the LFC threshold",
    "text": "Change the LFC threshold\nIn addition to an FDR cutoff, let’s also apply a log2FoldChange cutoff. This will of course be more conservative, but will probably give you a more confident set of genes.\n\n# Is the expression of the gene at least 3-fold different?\ndiff_lfc &lt;-\n  results(dds,\n    contrast = c(\"timepoint\", \"DIV7\", \"DIV0\"),\n    lfcThreshold = log2(??)\n    ) |&gt;\n  # Change this into a dataframe\n  as.data.frame() |&gt;\n  # Move ensembl gene IDs into their own column\n  rownames_to_column(var = \"ensembl_gene_id\") |&gt;\n  # drop unused columns\n  dplyr::select(-c(baseMean, lfcSE, stat, pvalue)) |&gt;\n  # Merge this with a table relating ensembl_gene_id with gene short names\n  inner_join(gene_name_map) |&gt;\n  # Rename external_gene_name column\n  dplyr::rename(gene = external_gene_name) |&gt;\n  as_tibble()\n\n# number of upregulated genes\nnrow(\n  filter(\n    diff_lfc, padj &lt; 0.01 & log2FoldChange &gt; 0\n    )\n  )\n\n# number of downregulated genes\nnrow(\n  filter(\n    diff_lfc, padj &lt; 0.01 & log2FoldChange &lt; 0\n    )\n  )"
  },
  {
    "objectID": "exercises/ex-24.html#change-the-lfc-threshold-1",
    "href": "exercises/ex-24.html#change-the-lfc-threshold-1",
    "title": "RNAseq DE",
    "section": "Change the LFC threshold",
    "text": "Change the LFC threshold\n\ndiff_lfc_sig &lt;-\n  mutate(\n    diff_lfc,\n    sig = case_when(\n      padj &lt; 0.01 ~ \"yes\",\n      .default = \"no\"\n    )\n  ) |&gt;\n  drop_na()\n\n\n# look at some specific genes\ndiff_lfc_sig |&gt;\n  filter(?? %in%\nc(\"Bdnf\",\"Dlg4\",\"Klf4\",\"Sox2\")) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-24.html#filtered-volcano",
    "href": "exercises/ex-24.html#filtered-volcano",
    "title": "RNAseq DE",
    "section": "Filtered Volcano",
    "text": "Filtered Volcano\n\nggplot(\n  diff_lfc_sig,\n  aes(\n    x = log2FoldChange,\n    y = -log10(padj),\n    color = sig\n  )\n) +\n  geom_point(alpha = 0.2) +\n  labs(\n    x = \"DIV7 expression / DIV0 expression, log2\",\n    y = \"-log10(FDR)\"\n  ) +\n  scale_color_manual(\n    values = c(\"black\", \"red\"),\n    labels = c(\"NS\", \"FDR &lt; 0.01\"),\n    name = \"\"\n  ) +\n  theme_cowplot()"
  },
  {
    "objectID": "exercises/ex-24.html#plotting-the-expression-of-single-genes",
    "href": "exercises/ex-24.html#plotting-the-expression-of-single-genes",
    "title": "RNAseq DE",
    "section": "Plotting the expression of single genes",
    "text": "Plotting the expression of single genes\nSometimes we will have particular marker genes that we might want to highlight to give confidence that the experiment worked as expected. We can plot the expression of these genes in each replicate. Let’s plot the expression of two pluripotency genes (which we expect to decrease) and two neuronal genes (which we expect to increase).\nSo what is the value that we would plot? We could use the ‘normalized counts’ value provided by DESeq2. However, remember there is not length calculation so it is difficult to compare accross genes.\nA more interpretable value to plot might be TPM, since TPM is length-normalized. Let’s say a gene was expressed at 500 TPM. Right off the bat, I know generally what kind of expression that reflects (pretty high)."
  },
  {
    "objectID": "exercises/ex-24.html#get-tpms",
    "href": "exercises/ex-24.html#get-tpms",
    "title": "RNAseq DE",
    "section": "Get TPMs",
    "text": "Get TPMs\nLet’s plot the expression of Klf4, Sox2, Bdnf, and Dlg4 in our samples.\n\ntpms &lt;- txi$abundance |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ensembl_gene_id\") |&gt;\n  inner_join(??) |&gt; # add symbols\n  dplyr::rename(gene = external_gene_name) |&gt;\n  # Filter for genes we are interested in\n  filter(gene %in% c(\"Klf4\", \"Sox2\", \"Bdnf\", \"Dlg4\"))  |&gt;\n  pivot_longer(-c(ensembl_gene_id, gene)) |&gt;\n  separate(col = name, into = c(\"condition\",\"rep\"), sep = \"\\\\.\")\n\ngt(tpms)"
  },
  {
    "objectID": "exercises/ex-24.html#now-plot",
    "href": "exercises/ex-24.html#now-plot",
    "title": "RNAseq DE",
    "section": "Now plot",
    "text": "Now plot\n\nggplot(\n  tpms,\n  aes(\n    x = ??,\n    y = ??,\n    color = ??\n  )\n) +\n  geom_jitter(size = 2, width = .25) +\n  labs(\n    x = \"\",\n    y = \"TPM\"\n  ) +\n  theme_cowplot() +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  facet_wrap(~gene, scales = \"free_y\")"
  },
  {
    "objectID": "exercises/ex-24.html#how-about-pathways",
    "href": "exercises/ex-24.html#how-about-pathways",
    "title": "RNAseq DE",
    "section": "How about pathways?",
    "text": "How about pathways?\nSay that instead of plotting individual genes we wanted to ask whether a whole class of genes are going up or down. We can do that by retrieving all genes that belong to a particular gene ontology term.\nThere are three classes of genes we will look at here:\n\nMaintenance of pluripotency (GO:0019827)\nPositive regulation of the cell cycle (GO:0045787)\nNeuronal differentitaion (GO:0030182)"
  },
  {
    "objectID": "exercises/ex-24.html#retrieve-pathway-information",
    "href": "exercises/ex-24.html#retrieve-pathway-information",
    "title": "RNAseq DE",
    "section": "Retrieve pathway information",
    "text": "Retrieve pathway information\nWe can use biomaRt to get all genes that belong to each of these categories. Think of it like doing a gene ontology enrichment analysis in reverse.\n\npluripotencygenes &lt;- getBM(\n  attributes = c(\"ensembl_gene_id\"),\n  filters = c(\"go_parent_term\"),\n  values = c(\"GO:0019827\"),\n  mart = mart\n)\n\ncellcyclegenes &lt;- getBM(\n  attributes = c(\"ensembl_gene_id\"),\n  filters = c(\"go_parent_term\"),\n  values = c(\"GO:0045787\"),\n  mart = mart\n)\n\nneurongenes &lt;- getBM(\n  attributes = c(\"ensembl_gene_id\"),\n  filters = c(\"go_parent_term\"),\n  values = c(\"GO:0030182\"),\n  mart = mart\n)\n\n\n# pathway &lt;- bind_rows(pluripotencygenes,\n#           cellcyclegenes,\n#           neurongenes\n#           )\n# \n# pathway$path &lt;- c(\n#   rep(\"pluri\",nrow(pluripotencygenes)),\n#   rep(\"cellcycle\",nrow(cellcyclegenes)),\n#   rep(\"neuron\",nrow(neurongenes))\n#                   )\n# \n# write_csv(x = pathway, file = here(\"data\",\"block-rna\",\"pathwaygenes.csv.gz\"))"
  },
  {
    "objectID": "exercises/ex-24.html#add-pathway-information-to-results",
    "href": "exercises/ex-24.html#add-pathway-information-to-results",
    "title": "RNAseq DE",
    "section": "Add pathway information to results",
    "text": "Add pathway information to results\nYou can see that these items are one-column dataframes that have the column name ‘ensembl_gene_id’. We can now go through our results dataframe and add an annotation column that marks whether the gene is in any of these categories.\n\ndiff_paths &lt;-\n  diff_lfc |&gt;\n  mutate(\n    annot = case_when(\n      ?? %in% pluripotencygenes$ensembl_gene_id ~ \"pluripotency\",\n      ?? %in% cellcyclegenes$ensembl_gene_id ~ \"cellcycle\",\n      ?? %in% neurongenes$ensembl_gene_id ~ \"neurondiff\",\n      .default = \"none\"\n    )\n  ) |&gt;\n  drop_na() # drop na\n\n# Reorder these for plotting purposes\ndiff_paths$annot &lt;-\n  factor(\n    diff_paths$annot,\n    levels = c(\"none\", \"cellcycle\",\n               \"pluripotency\", \"neurondiff\")\n  )"
  },
  {
    "objectID": "exercises/ex-24.html#are-there-significant-differences",
    "href": "exercises/ex-24.html#are-there-significant-differences",
    "title": "RNAseq DE",
    "section": "Are there significant differences?",
    "text": "Are there significant differences?\nOK we’ve got our table, now we are going to ask if the log2FoldChange values for the genes in each of these classes are different that what we would expect. So what is the expected value? Well, we have a distribution of log2 fold changes for all the genes that are not in any of these categories. So we will ask if the distribution of log2 fold changes for each gene category is different than that null distribution.\n\npvals &lt;- rstatix::wilcox_test(data = ??,\n                              ?? ~ ??, ref.group = \"none\")\n\n\np.pluripotency &lt;- pvals |&gt;\n  filter(group2 == \"pluripotency\") |&gt;\n  pull(p.adj)\n\np.cellcycle &lt;- pvals |&gt;\n  filter(group2 == \"cellcycle\") |&gt;\n  pull(p.adj)\n\n\np.neurondiff &lt;- pvals |&gt;\n  filter(group2 == \"neurondiff\") |&gt;\n  pull(p.adj)"
  },
  {
    "objectID": "exercises/ex-24.html#plot-pathway-differences",
    "href": "exercises/ex-24.html#plot-pathway-differences",
    "title": "RNAseq DE",
    "section": "plot pathway differences",
    "text": "plot pathway differences\n\nggplot(\n  ??,\n  aes(\n    x = ??,\n    y = ??,\n    fill = ??\n  )\n) +\n  labs(\n    x = \"Gene class\",\n    y = \"DIV7/DIV0, log2\"\n  ) +\n  geom_hline(\n    yintercept = 0,\n    color = \"gray\",\n    linetype = \"dashed\"\n  ) +\n  geom_boxplot(\n    notch = TRUE,\n    outlier.shape = NA\n  ) +\n  theme_cowplot() +\n  scale_fill_manual(values = c(\"gray\", \"red\", \"blue\", \"purple\"), guide = F) +\n  scale_x_discrete(\n    labels = c(\n      \"none\", \"Cell cycle\", \"Pluripotency\", \"Neuron\\ndifferentiation\"\n    )\n  ) +\n  ylim(-5, 7) +\n  # hacky significance bars\n  annotate(\"segment\", x = 1, xend = 2, y = 4, yend = 4) +\n  annotate(\"segment\", x = 1, xend = 3, y = 5, yend = 5) +\n  annotate(\"segment\", x = 1, xend = 4, y = 6, yend = 6) +\n  annotate(\"text\", x = 1.5, y = 4.4, label = paste0(\"p = \", p.cellcycle)) +\n  annotate(\"text\", x = 2, y = 5.4, label = paste0(\"p = \", p.pluripotency)) +\n  annotate(\"text\", x = 2.5, y = 6.4, label = paste0(\"p = \", p.neurondiff))"
  },
  {
    "objectID": "exercises/ex-24.html#what-if-we-want-to-look-at-pathways-in-an-unbiased-way",
    "href": "exercises/ex-24.html#what-if-we-want-to-look-at-pathways-in-an-unbiased-way",
    "title": "RNAseq DE",
    "section": "What if we want to look at pathways in an unbiased way?",
    "text": "What if we want to look at pathways in an unbiased way?\nWe will use Gene Set Enrichment Analysis (GSEA) to determine if pre-defined gene sets (pathways, GO terms, experimentally defined genes) are coordinately up-regulated or down-regulated between the two conditions you are comparing. To run gsea you need 2 things. 1. You list of expressed genes ranked by fold change. 2. Pre-defined gene sets. See MSigDb\n\nPMID: 12808457, 16199517"
  },
  {
    "objectID": "exercises/ex-24.html#gsea-examples",
    "href": "exercises/ex-24.html#gsea-examples",
    "title": "RNAseq DE",
    "section": "GSEA examples",
    "text": "GSEA examples\nTop = upregulated\n\nBottom = downregulated"
  },
  {
    "objectID": "exercises/ex-24.html#prep-gsea",
    "href": "exercises/ex-24.html#prep-gsea",
    "title": "RNAseq DE",
    "section": "Prep GSEA",
    "text": "Prep GSEA\n\nWe need to make a list of all genes and their LFC.\nWe need to find interesting gene sets.\nRun GSEA\n\n\n# retrieve hallmark gene set from msigdb\nmouse_hallmark &lt;- msigdbr(species = \"??\") %&gt;%\n  filter(gs_cat == \"?\") %&gt;% ## halmark\n  dplyr::select(gs_name, gene_symbol)\n\n# create a list of gene LFCs\nrankedgenes &lt;- diff_lfc %&gt;% pull(??)\n\n# add symbols as names of the list\nnames(rankedgenes) &lt;- diff$??\n\n# sort by LFC\nrankedgenes &lt;- sort(rankedgenes, decreasing = TRUE)\n\n# deduplicate\nrankedgenes &lt;- rankedgenes[!duplicated(names(rankedgenes))]"
  },
  {
    "objectID": "exercises/ex-24.html#run-gsea",
    "href": "exercises/ex-24.html#run-gsea",
    "title": "RNAseq DE",
    "section": "Run GSEA",
    "text": "Run GSEA\n\n# run gsea\ndiv7vs0 &lt;- GSEA(geneList = ??,\n                      eps = 0,\n                     pAdjustMethod = \"fdr\",\n                     pvalueCutoff = .05,\n                     minGSSize = 20,\n                     maxGSSize = 1000,\n                     TERM2GENE = ??)\n\ndiv7vs0@result |&gt; \n  select(??,??,??) |&gt;\n  gt()"
  },
  {
    "objectID": "exercises/ex-24.html#plot-gsea",
    "href": "exercises/ex-24.html#plot-gsea",
    "title": "RNAseq DE",
    "section": "Plot GSEA",
    "text": "Plot GSEA\n\n# plot \"HALLMARK_G2M_CHECKPOINT\"\ngseaplot(x = div7vs0, geneSetID = \"HALLMARK_G2M_CHECKPOINT\")"
  },
  {
    "objectID": "prepare/prepare-01.html",
    "href": "prepare/prepare-01.html",
    "title": "R Bootcamp",
    "section": "",
    "text": "Important\n\n\n\nBefore class begins, login with your CU credentials at Posit Cloud: https://sso.posit.cloud/cu-anschutz"
  },
  {
    "objectID": "prepare/prepare-01.html#prepare",
    "href": "prepare/prepare-01.html#prepare",
    "title": "R Bootcamp",
    "section": "Prepare",
    "text": "Prepare\n📖 Read the syllabus\n📖 Read the support resources\n📖 Look over the RStudio cheatsheet"
  },
  {
    "objectID": "prepare/prepare-16.html",
    "href": "prepare/prepare-16.html",
    "title": "Preparation for the DNA Block",
    "section": "",
    "text": "Important\n\n\n\nYou will need to review this material before class 17.\n\n\n\nPapers we will discuss in the block\nWe’ll use data from the following studies in chromatin accessibility section.\nSchep AN, Buenrostro JD, Denny SK, Schwartz K, Sherlock G, Greenleaf WJ. Structured nucleosome fingerprints enable high-resolution mapping of chromatin architecture within regulatory regions. Genome Res. 2015 PMID: 26314830; PMCID: PMC4617971 [Link]\nZentner GE, Henikoff S. Mot1 redistributes TBP from TATA-containing to TATA-less promoters. Mol Cell Biol. 2013 PMID: 24144978; PMCID: PMC3889552. [Link]\n\n\nNew software we will use in the block\nGViz enables visualization of genomic signals in a “track” format. Review the GViz vignette, especially the “Basic Features” section, which provides an overview.\nvalr is a tool set for genome interval manipulation with R. Read over the “Getting Started” to get a sense of the tools and the types of analysis they enable.\nComplexHeatmap provides a flexible framework for generating heatmaps. Look over the “A Single Heatmap” section (section 2)."
  },
  {
    "objectID": "prepare/prepare-23.html",
    "href": "prepare/prepare-23.html",
    "title": "Preparation for RNA-seq analysis",
    "section": "",
    "text": "Important\n\n\n\nYou will need to review this material before class 23.\n\n\n\nPapers we will discuss in the block\nWe’ll use data from the following studies in the RNA-seq section.\nHubbard KS, Gut IM, Lyman ME, McNutt PM. Longitudinal RNA sequencing of the deep transcriptome during neurogenesis of cortical glutamatergic neurons from murine ESCs. F1000Res. 2013 PMID: 24358889; PMCID: PMC3829120. [Link]"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html",
    "href": "problem-set-keys/ps-key-02.html",
    "title": "Problem Set 2 Key",
    "section": "",
    "text": "library(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#problem-set",
    "href": "problem-set-keys/ps-key-02.html#problem-set",
    "title": "Problem Set 2 Key",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 4 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Aug 30.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-1",
    "href": "problem-set-keys/ps-key-02.html#question-1",
    "title": "Problem Set 2 Key",
    "section": "Question 1",
    "text": "Question 1\nImport the dataset data_transcript_exp_subset using the readr package.\nHint: The file is located at the following path data/data_transcript_exp_subset.csv.gz\n\nx &lt;- read_csv(here(\"data/data_transcript_exp_subset.csv.gz\"))\n\nRows: 100 Columns: 7\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (1): ensembl_transcript_id\ndbl (6): rna_0h_rep1, rna_0h_rep2, rna_0h_rep3, rna_14h_rep1, rna_14h_rep2, ...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-2",
    "href": "problem-set-keys/ps-key-02.html#question-2",
    "title": "Problem Set 2 Key",
    "section": "Question 2",
    "text": "Question 2\nExplore the dataset. Is this dataset tidy? If not, why not?\nThis data frame is a subset (100 lines) of transcript-level gene expression data where transcript abundance was measured at two different time points of a certain treatment conducted in triplicates. The column names have the format of molecule_time_replicate\nFirst, explore the structure of the dataset using some of the functions we learned in class.\n\nx\n\n# A tibble: 100 x 7\n   ensembl_transcript_id        rna_0h_rep1 rna_0h_rep2 rna_0h_rep3 rna_14h_rep1\n   &lt;chr&gt;                              &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298          243         322         303         177   \n 2 ENST00000338591.7_360_2034          19          17          15           9   \n 3 ENST00000379389.4_176_647           45          53          48          11   \n 4 ENST00000379370.6_1158_6186         42          50          52          32   \n 5 ENST00000379339.5_212_1352          17          19          25           3   \n 6 ENST00000263741.11_1328_1496        27.5        33.7        36.3        22.5 \n 7 ENST00000360001.10_285_1350        158         170.        171.        121   \n 8 ENST00000263741.11_315_1338        148.        162.        158.        116.  \n 9 ENST00000379198.3_138_1002          11          21          23           6   \n10 ENST00000347370.6_475_1096          27.3        23.8        28.5         7.33\n# i 90 more rows\n# i 2 more variables: rna_14h_rep2 &lt;dbl&gt;, rna_14h_rep3 &lt;dbl&gt;\n\nsummary(x)\n\n ensembl_transcript_id  rna_0h_rep1       rna_0h_rep2        rna_0h_rep3      \n Length:100            Min.   :   0.00   Min.   :    0.00   Min.   :    0.00  \n Class :character      1st Qu.:  10.70   1st Qu.:   11.88   1st Qu.:   11.12  \n Mode  :character      Median :  27.41   Median :   31.05   Median :   31.91  \n                       Mean   : 173.31   Mean   :  196.08   Mean   :  186.10  \n                       3rd Qu.:  87.08   3rd Qu.:  105.00   3rd Qu.:   88.33  \n                       Max.   :9802.00   Max.   :11144.00   Max.   :10619.00  \n  rna_14h_rep1       rna_14h_rep2       rna_14h_rep3     \n Min.   :   0.000   Min.   :   0.000   Min.   :   0.000  \n 1st Qu.:   3.875   1st Qu.:   3.962   1st Qu.:   5.000  \n Median :  10.435   Median :   9.665   Median :   9.665  \n Mean   : 102.875   Mean   :  93.370   Mean   : 111.515  \n 3rd Qu.:  41.000   3rd Qu.:  38.750   3rd Qu.:  48.750  \n Max.   :5292.000   Max.   :5090.000   Max.   :6012.000  \n\nglimpse(x)\n\nRows: 100\nColumns: 7\n$ ensembl_transcript_id &lt;chr&gt; \"ENST00000327044.6_51_2298\", \"ENST00000338591.7_~\n$ rna_0h_rep1           &lt;dbl&gt; 243.00, 19.00, 45.00, 42.00, 17.00, 27.50, 158.0~\n$ rna_0h_rep2           &lt;dbl&gt; 322.00, 17.00, 53.00, 50.00, 19.00, 33.67, 169.6~\n$ rna_0h_rep3           &lt;dbl&gt; 303.00, 15.00, 48.00, 52.00, 25.00, 36.33, 171.3~\n$ rna_14h_rep1          &lt;dbl&gt; 177.00, 9.00, 11.00, 32.00, 3.00, 22.50, 121.00,~\n$ rna_14h_rep2          &lt;dbl&gt; 177.00, 5.00, 5.00, 31.00, 0.00, 29.17, 124.17, ~\n$ rna_14h_rep3          &lt;dbl&gt; 239.00, 8.00, 14.00, 30.00, 2.00, 27.33, 155.33,~\n\n\nComment on whether this dataset is tidy, and if not, list the reasons why. Hint: In a tidy dataframe, every column represents a single variable and every row represents a single observation\nAnswer\nIt is not tidy because the time points and replicates are not in their own columns."
  },
  {
    "objectID": "problem-set-keys/ps-key-02.html#question-3",
    "href": "problem-set-keys/ps-key-02.html#question-3",
    "title": "Problem Set 2 Key",
    "section": "Question 3",
    "text": "Question 3\nHow will you reshape the data frame so that each row has only one experimental observation?\nHint: Use pivot_longer()\n\nx |&gt; pivot_longer(-ensembl_transcript_id)\n\n# A tibble: 600 x 3\n   ensembl_transcript_id      name         value\n   &lt;chr&gt;                      &lt;chr&gt;        &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna_0h_rep1    243\n 2 ENST00000327044.6_51_2298  rna_0h_rep2    322\n 3 ENST00000327044.6_51_2298  rna_0h_rep3    303\n 4 ENST00000327044.6_51_2298  rna_14h_rep1   177\n 5 ENST00000327044.6_51_2298  rna_14h_rep2   177\n 6 ENST00000327044.6_51_2298  rna_14h_rep3   239\n 7 ENST00000338591.7_360_2034 rna_0h_rep1     19\n 8 ENST00000338591.7_360_2034 rna_0h_rep2     17\n 9 ENST00000338591.7_360_2034 rna_0h_rep3     15\n10 ENST00000338591.7_360_2034 rna_14h_rep1     9\n# i 590 more rows\n\n\nQuestion 4\nHow will you modify the dataframe so that multiple variables are not present in a single column?\nHint: Use separate()\n\nx_tidy &lt;- x |&gt;\n  pivot_longer(-ensembl_transcript_id) |&gt;\n  separate(name, into = c(\"mol\", \"time\", \"rep\"), sep = \"_\")\n\nx_tidy\n\n# A tibble: 600 x 5\n   ensembl_transcript_id      mol   time  rep   value\n   &lt;chr&gt;                      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 ENST00000327044.6_51_2298  rna   0h    rep1    243\n 2 ENST00000327044.6_51_2298  rna   0h    rep2    322\n 3 ENST00000327044.6_51_2298  rna   0h    rep3    303\n 4 ENST00000327044.6_51_2298  rna   14h   rep1    177\n 5 ENST00000327044.6_51_2298  rna   14h   rep2    177\n 6 ENST00000327044.6_51_2298  rna   14h   rep3    239\n 7 ENST00000338591.7_360_2034 rna   0h    rep1     19\n 8 ENST00000338591.7_360_2034 rna   0h    rep2     17\n 9 ENST00000338591.7_360_2034 rna   0h    rep3     15\n10 ENST00000338591.7_360_2034 rna   14h   rep1      9\n# i 590 more rows\n\n\nQuestion 5\nHow will you save your output as a TSV file?\nHint: Use the readr cheatsheet to figure this out.\nhttps://rstudio.cloud/learn/cheat-sheets\n\nwrite_csv(x_tidy, \"transcripts.tidy.csv\")"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html",
    "href": "problem-set-keys/ps-key-04.html",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#problem-set",
    "href": "problem-set-keys/ps-key-04.html#problem-set",
    "title": "R Bootcamp Problem Set 4",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#grading-rubric",
    "href": "problem-set-keys/ps-key-04.html#grading-rubric",
    "title": "R Bootcamp Problem Set 4",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-1-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-1-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 1 5 points\n",
    "text": "Question 1 5 points\n\n\nLoad the tidyverse and here packages.\n\nImport datasets: data/data_rna_protein.csv.gz.\n\ndata_rna_protein.csv.gz: This is a combined dataset from an RNAseq and SILAC proteomics experiment, where a transcription factor (TF) was differentially expressed and the fold change in RNA and protein calculated between TF-expressing and non-expressing cells.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\nexp_tbl &lt;- read_csv(\n  here(\"problem-sets/data/data_rna_protein.csv.gz\")\n)\n\nRows: 21282 Columns: 17\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (1): geneid\ndbl (16): iDUX4_logFC, iDUX4_logCPM, iDUX4_LR, iDUX4_pval, iDUX4_fdr, hl.rat...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-2-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-2-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 2 5 points\n",
    "text": "Question 2 5 points\n\nUsing the imported data set, carry out the following:\n\nInspect the data so you know what you are dealing with (summary() etc).\nSelect only the following columns: geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, and pval.\nRename them as follows: rna_FC = iDUX4_logFC, rna_pval = iDUX4_fdr, protein_FC = hl.ratio, protein_pval = pval (hint: use dplyr::rename())\nDrop all rows with NA values in them (hint: use a function from tidyr)\nRemove duplicate rows (hint: use dplyr::distinct()).\nArrange the table by descending rna_FC and ascending protein_FC.\nConduct steps 2-7 by piping the output of one step to another (i.e, a single workflow & remember to comment).\nSave the output of this workflow into a new object.\n\n\nexp_tbl_subset &lt;- exp_tbl |&gt;\n  select(geneid, iDUX4_logFC, iDUX4_fdr, hl.ratio, pval) |&gt;\n  rename(\n    rna_FC = iDUX4_logFC,\n    rna_pval = iDUX4_fdr,\n    protein_FC = hl.ratio,\n    protein_pval = pval\n  ) |&gt;\n  drop_na() |&gt;\n  distinct() |&gt;\n  arrange(desc(rna_FC), protein_FC)"
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#question-3-5-points",
    "href": "problem-set-keys/ps-key-04.html#question-3-5-points",
    "title": "R Bootcamp Problem Set 4",
    "section": "Question 3 5 points\n",
    "text": "Question 3 5 points\n\nHow well do the overall rna_FC and protein_FC values correlate in this experiment?\nUsing the output from the above question, do the following:\n\nCreate a scatter plot of rna_FC vs protein_FC. observe how the points scatter.\nAdd a line to the plot that would indicate perfect 1:1 correlation. Hint: use geom_abline() with its slope argument.\nAdd a linear model fit using geom_smooth() (method = 'lm'). Observe how the x=y line deviates from your geom_smooth line.\nCalculate the Spearman correlation coefficient. (Hint: This uses a base R math function called cor - Use help() or Google to learn more and how to specify method as spearman)\nUsing all of the information from above, comment on the correlation between rna_FC and protein_FC below.\n\n\nggplot(exp_tbl_subset, aes(rna_FC, protein_FC)) +\n  geom_point() +\n  geom_abline(linewidth = 1, color = \"green\") +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nrna_prot_cor &lt;- cor(\n  exp_tbl_subset$rna_FC,\n  exp_tbl_subset$protein_FC,\n  method = \"spearman\"\n)\n\nAnswer\nThe green line indicates a perfect correlation, and the blue line is the linear model fit of the data. The Spearman correlation is 0.346, indicating a strong positive correlation. One way to think about this is that there are 0.346 proteins made per mRNA."
  },
  {
    "objectID": "problem-set-keys/ps-key-04.html#submit",
    "href": "problem-set-keys/ps-key-04.html#submit",
    "title": "R Bootcamp Problem Set 4",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html",
    "href": "problem-set-keys/ps-key-07.html",
    "title": "R Bootcamp Problem Set 6",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#problem-set",
    "href": "problem-set-keys/ps-key-07.html#problem-set",
    "title": "R Bootcamp Problem Set 6",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Sept 1."
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#grading-rubric",
    "href": "problem-set-keys/ps-key-07.html#grading-rubric",
    "title": "R Bootcamp Problem Set 6",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#libraries",
    "href": "problem-set-keys/ps-key-07.html#libraries",
    "title": "R Bootcamp Problem Set 6",
    "section": "Libraries",
    "text": "Libraries\nLoad the libraries you need for analysis below.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#question-1---5-points",
    "href": "problem-set-keys/ps-key-07.html#question-1---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 1 - 5 points\n",
    "text": "Question 1 - 5 points\n\nRun the following chunk:\n\nset.seed(42)\nx &lt;- sample(1000, replace = TRUE)\n\nNow use logical indexing to find the number of values &gt; 450 in x.\n\n# either are correct\nsum(x &gt; 450)\n\n[1] 566\n\nlength(x[x &gt; 450])\n\n[1] 566"
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#question-2---5-points",
    "href": "problem-set-keys/ps-key-07.html#question-2---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 2 - 5 points\n",
    "text": "Question 2 - 5 points\n\nCount the number of species in the penguins tibble using forcats::fct_count()\nCount number of island + sex combinations using dplyr::count(), and sort the result by count.\n\nforcats::fct_count(penguins$island)\n\n# A tibble: 3 x 2\n  f             n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n\n\ndplyr::count(penguins, island, sex, sort = TRUE)\n\n# A tibble: 9 x 3\n  island    sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Biscoe    male      83\n2 Biscoe    female    80\n3 Dream     male      62\n4 Dream     female    61\n5 Torgersen female    24\n6 Torgersen male      23\n7 Biscoe    &lt;NA&gt;       5\n8 Torgersen &lt;NA&gt;       5\n9 Dream     &lt;NA&gt;       1"
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#question-3---5-points",
    "href": "problem-set-keys/ps-key-07.html#question-3---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 3 - 5 points\n",
    "text": "Question 3 - 5 points\n\nUse stringr::str_c() to combine upper and lowercase letters from letters and LETTERS with a slash.\nYour answer should look like: \"A/a\" \"B/b\" \"C/c\" etc.\n\ncombined &lt;- str_c(LETTERS, \"/\", letters)\n\nUse stringr::str_split() or one of its variants to split up the strings you made above and extract the letter after the slash.\n\nstr_split_i(combined, \"/\", 2)\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nstr_split(combined, \"/\") |&gt;\n  purrr::map(2) |&gt;\n  unlist()\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\""
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#question-4---5-points",
    "href": "problem-set-keys/ps-key-07.html#question-4---5-points",
    "title": "R Bootcamp Problem Set 6",
    "section": "Question 4 - 5 points\n",
    "text": "Question 4 - 5 points\n\nCreate a ggplot using the diamonds data set.\n\nGenerate a ggridges::geom_density_ridges() for the prices, with a different fill color for each cut.\nRecolor the densities using ggplot2::scale_fill_brewer(), choosing a specific palette.\nmake the outline of the densities black, and change their alpha to 0.2.\nchange the theme to cowplot::theme_minimal_grid()\n\nremove the legend (google: “remove legend from ggplot2”)\nadd an informative title and subtitle using ggplot2::labs().\n\n\nlibrary(ggridges)\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nggplot(\n  diamonds,\n  aes(\n    x = price,\n    y = cut,\n    fill = cut\n  )\n) +\n  geom_density_ridges(color = \"black\", alpha = 0.2) +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal_grid() +\n  theme(legend.position = \"none\")\n\nPicking joint bandwidth of 458"
  },
  {
    "objectID": "problem-set-keys/ps-key-07.html#submit",
    "href": "problem-set-keys/ps-key-07.html#submit",
    "title": "R Bootcamp Problem Set 6",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-set-keys/ps-key-11.html",
    "href": "problem-set-keys/ps-key-11.html",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp"
  },
  {
    "objectID": "problem-set-keys/ps-key-11.html#problem-1",
    "href": "problem-set-keys/ps-key-11.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Problem # 1",
    "text": "Problem # 1\nAssume that the height jackalopes fit a normal distribution. Through careful field research measuring 1000 wild jackalopes, we have determined the mean height is 97 cm and the standard deviation is 10 cm. Your was camping and found a jackalope. Being a great friend and knowing your interest in jackalopes, they (harmlessly) subdued and measured the wild jackalope and found that it was 75 cm.\n\nSimulate a normal distribution of 1000 jackalope heights using the mean and sd you painstakingly measured.\n\n\nj &lt;- tibble(height = rnorm(n = 1000, mean = 97, sd = 10))\n\n\nPlot the density of the jackalope height distribution. Indicate with a vertical line the height of the jackalope your friend measured.\n\n\nggplot(\n  data = j,\n  aes(x = height)\n) +\n  geom_density() +\n  geom_vline(xintercept = 75) +\n  theme_cowplot()\n\n\n\n\n\nCalculate the probability of a jackalope being 75 cm or shorter.\n\n\npnorm(75, mean = 97, sd = 10, lower.tail = T)\n\n[1] 0.01390345\n\n\n\nAre jackalope heights normally distributed?\n\n\nj |&gt;\n  shapiro_test(height)\n\n# A tibble: 1 x 3\n  variable statistic     p\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 height       0.999 0.855"
  },
  {
    "objectID": "problem-set-keys/ps-key-11.html#explore-coin-flip-distribution-characteristics",
    "href": "problem-set-keys/ps-key-11.html#explore-coin-flip-distribution-characteristics",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Explore coin flip distribution characteristics",
    "text": "Explore coin flip distribution characteristics\nWhen we flip a fair coin multiple times (numFlips) in a row, we expect to get heads (or tails) 50% of the time on average. This is not always the case for a single round of flipping, but if we do multiple rounds with (numRounds) that average should be 50%."
  },
  {
    "objectID": "problem-set-keys/ps-key-11.html#problem-2",
    "href": "problem-set-keys/ps-key-11.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 11",
    "section": "Problem # 2",
    "text": "Problem # 2\nIn class, we simulated coin flip experiments using two different coins that were either fair (0.5 prob of head) or unfair (0.9 prob of head). We varied the number of flips in a single round (numFlips) and the number of rounds of flipping (numRounds). For this assignment, use the same to coins and use all possible combinations of numFlips and numRounds from the table below.\n\nparameters to explore\n\nnumFlips\nnumRounds\n\n\n\n5\n10\n\n\n500\n100\n\n\n\n\nCreate a tibble has all the combinations of numFlips, numRounds, and prob of getting heads.\n\n\n# hint for 8 flips and 12 rounds of a fair coin you could do\n# rbinom(n = 8, size = 12, prob = .5)/12\n\nfair5 &lt;- tibble(\n  r10 = rbinom(n = 5, size = 10, prob = .5) / 10,\n  r100 = rbinom(n = 5, size = 100, prob = .5) / 100,\n  type = rep(\"fair5\")\n)\n\n\nfair500 &lt;- tibble(\n  r10 = rbinom(n = 500, size = 10, prob = .5) / 10,\n  r100 = rbinom(n = 500, size = 100, prob = .5) / 100,\n  type = rep(\"fair500\")\n)\n\n\nunfair5 &lt;- tibble(\n  r10 = rbinom(n = 5, size = 10, prob = .9) / 10,\n  r100 = rbinom(n = 5, size = 100, prob = .9) / 100,\n  type = rep(\"unfair5\")\n)\n\nunfair500 &lt;- tibble(\n  r10 = rbinom(n = 500, size = 10, prob = .9) / 10,\n  r100 = rbinom(n = 500, size = 100, prob = .9) / 100,\n  type = rep(\"unfair500\")\n)\n\nall &lt;- bind_rows(fair5, fair500, unfair5, unfair500) |&gt;\n  pivot_longer(\n    cols = c(\"r10\", \"r100\"),\n    names_to = \"r\",\n    values_to = \"f\"\n  )\n\n\nPlot your result using faceting. I recommend faceting by numFlips (like in class describing both the number and fair v unfair) . Include the observed mean as a black diamond and the true mean as a dashed line.\n\n\nggplot(all, aes(x = r, y = f, color = r)) +\n  geom_jitter() +\n  stat_summary(\n    fun.y = mean, geom = \"point\",\n    shape = 18,\n    size = 3, color = \"black\"\n  ) +\n  ylim(-0.05, 1.05) +\n  facet_grid(~type) +\n  geom_hline(yintercept = .5, linetype = \"dashed\") +\n  geom_hline(yintercept = .9, linetype = \"dashed\") +\n  theme_cowplot()\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\ni Please use the `fun` argument instead.\n\n\n\n\n\n3. Report the means and sd of each pair of numFlips and numRounds\n\nall |&gt;\n  group_by(type, r) |&gt;\n  get_summary_stats(show = c(\"mean\", \"sd\"))\n\n# A tibble: 8 x 6\n  type      r     variable     n  mean    sd\n  &lt;chr&gt;     &lt;chr&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 fair5     r10   f            5 0.52  0.13 \n2 fair5     r100  f            5 0.512 0.029\n3 fair500   r10   f          500 0.5   0.158\n4 fair500   r100  f          500 0.497 0.053\n5 unfair5   r10   f            5 0.92  0.13 \n6 unfair5   r100  f            5 0.906 0.036\n7 unfair500 r10   f          500 0.899 0.093\n8 unfair500 r100  f          500 0.9   0.029\n\n\n4. Describe in a few sentences how increasing numFlips and numRounds alters:The estimation of and spread around the true mean.\nIncreasing numRounds leads to a closer approximation of the true mean.\nIncreasing numRounds leads to a decrease in the sd.\nIncreasing numFlips increases the sd."
  },
  {
    "objectID": "problem-set-keys/ps-key-13.html",
    "href": "problem-set-keys/ps-key-13.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "@@ -1,204 +0,0 @@\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-set-keys/ps-key-13.html#problem-1",
    "href": "problem-set-keys/ps-key-13.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nIs there an association between mouse calcium and sodium levels?\n1. Make a scatterplot to inspect variable\n\nggscatter(\n  data = b,\n  y = \"calcium\",\n  x = \"sodium\"\n)\n\n\n\n\n2. Are they normal (enough)?\n\nggqqplot(data = b, x = \"calcium\")\n\n\n\nb |&gt; shapiro_test(calcium)\n\n# A tibble: 1 × 3\n  variable statistic         p\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1 calcium      0.995 0.0000108\n\nggqqplot(data = b, x = \"sodium\")\n\n\n\nb |&gt; shapiro_test(sodium)\n\n# A tibble: 1 × 3\n  variable statistic          p\n  &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 sodium       0.995 0.00000432\n\n\nWhich test will you use and why?\n\nI will use the Pearson since the qqplots look ok and there are ~1700 observations. Spearman is fine too - especially since sodium looks a little like an integer and not continuous.\n\n3. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that there is no dependency/association between \\(calcium\\) and \\(sodium\\)\n4. Calculate and plot the correlation on a scatterplot\n\nggscatter(\n  data = b,\n  y = \"calcium\",\n  x = \"sodium\"\n) +\n  stat_cor(\n    method = \"pearson\",\n    label.x = 110,\n    label.y = 2.4\n  )"
  },
  {
    "objectID": "problem-set-keys/ps-key-13.html#problem-2",
    "href": "problem-set-keys/ps-key-13.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 2",
    "text": "Problem # 2"
  },
  {
    "objectID": "problem-set-keys/ps-key-13.html#do-mouse-calcium-levels-explain-mouse-sodium-levels-if-so-to-what-extent",
    "href": "problem-set-keys/ps-key-13.html#do-mouse-calcium-levels-explain-mouse-sodium-levels-if-so-to-what-extent",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Do mouse calcium levels explain mouse sodium levels? If so, to what extent?",
    "text": "Do mouse calcium levels explain mouse sodium levels? If so, to what extent?\nUse a linear model to do the following:\n1. Specify the Response and Explanatory variables — (2 pts)\n\nThe response variable y is sodium The explantory variable x is calcium\n\n2. Declare the null hypothesis — (1 pts)\n\nThe null hypothesis is calcium levels do not explain/predict sodium levels.\n\n3. Use the lm function to create a fit (linear model)\nalso save the slope and intercept for later\n\nfit &lt;- lm(formula = sodium ~ 1 + calcium, data = b)\n\n\nint &lt;- tidy(fit)[1, 2]\nslope &lt;- tidy(fit)[2, 2]\n\n4. Add residuals to the data and create a plot visualizing the residuals\n\nb_fit &lt;- augment(fit, data = b)\n\navg_sod &lt;- mean(b$sodium)\n\nggplot(\n  data = b_fit,\n  aes(x = calcium, y = sodium)\n) +\n  geom_point(size = 1, aes(color = .resid)) +\n  geom_abline(\n    intercept = pull(int),\n    slope = pull(slope),\n    col = \"red\"\n  ) +\n  scale_color_gradient2(\n    low = \"blue\",\n    mid = \"black\",\n    high = \"yellow\"\n  ) +\n  geom_segment(\n    aes(\n      xend = calcium,\n      yend = .fitted\n    ),\n    alpha = .1\n  ) + # plot line representing residuals\n  theme_linedraw()\n\n\n\n\n5. Calculate the \\(R^2\\) and compare to \\(R^2\\) from fit\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\n\\(SS_{fit} = \\sum_{i=1}^{n} (data - line)^2 = \\sum_{i=1}^{n} (y_{i} - (\\beta_0 \\cdot 1+ \\beta_1 \\cdot x)^2\\)\n\\(SS_{null}\\) — sum of squared errors around the mean of \\(y\\)\n\\(SS_{null} = \\sum_{i=1}^{n} (data - mean)^2 = \\sum_{i=1}^{n} (y_{i} - \\overline{y})^2\\)\n\nss_fit &lt;- sum(b_fit$.resid^2)\nss_null &lt;- sum(\n  (b_fit$sodium - avg_sod)^2\n)\nrsq &lt;- 1 - ss_fit / ss_null\nglance(fit) |&gt; select(r.squared)\n\n# A tibble: 1 × 1\n  r.squared\n      &lt;dbl&gt;\n1     0.684\n\n\n6. Using \\(R^2\\), describe the extent to which calcium explains sodium levels\n\n\\(calcium\\) explains ~68% of variation in \\(sodium\\) levels\n\n7. Report (do not calculate) the \\(p-value\\) and your decision on the null\n\nfit |&gt;\n  glance() |&gt;\n  select(p.value)\n\n# A tibble: 1 × 1\n  p.value\n    &lt;dbl&gt;\n1       0\n\n\n\nThe null hypothesis is calcium levels do not explain/predict sodium levels IS NOT SUPPORTED\n\nCalcium levels to predict sodium levels."
  },
  {
    "objectID": "problem-set-keys/ps-key-13.html#problem-3",
    "href": "problem-set-keys/ps-key-13.html#problem-3",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 3",
    "text": "Problem # 3\nWhat is the association between mouse weight and age levels for different sexes?\n1. Calculate the pearson correlation coefficient between weight and age for females and males\n\nb |&gt;\n  group_by(factor(sex)) |&gt;\n  cor_test(weight, age)\n\n# A tibble: 2 × 9\n  `factor(sex)` var1   var2    cor statistic        p conf.low conf.high method \n  &lt;fct&gt;         &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  \n1 F             weight age    0.21      6.30 4.67e-10    0.143     0.269 Pearson\n2 M             weight age    0.37     12.0  1.22e-30    0.314     0.427 Pearson\n\n\n2. Describe your observations\n\nThe relationship between weight and age is stronger for males than it is for females."
  },
  {
    "objectID": "problem-set-keys/ps-key-15.html",
    "href": "problem-set-keys/ps-key-15.html",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\nang &lt;- read_csv(here(\"data/bootcamp/edger.csv.gz\")) |&gt;\n  clean_names() |&gt;\n  filter(fdr &lt; 0.05) |&gt;\n  select(log_fc_time0_25:log_fc_time8) |&gt;\n  as.matrix()\n\nRows: 17942 Columns: 17\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (1): gene\ndbl (16): FDR, maxabsfc, logFC.Time0.25, logFC.Time0.5, logFC.Time0.75, logF...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\ncolnames(ang) &lt;- gsub(pattern = \"log_fc_\", \"\", colnames(ang))"
  },
  {
    "objectID": "problem-set-keys/ps-key-15.html#problem-1",
    "href": "problem-set-keys/ps-key-15.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "Problem # 1",
    "text": "Problem # 1\nMake sure to run the chunk above. The data represent the avg fold change in gene expression for an angiotensin II time course (.25, .5, .75, 1, 1.5, 2, 3, 4, 6, 8, 24 hrs) compared to unstimulated."
  },
  {
    "objectID": "problem-set-keys/ps-key-15.html#correlation",
    "href": "problem-set-keys/ps-key-15.html#correlation",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "correlation",
    "text": "correlation\nCreate hierarchical clustering heatmap of pairwise pearson correlation coefficients. And provide 1-2 observations.\n\n# scale\nang &lt;- t(scale(t(ang)))\n\n\n# pairwise pearson correlation\np_ang &lt;- cor(ang, method = \"pearson\")\n\n# make heatmap\npheatmap(\n  mat = p_ang,\n  clustering_distance_rows = \"euclidean\",\n  clustering_distance_cols = \"euclidean\",\n  clustering_method = \"ward.D2\"\n)\n\n\n\n\nTimepoints close to each other tend to correlate strongly with each other. The 4,6, and 8 hr time points are the most different from all others."
  },
  {
    "objectID": "problem-set-keys/ps-key-15.html#pca",
    "href": "problem-set-keys/ps-key-15.html#pca",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "PCA",
    "text": "PCA\nPerform PCA and visualize PC1 vs PC2.Provide 1-2 observations.\n\n# pca\npc_ang &lt;- prcomp(ang)\n\n# gather info from summary\npca_data_info &lt;- summary(pc_ang)$importance |&gt; as.data.frame()\n\npca_data_info &lt;- round(x = pca_data_info, digits = 3)\n\n# we make a dataframe out of the rotations and will use this to plot\npca_plot_data &lt;- pc_ang$rotation |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(var = \"ID\")\n\n# plot\nggplot(data = pca_plot_data, mapping = aes(x = PC1, y = PC2, color = ID)) +\n  geom_point() +\n  xlab(paste(\"PC1, %\", 100 * pca_data_info[\"Proportion of Variance\", \"PC1\"])) +\n  ylab(paste(\"PC2, %\", 100 * pca_data_info[\"Proportion of Variance\", \"PC2\"])) +\n  ggtitle(\"PCA for angII timecourse\") +\n  theme_cowplot()\n\n\n\n\nThere is a a circular patter that seems to correspond to the timepoints. Interestingly, 24 appears to group back with 0.25 indicating the system is resetting w/respect to RNA levels."
  },
  {
    "objectID": "problem-set-keys/ps-key-15.html#calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "href": "problem-set-keys/ps-key-15.html#calculate-the-empirical-p-value-of-the-cluster-most-enriched-for-dux4-targets-by-sampling",
    "title": "Problem Set Stats Bootcamp - class 15",
    "section": "Calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling",
    "text": "Calculate the empirical p-value of the cluster most enriched for DUX4 targets by sampling\nIn order to do this, you will need to:\n\nIdentify which cluster is the most enriched for DUX4 targets.\n\nDetermine how many genes are in the cluster. You will need to know this to figure out how many genes to sample from the whole data set.\nDetermine how many of the genes in the cluster are DUX4 targets. This is the metric that you are interested in comparing between the null distribution and your observation.\n\n\nGenerate 1000 random sample of the proper size from all genes and find out how many of them are DUX4 targets.\nVisualize the distribution of DUX4 targets in these 1000 random (your null distribution) and overlay the number of DUX4 targets you observed in the cluster that was most enriched for DUX4 targets.\n\n\n# read in data\ncd &lt;- read_tsv(here(\"data\", \"dux4_clustering_results.csv.gz\"))\n\nRows: 10566 Columns: 15\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr  (2): gene_symbol, target\ndbl (13): hour00_rep1, hour00_rep2, hour00_rep3, hour04_rep1, hour04_rep2, h...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# how many genes are in cluster 5?\nc5 &lt;- cd |&gt;\n  filter(Cluster == \"5\") |&gt;\n  nrow()\n\n# how many dux targets are in cluster 5?\nc5t &lt;- cd |&gt;\n  filter(Cluster == \"5\" & target == \"target\") |&gt;\n  nrow()\n\nsampled_targets &lt;- vector()\n\nfor (i in 1:1000) {\n  sampled_targets[i] &lt;- sample_n(tbl = cd, size = c5) |&gt;\n    group_by(target) |&gt;\n    tally() |&gt;\n    # need this so all groups have at least 1.\n    mutate(n = n + 1) |&gt;\n    filter(target == \"target\") |&gt;\n    pull(n)\n}\n\nn &lt;- tibble(\n  targets = sampled_targets,\n  type = \"null\"\n)\n\nn |&gt;\n  arrange(-sampled_targets) |&gt;\n  top_n(10)\n\nSelecting by type\n\n\n# A tibble: 1,000 x 2\n   targets type \n     &lt;dbl&gt; &lt;chr&gt;\n 1      18 null \n 2      18 null \n 3      17 null \n 4      17 null \n 5      17 null \n 6      17 null \n 7      16 null \n 8      16 null \n 9      16 null \n10      16 null \n# i 990 more rows\n\nggplot(data = n, aes(x = targets)) +\n  geom_density() +\n  geom_vline(xintercept = c5t, color = \"red\") +\n  theme_cowplot()\n\n\n\n\nWhat is the p-value?\np &lt; 0.001\nWhat is your interpretation?\nThe null hypothesis that the number of DUX4 targets in c5t can be explained by chance - IS NOT WELL SUPPORTED.\nThe number of DUX4 targets in c5t CANNOT be explained by chance."
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html",
    "href": "problem-set-keys/ps-key-18.html",
    "title": "DNA Block - Problem Set 18",
    "section": "",
    "text": "Total points: 20. First problem is worth 7 points, second problem is worth 13 points."
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html#problem-set",
    "href": "problem-set-keys/ps-key-18.html#problem-set",
    "title": "DNA Block - Problem Set 18",
    "section": "",
    "text": "Total points: 20. First problem is worth 7 points, second problem is worth 13 points."
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html#load-libraries",
    "href": "problem-set-keys/ps-key-18.html#load-libraries",
    "title": "DNA Block - Problem Set 18",
    "section": "Load libraries",
    "text": "Load libraries\nStart by loading libraries you need analysis in the code chunk below.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nlibrary(valr)\n\nLoad the data from the MNase-seq experiment.\n\n# XXX: blanks here\nmnase_tbl &lt;- read_bed(\n  here(\"data/block-dna/yeast_mnase_chrII.bed.gz\")\n)\n\nIn class we learned that MNase digestion yields nucleosomal “footprints” of ~150 bp in size. I’ve added blue vertical lines to emphasize positions of the major peak (intact nucleosomes) as well as smaller “sub-nucleosomal” peak.\n\nWe can calculate the counts for the histogram above and more precisely determine the maximum signal using which.max() to identify the index of the maximum value in a vector (not the value itself!):\n\nfrag_hist &lt;-\n  mnase_tbl |&gt;\n  mutate(frag_len = end - start) |&gt;\n  count(frag_len)\n\n# `which.max` takes a vector and gives us the index of the maximum value\nmax_idx &lt;- which.max(frag_hist$n)\n\n# now we can use index to find the abundant fragment size\nncp_max &lt;- frag_hist$frag_len[max_idx]\n\nSo this tells us that that the most abundant fragment size in the library is 149 bp."
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html#question-1-7-points",
    "href": "problem-set-keys/ps-key-18.html#question-1-7-points",
    "title": "DNA Block - Problem Set 18",
    "section": "Question 1 – 7 points",
    "text": "Question 1 – 7 points\nLet’s take a closer look at the some of the smaller fragments in the MNase experiment. In particular, let’s zoom in on the populations of fragments that are smaller than 1 nucleosome in size, the peak between 85 and 95 bp (the left-most blue vertical line).\n\nUse the above strategy to precisely determine the peak of this smaller size range. How big are those fragments? These are called “sub-nucleosomal” fragments.\n\n\nfrag_hist_sub &lt;- filter(frag_hist, frag_len &gt; 85 & frag_len &lt; 95)\nn_max_sub &lt;- which.max(frag_hist_sub$n)\nsubnuc_max &lt;- frag_hist_sub$frag_len[n_max_sub]\n\n\nThe population of fragments is at 92 bp.\n\n\nDo this one more time, and identify the position of maximum signal in the disome peak (i.e., the fragments protected by two nucleosomes).\n\n\nfrag_hist_di &lt;- filter(frag_hist, frag_len &gt; 280 & frag_len &lt; 320)\nn_max_di &lt;- which.max(frag_hist_di$n)\ndinuc_max &lt;- frag_hist_di$frag_len[n_max_di]\n\n\nRecreate the histogram using ggplot2 (using relevant code from class 17) and add the blue vertical lines at the peak positions you calculated, including the position of the disomes above.\n\n\nggplot(\n  mnase_tbl,\n  aes(x = end - start)\n) +\n  geom_histogram(\n    # single base-pair resolution\n    binwidth = 1\n  ) +\n  labs(\n    x = \"fragment length (bp)\",\n    title = \"Histogram of fragment lengths from MNase-seq\"\n  ) +\n  theme_cowplot() +\n  geom_vline(xintercept = c(subnuc_max, ncp_max, dinuc_max), color = \"blue\")"
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html#question-2-13-points",
    "href": "problem-set-keys/ps-key-18.html#question-2-13-points",
    "title": "DNA Block - Problem Set 18",
    "section": "Question 2 – 13 points",
    "text": "Question 2 – 13 points\nNext we’re going to look at where these sub-sucleosomes are with respect to intact nucleosomes.\nOur strategy will be to compare the density of sub-nucleosomes relative to the mid-points of previously mapped nucleosomes. Specifically, our reference point will be the midpoints of the +1 nucleosomes.\nSo you’ll make a metaplot, but instead of using transcription start sites as the reference point, we’ll use the midpoints of the +1 nucleosome, and instead of MNase-seq signal density, you’ll count up the number of individual reads that intersect with windows around those midpoints.\n\n\nFirst, load the relevant data. We’ll re-use the yeast_mnase_chrII.bed.gz data you loaded above, plus you’ll need to load two other files:\n\na “genome” file, sacCer3.chrom.sizes\n\na BED file, yeast_p1_chrII.bed.gz which contains the mid-points of the +1 nucleosomes on chromosome 22. Recall that the +1 nucleosome is the nucleosome downstream of the transcription start site.\n\n\n\n\n# XXX: blanks here\ngenome &lt;- read_genome(here(\"data/block-dna/sacCer3.chrom.sizes\"))\n# XXX: blanks here\np1_tbl &lt;- read_bed(here(\"data/block-dna/yeast_p1_chrII.bed.gz\"))\n\n\nNext, we need the mid-points of nucleosomes for comparison. The following function needs fixing.\n\n\ncalc_mids &lt;- function(tbl, min_len, max_len) {\n  tbl |&gt;\n    mutate(\n      # XXX: blanks here\n      frag_len = end - start\n    ) |&gt;\n    filter(\n      # XXX: blanks here\n      frag_len &gt;= min_len & frag_len &lt;= max_len\n    ) |&gt;\n    mutate(\n      # XXX: blanks here\n      midpoint = start + round((end - start) / 2)\n    ) |&gt;\n    select(chrom, midpoint) |&gt;\n    rename(start = midpoint) |&gt;\n    mutate(end = start + 1)\n}\n\n\n\n\n\nncp_mids_tbl &lt;-\n  calc_mids(mnase_tbl, ncp_max - 3, ncp_max + 3) |&gt;\n  bed_slop(genome, both = 20)\n\nsubnuc_mids_tbl &lt;-\n  calc_mids(mnase_tbl, subnuc_max - 3, subnuc_max + 3) |&gt;\n  bed_slop(genome, both = 20)\n\n\nNext, we need to make the intervals for the metaplot. We’ll look 100 bp up- and downstream of the +1 nucleosome positions, and make windows that are 1 bp in size.\n\n\np1_win_tbl &lt;-\n  bed_slop(\n    p1_tbl,\n    genome,\n    both = 100\n  ) |&gt;\n  # XXX: blank here\n  bed_makewindows(win_size = 1)\n\n\n\nAlmost there! Now you just need to identify the number of short and long nuclesome fragments (based on their midpoints) that intersect with the +1 nucleosomes you defined above.\nUse bed_intersect() to identify fragments that overlap, and then just count the number of fragments per .win_id (don’t forget the suffix). Note you will do this separately for the short and long fragments.\n\n\n\nncp_mids_summary_tbl &lt;-\n  bed_intersect(\n    p1_win_tbl,\n    ncp_mids_tbl\n  ) |&gt;\n  count(.win_id.x) |&gt;\n  mutate(type = \"Intact nucleosomes (~149 bp)\")\n\nsubnuc_mids_summary_tbl &lt;-\n  bed_intersect(\n    p1_win_tbl,\n    subnuc_mids_tbl\n  ) |&gt;\n  count(.win_id.x) |&gt;\n  mutate(type = \"Sub-nucleosomes (~90 bp)\")\n\n\nThe following joins the tables you made together, and makes the x-axis more informative, by converting to position rather than window ID.\n\n\nwin_ids &lt;- seq(-100, 100, 1)\n\nall_tbl &lt;- bind_rows(\n  ncp_mids_summary_tbl,\n  subnuc_mids_summary_tbl\n) |&gt;\n  mutate(win_ids = win_ids, .by = \"type\")\n\n\nFinally, we plot the data with position on the x-axis, and count on the y-axis.\n\n\nggplot(\n  all_tbl,\n  aes(win_ids, n)\n) +\n  geom_line(\n    linewidth = 1,\n    color = \"red\"\n    ) +\n  facet_wrap(\n    ~ type,\n    scales = \"free_y\"\n  ) +\n  theme_minimal_grid() +\n  labs(\n    x = \"Position relative to +1 nucleosome midpoints\",\n    y = \"Number of intersecting fragments\",\n    title = \"Fragment density around +1 nucleosome midpoints\"\n  )"
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html#interpretation",
    "href": "problem-set-keys/ps-key-18.html#interpretation",
    "title": "DNA Block - Problem Set 18",
    "section": "Interpretation",
    "text": "Interpretation\nHow do you interpret these plots?\nRationalize the pattern for intact nucleosomes. What pattern did you expect to see?\n\nExpectation is that large nucleosomal fragments will be centered on +1 nucleosome midpoints, so the plot agrees. The width of the density has to do with the size of the intervals we defined (expanding single-base pair midpoints by 20 and 100 bp (for query and reference intervals, respectively).\n\nRationalize the pattern for sub-nucleosome. How would you describe the positions of sub-nucleosomal fragments, relative to the +1 nucleosome midpoints? What might this mean with respect to gene transcription?\n\nThe density is bimodal, indicating two distributions of sub-nucleosomal fragments relative to +1 nucleosome midpoints. These fragments are formed at the edges of the nucleosome core particl during the process of nucleosome disassembly during transcription (losing a histone dimer from one side or the other, see Ramachandran et al. in the block resources document).\n\nWhat do the differences between signal magnitudes (reflected by the y-axis) mean?\n\nThere are more positioned +1 nucleosomes then there are sub-nucleosomal intermediates, which can be rationalized by the fact that only a subset of genes are on / being transcribed in the cells at the time of the experiment."
  },
  {
    "objectID": "problem-set-keys/ps-key-18.html#submit",
    "href": "problem-set-keys/ps-key-18.html#submit",
    "title": "DNA Block - Problem Set 18",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output. Then paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-01.html",
    "href": "problem-sets/ps-01.html",
    "title": "R Bootcamp Problem Set 1",
    "section": "",
    "text": "Each problem below is worth 10 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 10 points\nPartially correct answers: 6-8 points\nReasonable attempt: 4 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#problem-set",
    "href": "problem-sets/ps-01.html#problem-set",
    "title": "R Bootcamp Problem Set 1",
    "section": "",
    "text": "Each problem below is worth 10 points.\nThe problem set is due 12pm on Aug 30.\n\n\nEverything is good: 10 points\nPartially correct answers: 6-8 points\nReasonable attempt: 4 points"
  },
  {
    "objectID": "problem-sets/ps-01.html#setup",
    "href": "problem-sets/ps-01.html#setup",
    "title": "R Bootcamp Problem Set 1",
    "section": "Setup",
    "text": "Setup\nStart by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-1",
    "href": "problem-sets/ps-01.html#question-1",
    "title": "R Bootcamp Problem Set 1",
    "section": "Question 1",
    "text": "Question 1\nCreate 3 different vectors called x, y, and z:\n\n\nx should be character vector of length 5\n\ny should be a numerica vector of length 5\n\nz should be a logical vector of length 5\n\nUse length() to calculate the length of each vector."
  },
  {
    "objectID": "problem-sets/ps-01.html#question-2",
    "href": "problem-sets/ps-01.html#question-2",
    "title": "R Bootcamp Problem Set 1",
    "section": "Question 2",
    "text": "Question 2\nUsing the vectors you created above, create a new tibble with column names x, y, and z.\nUse nrow() and ncol() to calculate the number of rows and columns.\nWhat do you notice about the length of the vectors and the number of rows?\nAnswer here"
  },
  {
    "objectID": "problem-sets/ps-01.html#submit",
    "href": "problem-sets/ps-01.html#submit",
    "title": "R Bootcamp Problem Set 1",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-03.html",
    "href": "problem-sets/ps-03.html",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-03.html#setup",
    "href": "problem-sets/ps-03.html#setup",
    "title": "R Bootcamp Problem Set 3",
    "section": "",
    "text": "Start by loading libraries you need analysis in the code chunk below. When in doubt, start by loading the tidyverse package."
  },
  {
    "objectID": "problem-sets/ps-03.html#problem-set",
    "href": "problem-sets/ps-03.html#problem-set",
    "title": "R Bootcamp Problem Set 3",
    "section": "Problem Set",
    "text": "Problem Set\nEach problem below is worth 5 points.\nUse the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 12pm on Aug 31.\nGrading rubric\n\nEverything is good: 5 points\nPartially correct answers: 3-4 points\nReasonable attempt: 2 points"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-1",
    "href": "problem-sets/ps-03.html#question-1",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 1",
    "text": "Question 1\nLoad the palmerpenguins package. Inspect the penguins tibble with summary.\nUse drop_na() to remove rows with NA values in the penguins tibble. How many rows were removed from the tibble?\nThen, use replace_na() to replace NA values in bill_length_mm and bill_depth_mm with a value of 0."
  },
  {
    "objectID": "problem-sets/ps-03.html#question-2",
    "href": "problem-sets/ps-03.html#question-2",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 2",
    "text": "Question 2\nUse arrange, filter, and select on a dataframe. Do the following, in order:\n\nImport the data set data/data_transcript_exp_tidy.csv.\nSort the tibble by expression data (count) from highest to lowest level.\nFilter the tibble by count &gt; 100\nSelect all columns except for type"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-3",
    "href": "problem-sets/ps-03.html#question-3",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 3",
    "text": "Question 3\nHow will you:\n\ncreate a new column log10count that contains log10 transformed count values and\nrearrange the columns in the following order: ensembl_transcript_id, type, time, replicate, count, log10count.\n\n(Note that we have dropped extra)\nHint: Use mutate and select"
  },
  {
    "objectID": "problem-sets/ps-03.html#question-4",
    "href": "problem-sets/ps-03.html#question-4",
    "title": "R Bootcamp Problem Set 3",
    "section": "Question 4",
    "text": "Question 4\nCalculate a per-transcript sum, while keeping the time information?\nHint: Use group_by with multiple variables, and summarise the “count” values using sum()"
  },
  {
    "objectID": "problem-sets/ps-05.html",
    "href": "problem-sets/ps-05.html",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "Your objective is to create some new extreme art using R, something either ugly or sublime. What you cannot do is be boring; your goal is to stay on the fringe.\nYour submission (a quarto/Rmarkdown file) is due Tues Sept 5 by 12pm. If you submit an entry, you’ll get full credit on the problem set. Entries will be anonymized and winners will selected by popular vote."
  },
  {
    "objectID": "problem-sets/ps-05.html#extreme-art-objective",
    "href": "problem-sets/ps-05.html#extreme-art-objective",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "",
    "text": "Your objective is to create some new extreme art using R, something either ugly or sublime. What you cannot do is be boring; your goal is to stay on the fringe.\nYour submission (a quarto/Rmarkdown file) is due Tues Sept 5 by 12pm. If you submit an entry, you’ll get full credit on the problem set. Entries will be anonymized and winners will selected by popular vote."
  },
  {
    "objectID": "problem-sets/ps-05.html#favorite-rtists",
    "href": "problem-sets/ps-05.html#favorite-rtists",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Favorite Rtists",
    "text": "Favorite Rtists\nHere are some of my favorite generative artists who use R. Be inspired!\n\nDanielle Navarro [Art] [Github]\n\nIjeamaka Anyene [Github] and this study in particular.\nClaus Wilke [Art] [Github], a biologist at UT Austin who also wrote the book on data visualization (it’s excellent).\nThomas Lin Pederesen [Art] [Github]. I have some of his pieces in my office.\ninconvergent [Art]. It’s lisp, not R. But it’s so good.\n\nThere are several resources for color palettes, an important component of any hideous or beautiful creation.\n\nThe section in Data Viz for R on color is worth a read.\nThe colors in e.g. scale_color_brewer come from Cynthia Brewer, a cartographer who makes visually informative maps.\n\ncolor-hex has collections of complementary color palettes.\n\nThere are also several R packages that may help you build Rtistic plots.\n\n\ngganimate provides tools to bring your plots to life.\n\nggforce provides interesting geoms that build on ggplot2.\n\npatchwork provides layout functions for plots."
  },
  {
    "objectID": "problem-sets/ps-05.html#informative-but-boring.",
    "href": "problem-sets/ps-05.html#informative-but-boring.",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Informative, but boring.",
    "text": "Informative, but boring.\nThis is an informative but relatively boring plot. NOT THE GOAL HERE.\n\nCodelibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(cowplot)\n\npenguins_clean &lt;- drop_na(penguins)\n\nggplot(\n  penguins_clean,\n  aes(\n    x = body_mass_g / 1000,\n    y = bill_length_mm\n  )\n) +\n  geom_point(\n    aes(\n      shape = sex,\n      color = species\n    )\n  ) +\n  facet_grid(~island) +\n  theme_minimal_grid() +\n  scale_color_brewer(palette = \"Dark2\") +\n  labs(\n    title = \"Analysis of geographic isolation on penguin phenotypes\",\n    x = \"Body mass (kg)\",\n    y = \"Bill length (mm)\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-05.html#ugly-plots",
    "href": "problem-sets/ps-05.html#ugly-plots",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Ugly Plots",
    "text": "Ugly Plots\nYikes. We can thank Yunus Ozekin for this abomination.\n\nCodelibrary(tidyverse)\ntitanic_tbl &lt;- as_tibble(Titanic)\n\nggplot(\n  titanic_tbl,\n  aes(\n    x = Survived,\n    y = n,\n    color = Class,\n    shape = Sex,\n    size = 6\n  )\n) +\n  geom_jitter() +\n  scale_y_sqrt() +\n  labs(\n    x = \"Not Dead?\",\n    y = \"How many? (ppl)\",\n    title = \"WhO dIEd In titaNic?\",\n    caption = \"Some lived, some died.\"\n  ) +\n  scale_x_discrete(position = \"top\") +\n  theme(\n    axis.text.x = element_text(face = \"bold.italic\", color = \"#993333\", size = 18, angle = 180),\n    axis.text.y = element_text(face = \"bold\", color = \"orange\", size = 18, angle = 135),\n    plot.background = element_rect(fill = \"darkblue\"),\n    plot.title = element_text(face = \"italic\", color = \"green\", size = 48, angle = 183),\n    plot.caption = element_text(color = \"white\", size = 22),\n    axis.title.x = element_text(size = 22, color = \"pink\", angle = 12),\n    axis.title.y = element_text(color = \"yellow\", angle = 273, size = 17),\n    legend.background = element_rect(fill = \"yellow\"),\n    legend.title = element_text(angle = 71, face = \"bold\", color = \"purple\", size = 12),\n    legend.key = element_rect(color = \"green\", fill = \"orange\"),\n    legend.text = element_text(color = \"red\", size = 14),\n    panel.background = element_rect(fill = \"yellow\"),\n    panel.grid.major.y = element_line(color = \"green\", linetype = \"dotdash\", linewidth = 1.2),\n    panel.grid.major.x = element_line(color = \"purple\", linewidth = 3, linetype = \"twodash\"),\n    panel.grid.minor = element_line(color = \"red\", linewidth = 2, linetype = \"dashed\"),\n    legend.position = \"bottom\"\n  )"
  },
  {
    "objectID": "problem-sets/ps-05.html#beautiful-plots",
    "href": "problem-sets/ps-05.html#beautiful-plots",
    "title": "R Bootcamp - Problem Set 5 (Extreme aRt)",
    "section": "Beautiful Plots",
    "text": "Beautiful Plots\nThis is a piece from Ijeamaka Anyene’s ode to coord_polar() (link above). Reminds me of Miro.\n\nCodelibrary(tidyverse)\n\napply_pattern_theme &lt;- function(bg_hex, caption_hex) {\n  theme(\n    plot.background = element_rect(fill = bg_hex),\n    panel.background = element_rect(fill = bg_hex),\n    panel.grid = element_blank(),\n    plot.caption = element_text(\n      family = \"Open Sans\",\n      size = 6,\n      color = caption_hex\n    ),\n    legend.position = \"none\",\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()\n  )\n}\n\noutline &lt;- tibble(\n  x = 1, xend = 7,\n  y = 15, yend = 15\n)\nsegment_line &lt;- tibble(\n  x = c(1, 7), xend = c(1, 7),\n  y = c(0, 2), yend = 15\n)\narea &lt;- tibble(\n  x = c(3, 5, 6),\n  y = c(5, 7.5, 2),\n  type = LETTERS[1:3]\n)\npalette_values &lt;- c(\"#2a2640\", \"#a64e46\", \"#f29544\")\nggplot() +\n  geom_col(\n    data = area,\n    aes(x = x, y = y, fill = type),\n    alpha = 0.75,\n    width = 4\n  ) +\n  geom_segment(\n    data = outline,\n    aes(\n      x = x, y = y,\n      xend = xend, yend = yend\n    ),\n    size = 0.5\n  ) +\n  geom_segment(\n    data = segment_line,\n    aes(\n      x = x, xend = xend,\n      y = y, yend = yend\n    ),\n    size = 0.5\n  ) +\n  geom_point(aes(x = 5, y = 0)) +\n  scale_fill_manual(values = palette_values) +\n  scale_y_continuous(limits = c(0, 15)) +\n  scale_x_continuous(limits = c(1, 10)) +\n  coord_polar() +\n  labs(caption = \"Ijeamaka Anyene | @ijeamaka_a\") +\n  apply_pattern_theme(\n    bg_hex = \"#ded5c9\",\n    caption_hex = \"black\"\n  )\n\n\n\n\nHere’s another more complex geometric creation, again using coord_polar(). This will take a few seconds to render.\n\nCode# https://twitter.com/aschinchon/status/1095057262744387587\nlibrary(tidyverse)\n\nxy &lt;- seq(-2, 2, by = .005)\nexpand.grid(x = xy, y = xy) |&gt;\n  ggplot(\n    aes(\n      x = (cos(x)^2 + sin(y^2)),\n      y = (sin(y)^3 - cos(x^2))\n    )\n  ) +\n  geom_point(alpha = .01, shape = 20, size = 0) +\n  theme_void() +\n  coord_polar()"
  },
  {
    "objectID": "problem-sets/ps-09.html",
    "href": "problem-sets/ps-09.html",
    "title": "R Bootcamp Problem Set 9",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Sept 11."
  },
  {
    "objectID": "problem-sets/ps-09.html#problem-set",
    "href": "problem-sets/ps-09.html#problem-set",
    "title": "R Bootcamp Problem Set 9",
    "section": "",
    "text": "Use the data files in the data/ directory to answer the questions.\nFor this problem set, you are allowed to help each other, but you are not allowed to post correct answers in slack.\nThe problem set is due 5pm on Sept 11."
  },
  {
    "objectID": "problem-sets/ps-09.html#libraries",
    "href": "problem-sets/ps-09.html#libraries",
    "title": "R Bootcamp Problem Set 9",
    "section": "Libraries",
    "text": "Libraries\nLoad the libraries you need for analysis below.\nLoad the data\nLoad the data sets and inspect.\nTidy the data (4 points)\nGiven the experimental setup and the shape of the tibbles, you should be able to answer: Are these data tidy?\n\nWhat are the variables in the data?\n\n\nAnswer\n\n\nAre the variables the column names?\n\n\nAnswer\n\nThe names are encoded in the following order:\ngt, time, gene, rep_tech, rep_bio."
  },
  {
    "objectID": "problem-sets/ps-09.html#question-1-4-points",
    "href": "problem-sets/ps-09.html#question-1-4-points",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 1 (4 points)",
    "text": "Question 1 (4 points)\nCalculate summary statistics for the experiment.\n\nCalculate the mean of the technical replicates within each group of genotype, time, gene, and biological replicate.\nCalculate the mean and standard deviation of the biolgical replicates (which is the mean of technical replicates, above).\n\nYou should have a tibble that looks like this:\n# A tibble: 36 &lt;c3&gt;&lt;97&gt; 5\n   gt         time gene     bio_mean bio_sd\n   &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 RL-mutant     0 GAPDH       0.444 0.0759\n 2 RL-mutant     0 IFN-beta    3.32  0.188 \n 3 RL-mutant     4 GAPDH       1.61  0.487 \n 4 RL-mutant     4 IFN-beta   18.4   1.15  \n 5 RL-mutant     8 GAPDH       3.25  1.06  \n 6 RL-mutant     8 IFN-beta   32.2   1.82  \n 7 RL-mutant    12 GAPDH       3.90  0.911 \n 8 RL-mutant    12 IFN-beta   47.5   3.78  \n 9 RL-mutant    24 GAPDH       7.93  3.41  \n10 RL-mutant    24 IFN-beta   76.7   4.75  \n# &lt;e2&gt;&lt;84&gt;&lt;b9&gt; 26 more rows\n# &lt;e2&gt;&lt;84&gt;&lt;b9&gt; Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "problem-sets/ps-09.html#question-2-4-points",
    "href": "problem-sets/ps-09.html#question-2-4-points",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 2 (4 points)",
    "text": "Question 2 (4 points)\n\nCreate a plot of expression by time from the data, using the mean of the biological replicates as the y value.\nColor the plot by genes.\nUse ggplot2::geom_pointrange() do represent the standard deviation of the data. Alternatively, use ggplot2::geom_errobar() with geom_point().\nDraw a line through the points with geom_line().\nFacet the plot by genotype.\nChange the colors of the of the plot with a scale function.\nUpdate the labels on the plot (“time (hours)”, etc.)."
  },
  {
    "objectID": "problem-sets/ps-09.html#question-3-4-points",
    "href": "problem-sets/ps-09.html#question-3-4-points",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 3 (4 points)",
    "text": "Question 3 (4 points)\n\nWhat can you say about the expression of GAPDH and IFN in the different cell types?\n\n\nAnswer.\n\n\nCan you come up with a simple molecular mechanism to explain the results?\n\n\nAnswer."
  },
  {
    "objectID": "problem-sets/ps-09.html#question-4-4-points",
    "href": "problem-sets/ps-09.html#question-4-4-points",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 4 (4 points)",
    "text": "Question 4 (4 points)\nReformat the data from Question 2 such that you calculate a ratio of IFN to GAPDH. Start with the data Question 1.2, above.\nRe-plot the data as in Question 2, but leave out the color as you have collapsed the two genes into one value."
  },
  {
    "objectID": "problem-sets/ps-09.html#question-5-4-points",
    "href": "problem-sets/ps-09.html#question-5-4-points",
    "title": "R Bootcamp Problem Set 9",
    "section": "Question 5 (4 points)",
    "text": "Question 5 (4 points)\nIs there more spread across the technical replicates, or across the biological replicates (across the whole experiment)?\nTo get at this question, calculate the standard deviations across the two sets of replicates separately. Which one has a greater spread (max - min)? And what might this mean?\n\nAnswer."
  },
  {
    "objectID": "problem-sets/ps-09.html#grading-rubric",
    "href": "problem-sets/ps-09.html#grading-rubric",
    "title": "R Bootcamp Problem Set 9",
    "section": "Grading rubric",
    "text": "Grading rubric\n\nEverything is good: full points\nPartially correct answer: depends on how many steps are correct\nReasonable attempt: half points"
  },
  {
    "objectID": "problem-sets/ps-09.html#submit",
    "href": "problem-sets/ps-09.html#submit",
    "title": "R Bootcamp Problem Set 9",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-12.html",
    "href": "problem-sets/ps-12.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-sets/ps-12.html#problem-1",
    "href": "problem-sets/ps-12.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nDoes mouse sex explain mouse total cholesterol levels? Make sure to run chunks above.\n1. Examine and specify the variable(s)\n\nThe response variable y is \\(??\\)\nThe explantory variable x is \\(??\\)\n\nMake a violin plot:\nresponse variable on the y-axis\nexplanatory variable on the x-axis\nGet n, mean, median, sd\nIs it normally distribute?\n\nAnswer here\n\nIs it variance similar between groups?\n\nAnswer here\n\nWhat kind of test are you picking and why?\n\nAnswer here\n\n2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that \\(??\\) does not explain \\(??\\)\n3. Calculate test-statistic, exact p-value and plot\n\nMy interpretation of the result\n\n\n# i have pre-selected some families to compare\nmyfams &lt;- c(\n  \"B1.5:E1.4(4) B1.5:A1.4(5)\",\n  \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n  \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n  \"D5.4:G2.3(4) D5.4:C4.3(4)\"\n)\n\n# only keep the familys in myfams\nbfam &lt;- b |&gt;\n  filter(family %in% myfams) |&gt;\n  droplevels()\n\n# simplify family names and make factor\nbfam$family &lt;- gsub(pattern = \"\\\\..*\", replacement = \"\", x = bfam$family) |&gt;\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nbfam$family &lt;- relevel(x = bfam$family, ref = \"B1\")"
  },
  {
    "objectID": "problem-sets/ps-12.html#problem-2",
    "href": "problem-sets/ps-12.html#problem-2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 2",
    "text": "Problem # 2\nDoes mouse family explain mouse total cholesterol levels? Make sure to run chunk above.\n1. Examine and specify the variable(s)\n\nThe response variable y is \\(??\\)\nThe explantory variable x is \\(??\\)\n\nMake a plot:\nresponse variable on the y-axis\nexplanatory variable on the x-axis\nGet n, mean, median, sd\nIs it normally distribute?\n\nAnswer here\n\nIs it variance similar between groups?\n\nAnswer here\n\nWhat kind of test are you picking and why?\n\nAnswer here ### 2. Declare null hypothesis \\(\\mathcal{H}_0\\)\n\n\\(\\mathcal{H}_0\\) is that \\(??\\) does not explain \\(??\\)\n3. Calculate test-statistic, exact p-value and plot\n\nMy interpretation of the result"
  },
  {
    "objectID": "problem-sets/ps-14.html",
    "href": "problem-sets/ps-14.html",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "",
    "text": "-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nhere() starts at /Users/jayhesselberth/devel/rnabioco/molb-7950\nbiochem &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) |&gt;\n  janitor::clean_names()\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E4&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00FC&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00DF&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E6&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00D8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00F8&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00C5&gt;' to native encoding\n\n\nWarning in FUN(X[[i]], ...): unable to translate '&lt;U+00E5&gt;' to native encoding\n\n# simplify names a bit more\ncolnames(biochem) &lt;- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep &lt;- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem &lt;- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight &lt;- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) &lt;- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\n# rename gender to sex\nb &lt;- inner_join(biochem, weight, by = \"subject_name\") |&gt;\n  na.omit() |&gt;\n  rename(sex = gender)"
  },
  {
    "objectID": "problem-sets/ps-14.html#problem-1",
    "href": "problem-sets/ps-14.html#problem-1",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Problem # 1",
    "text": "Problem # 1\nCan mouse sex explain mouse cholesterol? {.smaller}"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-1-null-hypothesis-and-variable-specification",
    "href": "problem-sets/ps-14.html#step-1-null-hypothesis-and-variable-specification",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 1: Null hypothesis and variable specification",
    "text": "STEP 1: Null hypothesis and variable specification\n\\(\\mathcal{H}_0:\\)\n\n?? is the response variable\n\n\n?? is the explanatory variable"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-2-fit-linear-model-and-examine-results",
    "href": "problem-sets/ps-14.html#step-2-fit-linear-model-and-examine-results",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 2: Fit linear model and examine results",
    "text": "STEP 2: Fit linear model and examine results\nFit summary:\nCoefficient summary:"
  },
  {
    "objectID": "problem-sets/ps-14.html#collecting-residuals-and-other-information",
    "href": "problem-sets/ps-14.html#collecting-residuals-and-other-information",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Collecting residuals and other information",
    "text": "Collecting residuals and other information\nadd residuals and other information"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-4-visualize-the-error-around-fit",
    "href": "problem-sets/ps-14.html#step-4-visualize-the-error-around-fit",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 4: Visualize the error around fit",
    "text": "STEP 4: Visualize the error around fit\n\n# plot of data with mean and colored by residuals"
  },
  {
    "objectID": "problem-sets/ps-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "href": "problem-sets/ps-14.html#step-3-visualize-the-error-around-the-null-mean-weight",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "STEP 3: Visualize the error around the null (mean weight)",
    "text": "STEP 3: Visualize the error around the null (mean weight)"
  },
  {
    "objectID": "problem-sets/ps-14.html#plot-the-fit-error-and-the-null-error-as-2-panels",
    "href": "problem-sets/ps-14.html#plot-the-fit-error-and-the-null-error-as-2-panels",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Plot the fit error and the null error as 2 panels",
    "text": "Plot the fit error and the null error as 2 panels"
  },
  {
    "objectID": "problem-sets/ps-14.html#calculate-r2",
    "href": "problem-sets/ps-14.html#calculate-r2",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Calculate \\(R^2\\)\n",
    "text": "Calculate \\(R^2\\)\n\n\\(R^2 = 1 - \\displaystyle \\frac {SS_{fit}}{SS_{null}}\\)\ncheck agains Rsq in your fit"
  },
  {
    "objectID": "problem-sets/ps-14.html#compare-to-traditional-t-test",
    "href": "problem-sets/ps-14.html#compare-to-traditional-t-test",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Compare to traditional t-test",
    "text": "Compare to traditional t-test"
  },
  {
    "objectID": "problem-sets/ps-14.html#provide-your-interpreation-of-the-result",
    "href": "problem-sets/ps-14.html#provide-your-interpreation-of-the-result",
    "title": "Problem Set Stats Bootcamp - class 12",
    "section": "Provide your interpreation of the result",
    "text": "Provide your interpreation of the result"
  },
  {
    "objectID": "problem-sets/ps-16.html",
    "href": "problem-sets/ps-16.html",
    "title": "DNA Block - Problem Set 16",
    "section": "",
    "text": "You have two tasks for this problem set.\n\nRead the two papers in the preparation document before class on Wed.\nLook over the vignettes for the software in the preparation document. Use valr to complete the tasks below. These problems are due Wed at 5pm.\n\nEach problem below is worth 5 points."
  },
  {
    "objectID": "problem-sets/ps-16.html#problem-set",
    "href": "problem-sets/ps-16.html#problem-set",
    "title": "DNA Block - Problem Set 16",
    "section": "",
    "text": "You have two tasks for this problem set.\n\nRead the two papers in the preparation document before class on Wed.\nLook over the vignettes for the software in the preparation document. Use valr to complete the tasks below. These problems are due Wed at 5pm.\n\nEach problem below is worth 5 points."
  },
  {
    "objectID": "problem-sets/ps-16.html#setup",
    "href": "problem-sets/ps-16.html#setup",
    "title": "DNA Block - Problem Set 16",
    "section": "Setup",
    "text": "Setup\nLoad libraries you’ll need for analysis below.\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.3     v readr     2.1.4\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.3     v tibble    3.2.1\nv lubridate 1.9.2     v tidyr     1.3.0\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(valr)"
  },
  {
    "objectID": "problem-sets/ps-16.html#question-1-5-points",
    "href": "problem-sets/ps-16.html#question-1-5-points",
    "title": "DNA Block - Problem Set 16",
    "section": "Question 1 – 5 points",
    "text": "Question 1 – 5 points\nWe’ll work with a few different files for the next questions.\n\n\nhg19.refGene.chr22.bed.gz is a BED12 file containing gene (mRNA) information for chr22.\n\nhg19.rmsk.chr22.bed.gz is a BED6 containing repetitive elements in the human genome.\n\nhg19.dnase1.bw is a bigWig file containing DNase-seq signal.\n\nYou can find the path to each with valr_example(). Load each one individually using the valr read_* functions.\nSome valr functions require a “genome” file, which is just a tibble of chromosome names and sizes.\nThe hg19 genome file is available at valr_example(\"hg19.chrom.sizes.gz\"). Use read_genome() to load it.\nInspect the tibble. How many columns does it have? What is the largest chromosome?"
  },
  {
    "objectID": "problem-sets/ps-16.html#question-2-5-points",
    "href": "problem-sets/ps-16.html#question-2-5-points",
    "title": "DNA Block - Problem Set 16",
    "section": "Question 2 – 5 points",
    "text": "Question 2 – 5 points\nWhich repeat class covers the largest amount of chromosome 22? Use dplyr tools to analyze the repeats in hg19.rmsk.chr22.bed.gz."
  },
  {
    "objectID": "problem-sets/ps-16.html#question-3-5-points",
    "href": "problem-sets/ps-16.html#question-3-5-points",
    "title": "DNA Block - Problem Set 16",
    "section": "Question 3 – 5 points",
    "text": "Question 3 – 5 points\nWhich promoter has the highest DNase I accessibility?\n\nUse the valr create_tss() function to generate transcription start sites from the BED12 refGene annotations. How big are these intervals?\nGenerate promoter regions from the TSS with bed_slop(), adding 500 bp up- and downstream (i.e., both sides). bed_slop() requires the genome file above. How big are the regions now?\nUse bed_map() to calculate the total (i.e., summed) DNase I signal in the promoters (using the score column in the DNase file).\n\nWhich gene has the highest DNase I in the regions you defined above?"
  },
  {
    "objectID": "problem-sets/ps-16.html#submit",
    "href": "problem-sets/ps-16.html#submit",
    "title": "DNA Block - Problem Set 16",
    "section": "Submit",
    "text": "Submit\nBe sure to click the “Render” button to render the HTML output.\nThen paste the URL of this Posit Cloud project into the problem set on Canvas."
  },
  {
    "objectID": "problem-sets/ps-21.html",
    "href": "problem-sets/ps-21.html",
    "title": "DNA Block - Problem Set 21",
    "section": "",
    "text": "In this problem set you’ll examine the binding sites of the Reb1 transcription factor by CUT&RUN.\nThe first several chunks just run, putting libraries and files in your environment\nEach question below is worth 4 points.\n\nStart by loading libraries you need analysis in the code chunk below.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(valr)\nlibrary(cowplot)\n\n# genome viz\nlibrary(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\nlibrary(Gviz)\nlibrary(rtracklayer)\n\n# motif discovery and viz\nlibrary(BSgenome.Scerevisiae.UCSC.sacCer3)\nlibrary(rGADEM)\nlibrary(seqLogo)\n\nNext, load the coverage tracks for CUT&RUN data.\n\ntrack_start &lt;- 1e5 \ntrack_end &lt;- 2e5 \n\n# genes track\nsgd_genes_trk &lt;-\n  GeneRegionTrack(\n    TxDb.Scerevisiae.UCSC.sacCer3.sgdGene,\n    chromosome = \"chrII\",\n    start = track_start,\n    end = track_end,\n    fill = \"#009E73\",\n    background.title = \"white\",\n    col.title = \"black\",\n    fontsize = 14\n  )\n\n# signal tracks\ntrack_info &lt;-\n  tibble(\n    file_name = c(\n      \"CutRun_Reb1_lt120.bw\",\n      \"CutRun_Abf1_lt120.bw\",\n      \"CutRun_Reb1_gt150.bw\",\n      \"CutRun_Abf1_gt150.bw\"\n    ),\n    sample_type = c(\n      \"Reb1_Short\", \"Abf1_Short\",\n      \"Reb1_Long\", \"Abf1_Long\"\n    )\n  ) |&gt;\n  mutate(\n    file_path = here(\"data/block-dna\", file_name),\n    big_wig = purrr::map(\n      file_path, ~ import.bw(.x, as = \"GRanges\")\n    ),\n    data_track = purrr::map2(\n      big_wig, sample_type,\n      ~ DataTrack(\n          .x,\n          name = .y,\n          background.title = \"white\",\n          col.title = \"black\",\n          col.axis = \"black\",\n          fontsize = 12\n      )\n    )\n  ) |&gt;\n  dplyr::select(sample_type, big_wig, data_track)\n\n# x-axis track\nx_axis_trk &lt;- GenomeAxisTrack(\n  col = \"black\",\n  col.axis = \"black\",\n  fontsize = 16\n)\n\nNow that we have tracks loaded, we can make a plot.\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\nHow do you interpret the differences in signals between the short and long fragments above? I.e., where are the short fragments enriched? And where do you see more of the long fragments?\n\nAnswer.\n\n\nRemake the plot above, but zoom in to a promoter region that has strong enrichment for both Reb1 and Abf1 (short fragments).\nDo the signals for Reb1 and Abf1 line up with one another? Why is this the case?\n\nAnswer.\n\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = ___,\n  to = ___,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\nNext we’ll take a look at Reb1 CUT&RUN data. In the following chunk, use the appraoch we took in class to identify enriched sites of Reb1 binding.\n\nreb1_tbl &lt;- read_bigwig(here(\"data/block-dna/CutRun_Reb1_lt120.bw\"))\n\n# number of reads in the original Reb1 BED file\ntotal_reads &lt;- 16e6\n\ngenome &lt;- read_genome(here(\"data/block-dna/sacCer3.chrom.sizes\"))\n\n# how can we calculate genome size?\ngenome_size &lt;- ___ \n\n# define the genome-wide lambda value here\ngenome_lambda &lt;- ___ / ___ \n\npeak_calls &lt;-\n  reb1_tbl |&gt;\n  # define single-base sites\n  mutate(\n    midpoint = start + round((end - start) / 2),\n    start = midpoint,\n    end = start + 1,\n    # use the poisson to calculate a p-value with the genome-wide lambda\n    pval = ___(score, genome_lambda),\n    # convert p-values to FDR\n    fdr = p.adjust(pval, method = \"fdr\")\n  )\n\nLet’s take a look at a plot of the p-value across a chromosome.\nUse geom_hline() to draw a red horizontal line at a cutoff that selects ~10 regions enriched for Reb1 binding. You’ll use this cutoff in the code chunks below.\n\nggplot(\n  filter(peak_calls, chrom == \"chrII\"),\n  # convert p-values to positive values for plotting\n  aes(start, ___)\n) + \n  geom_line() +\n  xlim(track_start, track_end) +\n  theme_cowplot() +\n  geom_hline(___)\n\n\nHow many peaks are called in this region? Use the cutoff you defined above to identify “peaks” of Reb1 binding.\n\nAnswer.\n\nHow many total peaks are identified in the genome using this cutoff?\n\nAnswer.\n\n\n# most stringent cut-off\npeak_calls_sig &lt;- \n  filter(\n    peak_calls,\n    ___\n    ) |&gt;\n    # collapse neighboring, significant sites\n    bed_merge(max_dist = 20)\n\nfilter(\n  peak_calls_sig,\n  chrom == \"chrII\" &\n    start &gt;= track_start &\n    end &lt;= track_end\n)\n\nLet’s visualize these peaks in the context of genomic CUT&RUN signal. We need to define an AnnotationTrack with the peak intervals, which we can plot against the CUT&RUN coverage we defined above.\n\n# need a GRanges object to convert to an AnnotationTrack\npeak_calls_gr &lt;-\n  GRanges(\n    seqnames = peak_calls_sig$chrom,\n    ranges = IRanges(peak_calls_sig$start, peak_calls_sig$end)\n  )\n\npeak_calls_trk &lt;-\n  AnnotationTrack(\n    peak_calls_gr,\n    name = \"Peak calls\",\n    fill = \"red\",\n    background.title = \"white\",\n    col.title = \"red\",\n    fontsize = 16,\n    rotation.title = 0\n  )\n\nreb1_short_trk &lt;-\n  filter(\n    track_info,\n    sample_type == \"Reb1_Short\"\n  ) |&gt;\n  pull(data_track)\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    reb1_short_trk,\n    peak_calls_trk,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\nUse the peak calls you defined to identify a putative sequence motif bound by Reb1. You can assume that the most abundant motif identified is the most likely candidate.\nUse Google and Pubmed to identify a study that defines a Reb1 motif using a genomewide analysis. How well does your motify match the previously defined one?\n\npeak_seqs &lt;- BSgenome::getSeq(\n  # provided by BSgenome.Scerevisiae.UCSC.sacCer3\n  Scerevisiae,\n  peak_calls_gr\n)\n\n# takes ~2 minutes to run\ngadem &lt;- rGADEM::GADEM(\n  peak_seqs,\n  genome = Scerevisiae,\n  verbose = 1\n)\n\n# look at the consensus motifs\nconsensus(gadem)\n\n# how many consensus motifs are there?\nnOccurrences(gadem)\n\nNow let’s look at the sequence logo for the top hit.\n\npwm &lt;- gadem@motifList[[1]]@pwm\n\nseqLogo::seqLogo(pwm)"
  },
  {
    "objectID": "problem-sets/ps-21.html#problem-set",
    "href": "problem-sets/ps-21.html#problem-set",
    "title": "DNA Block - Problem Set 21",
    "section": "",
    "text": "In this problem set you’ll examine the binding sites of the Reb1 transcription factor by CUT&RUN.\nThe first several chunks just run, putting libraries and files in your environment\nEach question below is worth 4 points.\n\nStart by loading libraries you need analysis in the code chunk below.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(valr)\nlibrary(cowplot)\n\n# genome viz\nlibrary(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\nlibrary(Gviz)\nlibrary(rtracklayer)\n\n# motif discovery and viz\nlibrary(BSgenome.Scerevisiae.UCSC.sacCer3)\nlibrary(rGADEM)\nlibrary(seqLogo)\n\nNext, load the coverage tracks for CUT&RUN data.\n\ntrack_start &lt;- 1e5 \ntrack_end &lt;- 2e5 \n\n# genes track\nsgd_genes_trk &lt;-\n  GeneRegionTrack(\n    TxDb.Scerevisiae.UCSC.sacCer3.sgdGene,\n    chromosome = \"chrII\",\n    start = track_start,\n    end = track_end,\n    fill = \"#009E73\",\n    background.title = \"white\",\n    col.title = \"black\",\n    fontsize = 14\n  )\n\n# signal tracks\ntrack_info &lt;-\n  tibble(\n    file_name = c(\n      \"CutRun_Reb1_lt120.bw\",\n      \"CutRun_Abf1_lt120.bw\",\n      \"CutRun_Reb1_gt150.bw\",\n      \"CutRun_Abf1_gt150.bw\"\n    ),\n    sample_type = c(\n      \"Reb1_Short\", \"Abf1_Short\",\n      \"Reb1_Long\", \"Abf1_Long\"\n    )\n  ) |&gt;\n  mutate(\n    file_path = here(\"data/block-dna\", file_name),\n    big_wig = purrr::map(\n      file_path, ~ import.bw(.x, as = \"GRanges\")\n    ),\n    data_track = purrr::map2(\n      big_wig, sample_type,\n      ~ DataTrack(\n          .x,\n          name = .y,\n          background.title = \"white\",\n          col.title = \"black\",\n          col.axis = \"black\",\n          fontsize = 12\n      )\n    )\n  ) |&gt;\n  dplyr::select(sample_type, big_wig, data_track)\n\n# x-axis track\nx_axis_trk &lt;- GenomeAxisTrack(\n  col = \"black\",\n  col.axis = \"black\",\n  fontsize = 16\n)\n\nNow that we have tracks loaded, we can make a plot.\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\nHow do you interpret the differences in signals between the short and long fragments above? I.e., where are the short fragments enriched? And where do you see more of the long fragments?\n\nAnswer.\n\n\nRemake the plot above, but zoom in to a promoter region that has strong enrichment for both Reb1 and Abf1 (short fragments).\nDo the signals for Reb1 and Abf1 line up with one another? Why is this the case?\n\nAnswer.\n\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    track_info$data_track,\n    x_axis_trk\n  ),\n  from = ___,\n  to = ___,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\nNext we’ll take a look at Reb1 CUT&RUN data. In the following chunk, use the appraoch we took in class to identify enriched sites of Reb1 binding.\n\nreb1_tbl &lt;- read_bigwig(here(\"data/block-dna/CutRun_Reb1_lt120.bw\"))\n\n# number of reads in the original Reb1 BED file\ntotal_reads &lt;- 16e6\n\ngenome &lt;- read_genome(here(\"data/block-dna/sacCer3.chrom.sizes\"))\n\n# how can we calculate genome size?\ngenome_size &lt;- ___ \n\n# define the genome-wide lambda value here\ngenome_lambda &lt;- ___ / ___ \n\npeak_calls &lt;-\n  reb1_tbl |&gt;\n  # define single-base sites\n  mutate(\n    midpoint = start + round((end - start) / 2),\n    start = midpoint,\n    end = start + 1,\n    # use the poisson to calculate a p-value with the genome-wide lambda\n    pval = ___(score, genome_lambda),\n    # convert p-values to FDR\n    fdr = p.adjust(pval, method = \"fdr\")\n  )\n\nLet’s take a look at a plot of the p-value across a chromosome.\nUse geom_hline() to draw a red horizontal line at a cutoff that selects ~10 regions enriched for Reb1 binding. You’ll use this cutoff in the code chunks below.\n\nggplot(\n  filter(peak_calls, chrom == \"chrII\"),\n  # convert p-values to positive values for plotting\n  aes(start, ___)\n) + \n  geom_line() +\n  xlim(track_start, track_end) +\n  theme_cowplot() +\n  geom_hline(___)\n\n\nHow many peaks are called in this region? Use the cutoff you defined above to identify “peaks” of Reb1 binding.\n\nAnswer.\n\nHow many total peaks are identified in the genome using this cutoff?\n\nAnswer.\n\n\n# most stringent cut-off\npeak_calls_sig &lt;- \n  filter(\n    peak_calls,\n    ___\n    ) |&gt;\n    # collapse neighboring, significant sites\n    bed_merge(max_dist = 20)\n\nfilter(\n  peak_calls_sig,\n  chrom == \"chrII\" &\n    start &gt;= track_start &\n    end &lt;= track_end\n)\n\nLet’s visualize these peaks in the context of genomic CUT&RUN signal. We need to define an AnnotationTrack with the peak intervals, which we can plot against the CUT&RUN coverage we defined above.\n\n# need a GRanges object to convert to an AnnotationTrack\npeak_calls_gr &lt;-\n  GRanges(\n    seqnames = peak_calls_sig$chrom,\n    ranges = IRanges(peak_calls_sig$start, peak_calls_sig$end)\n  )\n\npeak_calls_trk &lt;-\n  AnnotationTrack(\n    peak_calls_gr,\n    name = \"Peak calls\",\n    fill = \"red\",\n    background.title = \"white\",\n    col.title = \"red\",\n    fontsize = 16,\n    rotation.title = 0\n  )\n\nreb1_short_trk &lt;-\n  filter(\n    track_info,\n    sample_type == \"Reb1_Short\"\n  ) |&gt;\n  pull(data_track)\n\nplotTracks(\n  c(\n    sgd_genes_trk,\n    reb1_short_trk,\n    peak_calls_trk,\n    x_axis_trk\n  ),\n  from = track_start,\n  to = track_end,\n  chromosome = \"chrII\",\n  transcriptAnnotation = \"gene\",\n  shape = \"arrow\",\n  type = \"histogram\"\n)\n\n\nUse the peak calls you defined to identify a putative sequence motif bound by Reb1. You can assume that the most abundant motif identified is the most likely candidate.\nUse Google and Pubmed to identify a study that defines a Reb1 motif using a genomewide analysis. How well does your motify match the previously defined one?\n\npeak_seqs &lt;- BSgenome::getSeq(\n  # provided by BSgenome.Scerevisiae.UCSC.sacCer3\n  Scerevisiae,\n  peak_calls_gr\n)\n\n# takes ~2 minutes to run\ngadem &lt;- rGADEM::GADEM(\n  peak_seqs,\n  genome = Scerevisiae,\n  verbose = 1\n)\n\n# look at the consensus motifs\nconsensus(gadem)\n\n# how many consensus motifs are there?\nnOccurrences(gadem)\n\nNow let’s look at the sequence logo for the top hit.\n\npwm &lt;- gadem@motifList[[1]]@pwm\n\nseqLogo::seqLogo(pwm)"
  },
  {
    "objectID": "problem-sets/ps-24.html",
    "href": "problem-sets/ps-24.html",
    "title": "RNA Block - Problem Set 24",
    "section": "",
    "text": "Total points: 20. Q1 - 10 pts, Q2,3 - 5 points each.\n\nPerform differential expression analysis comparing DIV28 vs DIV0 (10 pts)\nAre axonogenesis and cell cycle genes significantly differentially expressed? If so, in what direction (up/down-regulated)?\nPerform GSEA analysis using the Hallmark gene set. Make enrichment plot of HALLMARK_G2M_CHECKPOINT geneset."
  },
  {
    "objectID": "problem-sets/ps-24.html#problem-set",
    "href": "problem-sets/ps-24.html#problem-set",
    "title": "RNA Block - Problem Set 24",
    "section": "",
    "text": "Total points: 20. Q1 - 10 pts, Q2,3 - 5 points each.\n\nPerform differential expression analysis comparing DIV28 vs DIV0 (10 pts)\nAre axonogenesis and cell cycle genes significantly differentially expressed? If so, in what direction (up/down-regulated)?\nPerform GSEA analysis using the Hallmark gene set. Make enrichment plot of HALLMARK_G2M_CHECKPOINT geneset."
  },
  {
    "objectID": "problem-sets/ps-24.html#load-libraries-and-generate-gene-information-files-0-pts",
    "href": "problem-sets/ps-24.html#load-libraries-and-generate-gene-information-files-0-pts",
    "title": "RNA Block - Problem Set 24",
    "section": "Load libraries and generate gene information files (0 pts)",
    "text": "Load libraries and generate gene information files (0 pts)\nMake sure to run the code chunk below to load required libraries and generate t2g (file for tximport) and gene id to symbol mapping file.\n\nlibrary(biomaRt)\nlibrary(tximport)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3          ✔ readr     2.1.4     \n✔ forcats   1.0.0          ✔ stringr   1.5.0     \n✔ ggplot2   3.4.3          ✔ tibble    3.2.1     \n✔ lubridate 1.9.3          ✔ tidyr     1.3.0     \n✔ purrr     1.0.2.9000     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::select() masks biomaRt::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(DESeq2)\n\nLoading required package: S4Vectors\nLoading required package: stats4\nLoading required package: BiocGenerics\n\nAttaching package: 'BiocGenerics'\n\nThe following objects are masked from 'package:lubridate':\n\n    intersect, setdiff, union\n\nThe following objects are masked from 'package:dplyr':\n\n    combine, intersect, setdiff, union\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\nThe following objects are masked from 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\nAttaching package: 'S4Vectors'\n\nThe following objects are masked from 'package:lubridate':\n\n    second, second&lt;-\n\nThe following objects are masked from 'package:dplyr':\n\n    first, rename\n\nThe following object is masked from 'package:tidyr':\n\n    expand\n\nThe following object is masked from 'package:utils':\n\n    findMatches\n\nThe following objects are masked from 'package:base':\n\n    expand.grid, I, unname\n\nLoading required package: IRanges\n\nAttaching package: 'IRanges'\n\nThe following object is masked from 'package:lubridate':\n\n    %within%\n\nThe following objects are masked from 'package:dplyr':\n\n    collapse, desc, slice\n\nThe following object is masked from 'package:purrr':\n\n    reduce\n\nLoading required package: GenomicRanges\nLoading required package: GenomeInfoDb\nLoading required package: SummarizedExperiment\nLoading required package: MatrixGenerics\nLoading required package: matrixStats\n\nAttaching package: 'matrixStats'\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\n\nAttaching package: 'MatrixGenerics'\n\nThe following objects are masked from 'package:matrixStats':\n\n    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n    colWeightedMeans, colWeightedMedians, colWeightedSds,\n    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n    rowWeightedSds, rowWeightedVars\n\nLoading required package: Biobase\nWelcome to Bioconductor\n\n    Vignettes contain introductory material; view with\n    'browseVignettes()'. To cite Bioconductor, see\n    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n\n\nAttaching package: 'Biobase'\n\nThe following object is masked from 'package:MatrixGenerics':\n\n    rowMedians\n\nThe following objects are masked from 'package:matrixStats':\n\n    anyMissing, rowMedians\n\nlibrary(ggrepel)\nlibrary(here)\n\nhere() starts at /Users/nmukherjee/Dropbox/My Mac (Neelanjan’s MacBook Pro)/Documents/GitHub/molb-7950\n\nlibrary(cowplot)\n\n\nAttaching package: 'cowplot'\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nlibrary(rstatix)\n\n\nAttaching package: 'rstatix'\n\nThe following object is masked from 'package:IRanges':\n\n    desc\n\nThe following object is masked from 'package:biomaRt':\n\n    select\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nlibrary(clusterProfiler)\n\n\nRegistered S3 methods overwritten by 'treeio':\n  method              from    \n  MRCA.phylo          tidytree\n  MRCA.treedata       tidytree\n  Nnode.treedata      tidytree\n  Ntip.treedata       tidytree\n  ancestor.phylo      tidytree\n  ancestor.treedata   tidytree\n  child.phylo         tidytree\n  child.treedata      tidytree\n  full_join.phylo     tidytree\n  full_join.treedata  tidytree\n  groupClade.phylo    tidytree\n  groupClade.treedata tidytree\n  groupOTU.phylo      tidytree\n  groupOTU.treedata   tidytree\n  inner_join.phylo    tidytree\n  inner_join.treedata tidytree\n  is.rooted.treedata  tidytree\n  nodeid.phylo        tidytree\n  nodeid.treedata     tidytree\n  nodelab.phylo       tidytree\n  nodelab.treedata    tidytree\n  offspring.phylo     tidytree\n  offspring.treedata  tidytree\n  parent.phylo        tidytree\n  parent.treedata     tidytree\n  root.treedata       tidytree\n  rootnode.phylo      tidytree\n  sibling.phylo       tidytree\nclusterProfiler v4.8.3  For help: https://yulab-smu.top/biomedical-knowledge-mining-book/\n\nIf you use clusterProfiler in published research, please cite:\nT Wu, E Hu, S Xu, M Chen, P Guo, Z Dai, T Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo, and G Yu. clusterProfiler 4.0: A universal enrichment tool for interpreting omics data. The Innovation. 2021, 2(3):100141\n\nAttaching package: 'clusterProfiler'\n\nThe following object is masked from 'package:IRanges':\n\n    slice\n\nThe following object is masked from 'package:S4Vectors':\n\n    rename\n\nThe following object is masked from 'package:purrr':\n\n    simplify\n\nThe following object is masked from 'package:biomaRt':\n\n    select\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nlibrary(enrichplot)\nlibrary(msigdbr)\n# run the code below to generate t2g file and gene id-symbol mapping file\nmart &lt;- biomaRt::useMart(\n  \"ENSEMBL_MART_ENSEMBL\",\n  dataset = \"mmusculus_gene_ensembl\"\n)\n\nt2g &lt;- biomaRt::getBM(\n  attributes = c(\n    \"ensembl_transcript_id\",\n    \"ensembl_gene_id\",\n    \"external_gene_name\"\n  ),\n  mart = mart\n) |&gt;\n  as_tibble()\n\n# maps systematic to common gene names\ngene_name_map &lt;- t2g |&gt;\n  dplyr::select(-ensembl_transcript_id) |&gt;\n  unique()"
  },
  {
    "objectID": "problem-sets/ps-24.html#q1-perform-differential-expression-analysis-comparing-div28-vs-div0",
    "href": "problem-sets/ps-24.html#q1-perform-differential-expression-analysis-comparing-div28-vs-div0",
    "title": "RNA Block - Problem Set 24",
    "section": "Q1 Perform differential expression analysis comparing DIV28 vs DIV0",
    "text": "Q1 Perform differential expression analysis comparing DIV28 vs DIV0\nPrepare metadata and use tximport\n\n\nmetadata &lt;- data.frame(\n  sample_id = list.files(here(\"??\"),\n                         pattern = \"^DIV\"),\n  salmon_dirs = list.files(here(\"??\"),\n                           recursive = ??,\n                           pattern = \".gz$\",\n                           full.names = ??)\n  ) |&gt;\n  separate(col = sample_id, into = c(\"timepoint\",\"rep\"), sep = \"\\\\.\", remove = F)\n\nmetadata$rep &lt;- gsub(pattern = \"Rep\", replacement = \"\", metadata$rep) \n\nrownames(metadata) &lt;- metadata$sample_id\n\nmetadata &lt;- metadata |&gt; \n  filter(timepoint %in% c(\"??\",\"??\")) \n\nsalmdir &lt;- metadata$salmon_dirs\nnames(salmdir) &lt;- metadata$sample_id\n\ntxi &lt;- tximport(\n  files = salmdir,\n  type = \"salmon\",\n  tx2gene = t2g,\n  dropInfReps = TRUE,\n  countsFromAbundance = \"lengthScaledTPM\"\n)\n\nFilter genes and perform DESeq2\n\n\n# examine distribution of TPMs\nhist(log2(1 + rowSums(txi$??)), breaks = 40)\n\n# decide a cutoff\nkeepG &lt;- txi$abundance[log2(1 + rowSums(txi$abundance)) &gt; ??,] |&gt;\n  rownames()\n\nddsTxi &lt;- DESeqDataSetFromTximport(\n  ??,\n  colData = metadata,\n  design = ~??\n)\n\n# keep genes with sufficient expession\nddsTxi &lt;- ??\n\n# run DESeq2\ndds &lt;- ??\n\n# create a dataframe containing results and join w/gene symbols\ndiff &lt;-\n  results(\n    dds,\n    contrast = c(\"timepoint\", \"??\", \"??\")\n  ) |&gt;\n  # Change this into a dataframe\n  as.data.frame() |&gt;\n  # Move ensembl gene IDs into their own column\n  rownames_to_column(var = \"ensembl_gene_id\") |&gt;\n  # drop unused columns\n  dplyr::select(-c(baseMean, lfcSE, stat, pvalue)) |&gt;\n  # Merge this with a table relating ensembl_gene_id with gene short names\n  inner_join(gene_name_map) |&gt;\n  # Rename external_gene_name column\n  dplyr::rename(gene = external_gene_name) |&gt;\n  as_tibble()"
  },
  {
    "objectID": "problem-sets/ps-24.html#q2.-are-axonogenesis-and-cell-cycle-genes-significantly-differentially-expressed-if-so-in-what-direction-updown-regulated",
    "href": "problem-sets/ps-24.html#q2.-are-axonogenesis-and-cell-cycle-genes-significantly-differentially-expressed-if-so-in-what-direction-updown-regulated",
    "title": "RNA Block - Problem Set 24",
    "section": "Q2. Are axonogenesis and cell cycle genes significantly differentially expressed? If so, in what direction (up/down-regulated)?",
    "text": "Q2. Are axonogenesis and cell cycle genes significantly differentially expressed? If so, in what direction (up/down-regulated)?\n\ncellcyclegenes &lt;- ??(\n  attributes = c(\"ensembl_gene_id\"),\n  filters = c(\"go_parent_term\"),\n  values = c(\"GO:0045787\"),\n  mart = mart\n)\n\n\naxongenes &lt;- ??(\n  attributes = c(\"ensembl_gene_id\"),\n  filters = c(\"go_parent_term\"),\n  values = c(\"GO:0007409\"),\n  mart = mart\n)\n\ndiff_paths &lt;-\n  diff |&gt;\n  mutate(\n    annot = case_when(\n      ensembl_gene_id %in% axongenes$ensembl_gene_id ~ \"??\",\n      ensembl_gene_id %in% cellcyclegenes$ensembl_gene_id ~ \"??\",\n      .default = \"none\"\n    )\n  ) |&gt;\n  drop_na() # drop na\n\n# Reorder these for plotting purposes\ndiff_paths$annot &lt;-\n  factor(\n    diff_paths$annot,\n    levels = c(\"none\",\n               \"axonogenesis\",\n               \"cellcycle\")\n  )\n\n# calculate and report p-value using wilcox test\npvals &lt;- wilcox_test(data = diff_paths,\n                     ?? ~ ??,\n                     ref.group = \"??\")\n\n# make a plot of the LFC (y-axis) ~ pathways (x-axis)\nggplot(\n  diff_paths,\n  aes(\n    x = ??,\n    y = ??,\n    fill = ??\n  )\n) +\n  labs(\n    x = \"Gene class\",\n    y = \"DIV28/DIV0, log2\"\n  ) +\n  geom_hline(\n    yintercept = 0,\n    color = \"gray\",\n    linetype = \"dashed\"\n  ) +\n  geom_boxplot(\n    notch = TRUE,\n    outlier.shape = NA\n  ) +\n  ylim(-5,5) +\n  theme_cowplot()"
  },
  {
    "objectID": "problem-sets/ps-24.html#q3.-perform-gsea-analysis-using-the-hallmark-gene-set.",
    "href": "problem-sets/ps-24.html#q3.-perform-gsea-analysis-using-the-hallmark-gene-set.",
    "title": "RNA Block - Problem Set 24",
    "section": "Q3. Perform GSEA analysis using the Hallmark gene set.",
    "text": "Q3. Perform GSEA analysis using the Hallmark gene set.\n\n# retrieve mouse hallmark gene set from msigdb\nmouse_hallmark &lt;- msigdbr(species = \"??\") %&gt;%\n  filter(gs_cat == \"??\") %&gt;% \n  dplyr::select(gs_name, gene_symbol)\n\n\n# create a list of gene LFCs\nrankedgenes &lt;- diff %&gt;% pull(??)\n\n# add symbols as names of the list\nnames(rankedgenes) &lt;- diff$??\n\n# sort by LFC\nrankedgenes &lt;- sort(??, decreasing = TRUE)\n\n# deduplicate\nrankedgenes &lt;- rankedgenes[!duplicated(names(rankedgenes))]\n\n\n# run gsea\n?? &lt;- GSEA(geneList = ??,\n                      eps = 0,\n                     pAdjustMethod = \"fdr\",\n                     pvalueCutoff = .05,\n                     minGSSize = 20,\n                     maxGSSize = 1000,\n                     TERM2GENE = ??)\n\n\n# plot \"HALLMARK_G2M_CHECKPOINT\"\ngseaplot(x = ??, geneSetID = \"??\")"
  },
  {
    "objectID": "resources/block-rna-resources.html",
    "href": "resources/block-rna-resources.html",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "The paper describing salmon and its approach to transcriptome quantification\nThe documentation for salmon\nThe documentation for tximport"
  },
  {
    "objectID": "resources/block-rna-resources.html#software",
    "href": "resources/block-rna-resources.html#software",
    "title": "Resources for the RNA block",
    "section": "",
    "text": "The paper describing salmon and its approach to transcriptome quantification\nThe documentation for salmon\nThe documentation for tximport"
  },
  {
    "objectID": "resources/plot-competition.html",
    "href": "resources/plot-competition.html",
    "title": "Plot competition entries",
    "section": "",
    "text": "Vote for your favorites at Google Form.\n\nPlot 1\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\ntst=penguins\n# View(tst)\ntstpp=drop_na(tst)\n# View(tstpp)\nggplot(data=tstpp,aes(x=body_mass_g/6350.29,                 y=flipper_length_mm))+geom_point(aes(shape=sex, color=species),alpha=0.4, shape= 8)+ labs(title=\" Stones & Flippers in Penguins\",x=\"Stones is a totally normal unit\", y=\"aQuAtIc LoCoMoTiOn ApPeNdAgE (mm)\")+theme(panel.background = element_rect(fill = \"magenta\"))+theme(panel.grid.major = element_line(linewidth = 5, color = \"#ff1493\"))+theme(panel.grid.minor = element_line(linewidth = 5, color = \"#ffd700\"))+theme(legend.background = element_rect(fill = \"yellow\"))+theme(legend.title = element_text(angle = 310, face = \"bold\", color = \"#FFFACD\", size = 56))+theme(axis.text.y = element_text(face = \"bold\", color = \"#EEE685\", size = 5, angle = 67))+theme(axis.text.x = element_text(face = \"italic\", color = \"#8B8970\", size = 5, angle = 67))+theme( legend.text = element_text(face=\"italic\",color = \"red\", size = 36))+theme( legend.key = element_rect(color = \"white\", fill = \"olivedrab1\"))+theme(axis.title.y = element_text(color = \"#ffd700\", angle = 90, size = 9))+ theme(axis.title.x = element_text(size = 16, color = \"magenta\", angle = 0))+theme(plot.background = element_rect(fill = \"red\"))+theme(plot.title = element_text(face = \"plain\", color = \"magenta\", size = 24, angle = 0))\n\n\n\n\n\n\n\nPlot 2\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(here)\n\nlibrary(cowplot) # to make panels of plots\nlibrary(ggridges) # ridge plots\n\n#HOW GOOD IS THE SIMPSON\nsimpson_tibble &lt;- read_csv(here(\"data/plot-competition/simpsons_episodes.csv.gz\"))\nsimpson_tibble_cleaned &lt;- simpson_tibble |&gt; select(-image_url, -video_url)\n\nsimpson_tibble_cleaned_1.1 &lt;- simpson_tibble_cleaned |&gt; \n  group_by(season, us_viewers_in_millions) |&gt;\n  summarise(season, us_viewers_in_millions)\n\nsimpson_plot_ugly &lt;- ggplot(\n  simpson_tibble_cleaned,\n  aes(x = season,\n      y = us_viewers_in_millions,\n      color = imdb_rating,\n      size = imdb_votes\n      )\n  ) +\n  geom_point(alpha = 0.1) +\n  facet_wrap (\n    ~ imdb_rating,\n    nrow = 1\n  ) +\n   labs(\n    title = \"istheSiMpSoNsSTILLPOPULAR!!!!!!!!!!!!\",\n    subtitle = \"D'OOOOOOOOOHHHHHHHHHHH?\",\n    y = \"THEPPLWHOWATCH\",\n    x = \"SIMIPSONS OVER THE YEARS\",\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"limegreen\"),\n    axis.text.x = element_text( color = \"purple\", size = 18, angle = 156), \n    axis.text.y = element_text( color = \"red\", size = 18, angle = 135), \n    plot.title = element_text( color = \"green\", size = 10, angle = 263), \n    plot.caption = element_text(color = \"gray\", size = 22), \n    axis.title.x = element_text(size = 22, color = \"hotpink\", angle = 66), \n    axis.title.y = element_text(color = \"maroon\", angle = 473, size = 17),\n    legend.background = element_rect(fill = \"yellow\"), \n    legend.title = element_text(angle = 71, face = \"bold\", color = \"blue\", size = 12), \n    legend.key = element_rect(color = \"green\", fill = \"lightblue\"), \n    legend.text = element_text(color = \"cyan\", size = 14)\n    ) \nsimpson_plot_ugly\n\n\n\n\n\n\n\nPlot 3\n\n\nCode\nlibrary(tidyverse)\n\nggplot(starwars,\n       aes(\n         x = height,\n         y = birth_year,\n         color = homeworld\n       )) +\n  geom_point() +\n  labs(\n    title = \"starwars?\"\n  ) +\n  theme(\n    plot.title = element_text(face = \"italic\", color = \"yellow\", size = 16, angle = -45),\n    plot.background = element_rect(fill = 'green'),\n    panel.background = element_rect(fill = 'tomato1'),\n    plot.caption = element_text(),\n    legend.position = \"none\",\n    axis.title = element_text(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank()) +\n  coord_polar()\n\n\n\n\n\n\n\nPlot 4\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins_tbl = as_tibble(penguins)\n\npenguin2 &lt;- drop_na(penguins_tbl)\n\nggplot(\n  penguin2,\n  aes(\n    x = bill_length_mm,\n    y = flipper_length_mm,\n    color = species,\n    shape = sex\n  )\n) +\n  geom_point(alpha = .65, size = 10) +\n  xlim(30,61) +\n  ylim(150,250) +\n  labs(\n    x = \"Choose ur fighter\",\n    y = \"How big that flipper?\",\n    title = \"What penguin wins in a fight?\",\n    caption = \"Fight club: antarctica edition\"\n    ) + \n  theme(\n    axis.text.x = element_text(family = \"serif\", face = \"bold\", color = \"purple\", size = 20, angle = 11),\n    axis.text.y = element_text(family = \"luminari\", face = \"bold.italic\", color = \"yellow\", size = 24, angle = 135),\n    plot.background = element_rect(fill = \"#8c510a\"),\n    plot.title = element_text(family = \"luminari\", face = \"bold\", color = \"green\", size = 20, angle = 1, line= -5 ), \n    plot.caption = element_text(family = \"short\", face = \"italic\", color = \"#35978f\", size = 26, angle = 8), \n    axis.title.x = element_text(family = \"mono\", size = 30, color = \"blue\", angle = 183), \n    axis.title.y = element_text(color = \"darkorange\", angle = 275, size = 17),\n    legend.background = element_rect(fill = \"#dfc27d\"),\n     legend.title = element_text(family = \"short\", angle = 11, face = \"bold\", color = \"hotpink\", size = 9), \n    legend.key = element_rect(color = \"darkgreen\", fill = \"red\"), \n    legend.text = element_text(color = \"yellow\", size = 10, angle = 187, face = \"italic\"), \n    panel.background = element_rect(fill = \"brown\"), \n    panel.grid.major.x = element_line(linewidth = 5, color = \"yellow\"),\n      panel.grid.minor = element_line(linewidth = 3, color = \"red\"),\n    panel.grid.major.y = element_line(color = \"green\", linewidth = 4),\n    \n   \n  )\n\n\n\n\n\n\n\nPlot 5\n\n\nCode\nggplot(\n  quakes,\n  aes(\n    x = lat,\n    y = long,\n    fill = mag,\n  )\n) +\n  geom_hex(fill = \"orange2\") +\n  geom_rug(sides = \"trbl\", alpha = 1/2, position = \"jitter\", fill = \"sienna1\") +\n  geom_violin(fill = \"yellow2\") +\n  scale_y_reverse() + \n  scale_x_continuous() +\n  labs(\n    x = \"the higher the latittude, the higher the altitude\",\n    y = \"totally longitudinal\",\n    title = \"DroP THaT a$$ Like an &lt;ce&gt;&lt;b5&gt;&lt;ce&gt;&lt;b1&gt;&lt;cf&gt;&lt;81&gt;&lt;cf&gt;&lt;84&gt;&lt;ce&gt;&lt;b7&gt;QUAKE\"\n  ) + \n  theme(\n    axis.text.x = element_text(family = \"Impact\",face = \"bold\", color = \"darkgoldenrod2\", size = 15, angle = 183, debug = TRUE), \n    axis.text.y = element_text(family = \"Courier New\", face = \"bold\", color = \"darkgoldenrod3\", size = 15, angle = 290, debug = TRUE), \n    axis.title.x = element_text(family=\"Comic Sans MS\", face = \"bold\", color = \"blanchedalmond\", size = 22, debug = TRUE),\n    axis.title.y = element_text(family=\"Comic Sans MS\", face = \"bold\", color = \"bisque1\", size = 22, debug = TRUE),\n    panel.background = element_rect(fill = \"burlywood1\", color = \"chocolate1\", linewidth = 4), \n    plot.background = element_rect(fill = \"khaki1\"),\n    panel.grid.major = element_line(linewidth = 1, color = \"tan1\"),\n    panel.grid.minor = element_line(linewidth = 4, color = \"lightgoldenrod1\"),\n    plot.title = element_text(face = \"bold\", color = \"darkgoldenrod1\", size = 20)\n  )\n\n\n\n\n\nPlot 6\n\n\nCode\nlibrary(ggpubr)\nlibrary(jpeg)\nurl &lt;- \"https://i.imgur.com/qtPINjN.jpg\"\ndownload.file(url, destfile = here(\"data/plot-competition/trees.jpg\"))\nimg &lt;- jpeg::readJPEG(here(\"data/plot-competition/trees.jpg\"))\n\nggplot(\n data = trees,\n  mapping = aes(\n    x = Height,\n    y = Girth,\n    color = count(x),\n    size = 10\n  )\n) +\n  background_image(img) +\n  annotate(\"rect\", \n           xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf,\n           fill = \"green\", alpha = .8) +\n  geom_jitter(\n    aes(\n    fill = Volume,\n    size = Height\n  ), \n  alpha = 0.9,\n  shape = 24,\n  color = \"magenta\"\n) +\n  theme(\n    plot.background = element_rect(fill = \"magenta\"),\n    axis.text.x = element_text(face = \"bold\", color = \"orange\", size = 12, angle = 200),\n    axis.text.y = element_text(face = \"bold\", color = \"yellow\", size = 18, angle = 179),\n    axis.title.x = element_text(size = 34, color = \"grey\", angle = 90), \n    axis.title.y = element_text(color = \"maroon\", angle = 180, size = 17),\n  ) +\n  labs(\n    title = \"nature \\U1F600\",\n    x = \"tall\",\n    y = \"beefy\"\n  ) +\ntheme(legend.position = \"none\")\n\n\n\n\n\nPlot 7\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(knitr)\nlibrary(palmerpenguins)\nlibrary(cowplot)\nlibrary(ggridges)\nlibrary(datasets)\n\nchk_tbl &lt;- as_tibble(ChickWeight)\n\nggplot(\n  chk_tbl,\n  aes(\n    x = Time,\n    y = weight,\n    color = Diet,\n    size = weight\n  )\n) + \n  geom_point(\n  ) + \n  labs(\n    title = \"how much chonk can a little chick chonk if a\\nlittle chick could chomp chomp?\",\n    subtitle = \"cheep! cheep!                                       chomp!\",\n    x = \"time\",\n    y = \"chick chonk\",\n    legend = \"dr. chomp's\\nexperimental diet programs\",\n    Diet = \"dr. chomp's\\nexperimental diet programs\"\n  ) +\n  xlim(\n    -3, 25\n  )  + \n  theme(\n    axis.text.x = element_text(face = \"bold.italic\", color = \"#FFE70F\", size = 18, angle = 180),\n    axis.text.y = element_text(face = \"bold\", color = \"#FFE70F\", size = 25, angle = 290),\n    axis.title.x = element_text(face = \"bold\", color = \"lightgoldenrod3\", size = 26, angle = 358), \n    axis.title.y = element_text(face = \"bold\", color = \"lightgoldenrod3\", size = 12, angle = 275),\n    plot.background = element_rect(fill = \"#C4C254\"),\n    plot.title = element_text(face = \"bold\", color = \"gold2\", size = 16, angle = 1),\n    legend.background = element_rect(fill = \"yellow\"),\n    legend.title = element_text(face = \"bold\", color = \"palevioletred4\", size = 10, angle = 156), \n    legend.text = element_text(color = \"lightgoldenrod3\", size = 14),\n    panel.background = element_rect(fill = \"khaki4\"),\n    panel.grid.major.y = element_line(color = \"rosybrown3\"), \n    panel.grid.major.x = element_line(color = \"cadetblue4\"),\n    panel.grid.minor = element_line(color = \"khaki4\")\n  ) +\n  scale_color_manual(\n    breaks = c(\"1\", \"2\", \"3\", \"4\"),\n    values = c(\"thistle1\", \"darkslategray4\", \"lightcyan\", \"yellowgreen\")\n  ) \n\n\n\n\n\n\n\nPlot 8\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(cowplot)\n\npenguins &lt;- drop_na(penguins)\n\nggplot(penguins,\n       aes(x = log2(bill_depth_mm),\n           y = flipper_length_mm/log2(bill_length_mm),\n           shape = (species))) +\n    geom_point(aes(color = body_mass_g/333), size = 8) +\n    scale_color_gradient2(low = \"magenta\", mid = \"yellow\", high = \"chartreuse4\", midpoint = 14) +\n    facet_grid(~ year) +\n    theme_minimal_grid() +\n    labs(\n        title = \"Fun penguin facts - by year (as inspired by a watermelon)\",\n        x = \"thick beak with log2?\",\n        y = \"long flipper/long bill? if long bill still long when log2\",\n        caption = \"Wut do u mean these data mean nothing to you?\"\n    ) +\n#Ugly theme inspired by Yunus Ozekin\n      theme(\n    axis.text.x = element_text(face = \"bold.italic\", color = \"#993333\", size = 29, angle = 330), \n    axis.text.y = element_text(face = \"bold\", color = \"orange\", size = 23, angle = 186), \n    plot.background = element_rect(fill = \"chartreuse4\"), \n    plot.title = element_text(face = \"bold\", color = \"chartreuse\", size = 65, angle = 1),\n    panel.background = element_rect(fill = \"brown1\"), \n    panel.grid.major.y = element_line(color = \"chartreuse1\", linetype = \"dotdash\", linewidth = 1.2), \n    panel.grid.major.x = element_line(color = \"magenta3\", linewidth = 3, linetype = \"twodash\"), \n    axis.title.x = element_text(face = \"italic\", size = 37, color = \"purple4\", angle = 12), \n    axis.title.y = element_text(face = \"bold\", color = \"yellow3\", angle = 273, size = 28),\n    plot.caption = element_text(size = 33, color = \"brown3\", angle = 4)\n)\n\n\n\n\n\n\n\nPlot 9\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nlyrics &lt;- c(\"I was tired of my lady wed been together too long Like a worn-out recording of a favorite song So while she lay there sleepin I read the paper in bed And in the personal columns there was this letter I read If you like Pina Coladas and getting caught in the rain If youre not into yoga if you have half a brain If you like making love at midnight in the dunes on the cape Then Im the love that youve looked for write to me and escape\")\n\n# Process lyrics into vector\nlyrics &lt;- lyrics %&gt;%\n  tolower() %&gt;%\n  str_split(pattern = \" \") %&gt;%\n  unlist() %&gt;%\n  unique()\n\n# Create tibble\ncolada_tbl &lt;- tibble(song_lyrics_1 = lyrics)\n\n# Add values for similarity of each given word in the song to each other given word\nfor (num_x in 1:length(lyrics)){\n  new_vector &lt;- c()\n  for (num_y in 1:length(lyrics)){\n    characters_1 &lt;- str_split(lyrics[num_x], \"\")[[1]]\n    characters_2 &lt;- str_split(lyrics[num_y], \"\")[[1]]\n    similarity &lt;- sum(characters_1 %in% characters_2)/((length(characters_1)+length(characters_2))/2)\n    new_vector &lt;- c(new_vector,similarity)}\n  colada_tbl[lyrics[num_x]] &lt;- new_vector\n}\n\n# Function to add an beach scene\nocean &lt;- function(tbl,disp_word){\n  disp_word &lt;- unlist(str_split(disp_word,pattern = \"\"))\n    for (i in 1:length(disp_word)){\n      sea &lt;- sample(30:35,1)\n      foam &lt;- sample(2:6,1)\n      sand &lt;- 64 - sea - foam\n      tbl &lt;- tbl %&gt;%\n      rbind(c(disp_word[i],rep(1, sea), rep(0.2, foam), rep(-1, sand)))\n    }\n  return(tbl)\n}\n\n# Add in a beach scene with some random row names\ncolada_tbl &lt;- ocean(colada_tbl,'QWERTYUOPASDFGHJKLZXCVBNM1234567890')\n\n# Make into long tbl\ncolada_long &lt;- pivot_longer(colada_tbl, cols = lyrics,names_to = \"song_lyrics_2\", values_to = \"Similarity\")\n\n# Order tibble correctly for visualization\ncolada_long$song_lyrics_1 &lt;- factor(colada_long$song_lyrics_1, \n                                   levels = c(rev(unlist(str_split('QWERTYUOPASDFGHJKLZXCVBNM1234567890',pattern=\"\"))),rev(lyrics)))\n  \ncolada_long$song_lyrics_2 &lt;- factor(colada_long$song_lyrics_2, \n                                   levels = lyrics)\n\n# Make similarity values numeric\ncolada_long$Similarity &lt;- as.numeric(colada_long$Similarity)\n\n# Plot the Pi&lt;c3&gt;&lt;b1&gt;a Colada Art\nggplot(colada_long, aes(x = song_lyrics_2, y = song_lyrics_1)) +\n  geom_tile(aes(fill = Similarity)) + # Fill based on word similarity values\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, # Font, color, size, and orientation of axis labels\n                                   color = 'darkgrey',family = \"Comic Sans MS\"),\n        axis.text.y = element_text(angle = 0, hjust = 1, \n                                   color = 'darkgrey',family = \"Comic Sans MS\")) +\n  scale_fill_gradient2(low = \"#F0E68C\", high = \"skyblue\", mid = \"white\", midpoint = 0.2) + # Add scale of heatmap\n  geom_boxplot(aes(x = song_lyrics_2, y = Similarity*8-8, color = song_lyrics_2)) + # Add rainbow boxplots\n  scale_color_discrete() +\n  theme(legend.position = \"none\") + # Remove legend\n  theme(text = element_text(size = 6)) +\n  labs(title = \"DUNES ON THE CAPE\", # Add title and axis labels\n       x= 'Getting Caught in the Rain', \n       y = 'Pi&lt;c3&gt;&lt;b1&gt;a Coladas') +\n  theme(plot.title = element_text(size = 25,family = \"Times New Roman\",color='lavender', \n                                  face = 'bold', hjust = 0.5),\n        axis.title.x = element_text(size = 15,family = \"Comic Sans MS\",color='salmon'),\n        axis.title.y = element_text(size = 15,family = \"Comic Sans MS\",color='pink')) + # Add in \"Margaritaville\" text\n            geom_text(aes(x = 'like', y = 'like', label = 'Pi&lt;c3&gt;&lt;b1&gt;a Colada'),size = 3, \n                      color = 'skyblue') +\n            geom_text(aes(x = 'while', y = 'while', label = 'Pi&lt;c3&gt;&lt;b1&gt;a Colada'),size = 5, \n                      color = 'skyblue') +\n            geom_text(aes(x = 'columns', y = 'columns', label = 'Pi&lt;c3&gt;&lt;b1&gt;a Colada'),size = 8, \n                      color = 'skyblue') +\n            geom_text(aes(x = 'midnight', y = 'midnight', label = 'Pi&lt;c3&gt;&lt;b1&gt;a Colada'),size = 10, \n                      color = 'skyblue')\n\n\n\n\n\nPlot 10\n\n\nCode\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(cowplot)\n\n#Plot stacked columns with lengths as percent of world population per year\n# Pipe that assigns output as df and starts with the world population dataset\ndf &lt;- population |&gt;\n        mutate(percent_population=(population/max(population)*100)) |&gt;\n          filter(percent_population&gt;5) |&gt;\n            arrange(population)\np &lt;-  ggplot(data=df) +       \n      geom_col(aes(country, percent_population)) +\n      labs(title = 'Percent of World Population of Countries in {frame_time}', x='', y='') +\n      theme_cowplot() +\n      transition_time(as.integer(year)) +\n      ease_aes('linear') \n# Animate graphs and save animation\nsuppressWarnings(animate(p, renderer=gifski_renderer(), file_renderer=\"data/out/animation\"))\nanim_save(\"data/out/animation/gg_anim_wc.gif\")\n\n\n\n\n\nPlot 11\n\n\nCode\nlibrary(tidyverse)\nlibrary(gapminder)\n\nggplot(\n  gapminder,\n  aes(\n    x = lifeExp,\n    y = gdpPercap,\n    color = year,\n    shape = continent,\n    size = pop\n  )\n) +\n\n  geom_jitter(\n    color = \"#edfd07\", \n    fill = \"white\", \n    size = 10,\n    alpha = 0.2\n  ) +\n  scale_x_log10() +\n  scale_y_sqrt() +\n  labs(\n    x = \"When die?\",\n    y = \"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\",\n    title = \"money made x age\",\n    ) + \n  scale_x_discrete(position = \"top\") + \n  theme(\n    axis.text.x = element_text(face = \"bold.italic\", color = \"purple\", size = 18, angle = 180), \n    axis.text.y = element_text(face = \"italic\", color = \"white\", size = 12, angle = 90), \n    plot.title = element_text(face = \"bold.italic\", color = \"#6ef710\", size = 15, angle = 90), \n    axis.title.x = element_text(size = 10, color = \"pink\", angle = 270), \n    axis.title.y = element_text(color = \"white\", angle = 120, size = 20),\n    plot.background = element_rect(fill = \"#10f7ed\"), \n    legend.background = element_rect(fill = \"#6ef710\"), \n    legend.title = element_text(angle = 95, face = \"italic\", color = \"#edfd07\", size = 7), \n    legend.key = element_rect(color = \"magenta\", fill = \"#10f7ed\"), \n    legend.text = element_text(color = \"#10f7ed\", size = 8), \n    panel.background = element_rect(fill = \"magenta\"), \n    legend.position = \"right\",\n    panel.grid = element_blank()\n  )\n\n\n\n\n\nPlot 12\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(\"starwars\")\nstarwars_data &lt;- starwars %&gt;%\n  select(name, height, mass, species)\n\ndat &lt;- data.frame(\n  x0 = rep(0, nrow(starwars_data)),\n  y0 = rep(0, nrow(starwars_data)),\n  x1 = runif(nrow(starwars_data)),\n  y1 = runif(nrow(starwars_data)),\n  shade = seq(1, nrow(starwars_data)),\n  size = 0.6\n)\n\nggplot(dat, aes(x = x0, y = y0, xend = x1, yend = y1, colour = shade, size = size)) +\n  geom_segment(show.legend = FALSE) +\n  coord_polar() +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0)) + \n  scale_color_gradient(low = \"blue\", high = \"white\") + \n  scale_size(range = c(2, 10)) + \n  theme_void() +\n  theme(plot.background = element_rect(fill = \"black\"))\n\n\n\n\n\n\n\nPlot 13\n\n\nCode\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(ggplot2)\nbfro_reports_geocoded &lt;- read_csv(here(\"data/plot-competition/bfro_reports_geocoded.csv.gz\"))\n\ncobigfoot = filter(\n  bfro_reports_geocoded,\n  state == \"Colorado\"\n)\n\nggplot(\n  cobigfoot,\n  aes(\n    x = conditions,\n    y = temperature_high\n  )\n) +\n  geom_point(\n    aes(\n      color = season,\n      size = wind_speed\n    ),\n    shape = 8,\n  ) +\n  coord_polar() +\n  labs(\n    x = \"Hows that sky?\",\n    y = \"Hot or Not: Temperature\",\n    title = \"Will YOU see Bigf00t?\",\n    subtitle = \"Colorado edition\",\n    caption = \"ItS BiGf00t SeAsON\"\n  ) +\n  scale_x_discrete(position = \"top\") +\n  theme(axis.title.x = element_text(family = \"mono\", color = \"lightblue\", face = \"bold\", size = 15)) +\n   theme(axis.title.y = element_text(family = \"sans\", color = \"blue\", face = \"bold\", size = 13)) +\n   theme(plot.caption = element_text(color = \"purple\", size = 22, angle = 20, family = \"mono\")) +\n   theme(plot.title = element_text(family = \"mono\",color = \"red\", hjust = 0.5, line = -10, size = 30))  +\n  theme(plot.subtitle = element_text(family = \"serif\",hjust = 0.75, angle = 5, line = -2, color = \"pink\", size = 25)) +\n  theme(plot.background = element_rect(fill = \"darkblue\")) +\n  theme(panel.background = element_rect(fill = \"yellow\")) +\n  theme(panel.grid.major = element_blank()) +\n  theme(legend.title = element_text(face = \"bold\", color = \"purple\", size = 5)) +\n  theme(legend.text = element_text(color = \"magenta\", size = 5)) +\n  theme(axis.text.x = element_text(family = \"mono\", color = \"lightblue\", face = \"bold\")) +\ntheme(axis.text.y = element_text(family = \"serif\", color = \"white\", face = \"bold\", size = 10)) + \n  geom_jitter(\n    color = \"green\",\n    shape = 12\n  )\n\n\n\n\n\n\n\nPlot 14\n\n\nCode\nlibrary(tidyverse)\nggplot(data = Orange,\n       mapping = aes(\n         x = age,\n         y =  circumference,\n         color = Tree,\n       )\n) +\n  geom_point() +\n  theme(panel.background = element_rect(fill = \"green\")) +\n  labs(\n    x = \"age\",\n    y = \"CIRCUMFERENCE\",\n    title = \"orange trees\",\n    ) +\n  theme(legend.position = \"bottom\") +\n  theme(plot.background = element_rect(fill = \"red\"))\n\n\n\n\n\n\n\nPlot 15\n\n\nCode\nlibrary(tidyverse)\nlibrary(DAAG)\n\ngreatLakes &lt;- as_tibble(greatLakes) %&gt;%\n  mutate(Michigan = michHuron, year = 1918:2009) %&gt;%\n  #, puddle_in_my_backyard = Ontario\n  #mutate(puddle_in_my_backyard = 0) %&gt;%\n  select(year, Huron = michHuron, everything()) %&gt;%\n  pivot_longer(cols = 2:6, names_to = \"lake\", values_to = \"heights\")\ngreatLakes$heights[552] = 2\n\nggplot(data = greatLakes, aes(x = year, y = heights^3, color = lake)) + \n  geom_point() + geom_line(alpha = 0.9, linewidth = 4) +\n  geom_vline(aes(xintercept = 1965), color = \"white\") +\n  geom_text(aes(label = \"lake level\", angle = 100), size = 2) +\n  theme(plot.background = element_rect(fill = \"mediumspringgreen\"),\n        plot.title = element_text(color = \"greenyellow\", size = 17, angle = 1), \n        plot.caption = element_text(color = \"white\", size = 22),#not in use\n        axis.title.x = element_text(size = 12, color = \"pink\", angle = 1), \n        axis.title.y = element_text(color = \"pink\", size = 12, angle = 92), \n        axis.ticks = element_line(color = \"pink\", linewidth = 13),\n        axis.text = element_text(color = \"green2\", face = \"bold\"),\n        legend.background = element_rect(fill = \"black\"), \n        legend.title = element_text(color = \"mediumorchid4\", size = 10, angle = 359), \n        legend.key = element_rect(color = \"orange\", fill = \"yellow\"), \n        legend.text = element_text(color = \"red\", size = 6, face = \"bold\"), \n        panel.background = element_rect(fill = \"red\"), \n        panel.grid.major.y = element_line(color = \"yellow\", linewidth = 10, linetype = \"dashed\"), \n        panel.grid.major.x = element_line(color = \"yellow\", linewidth = 0.1), \n        panel.grid.minor = element_line(color = \"green\", linewidth = 0.2)\n        #legend.position = \"bottom\"\n) +\n  labs(x = \"year\", y = \"heights (cubed)\",\n       title = \"gr8 lakes\") +\n  annotate(x = 1975, y = 3000000, label = \"1975: Edmund Fitzgerald sinks\", size = 2.5,  vjust = 3.5, geom=\"label\")\n\n\n\n\n\nPlot 16\n\n\nCode\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(RColorBrewer)\nlibrary(Rtsne)\n\nsetup_coords &lt;- function(groups = 3, n = 100, sd = .05) {\n  tibble(\n    x = rep(1:groups, each = n) + rnorm(groups*n, sd = sd),\n    y = rep(seq(from = 0, to = 10, length.out = n), groups) + \n          rnorm(groups*n, sd = sd),\n    group = rep(letters[1:groups], each = n)\n  )\n}\n\ndo_tsne &lt;- function(coords, perplexity = 5) {\n  tsne_fit &lt;- coords %&gt;%\n    select(x, y) %&gt;%\n    scale() %&gt;%\n    Rtsne(perplexity = perplexity, max_iter = 500, check_duplicates = FALSE)\n  \n    tsne_fit$Y %&gt;%\n      as.data.frame() %&gt;%\n      cbind(select(coords, -x, -y))\n}\n\nfinal_plot &lt;- function(groups = 24, n = 800, sd = 4, perplexity = 100) {\n  setup_coords(groups = groups, n = n, sd = sd) %&gt;%\n    do_tsne(perplexity) %&gt;%\n    ggplot(aes(V1, V2, color = group)) + \n    geom_point(show.legend = FALSE) +\n    coord_fixed() + theme_void() + \n    ggtitle(\"It is a flower\")+\n    scale_color_brewer(palette='PiYG', type=\"seq\")+\n    theme(\n      plot.margin = margin(20, 20, 20, 20),\n      panel.border = element_rect(color = \"white\", fill = NA),\n      plot.title = element_text(family = \"serif\", hjust = 0.5, face = \"italic\")\n      )\n}\n\nfinal_plot(groups = 15, sd = 40)\n\n\n\n\n\nPlot 17\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(here)\nlibrary(ggridges)\nlibrary(viridis)\n\nggplot(\n  diamonds,\n  aes(\n    x = carat,\n    y = log10(depth) + sin(carat)\n  )\n) + \n  stat_density2d(\n    aes(fill = after_stat(density)), \n    geom = 'tile', \n    contour = F,\n    size = 0.22,\n    bins = 20,\n    linetype = 5,\n    show.legend = FALSE\n  ) +\n  scale_fill_viridis()+\n  geom_density2d(\n    aes(fill = ..level..), \n    geom = \"polygon\", \n    colour= \"white\",\n   linewidth = 0.25, \n   bins = 10\n  ) +\n  theme_void()+\n  xlim(0,2.5)+\n  ylim(1.9,2.9)\n\n\n\n\n\n\n\nPlot 18\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\ncustom_colors&lt;-c(\"tan4\",\"olivedrab4\",\"orange3\")\n\nggplot(\n  data=iris,\n  mapping=aes(\n    x=Petal.Width,\n    y=Petal.Length,\n    fill=Species\n  )\n)+\n  geom_boxplot()+\n  labs(\n    x=\"Error\",\n    y=\"errors per error\",\n    color=\"error\",\n    title = \"Teefs\",\n    subtitle=\"ERROR codes COLLECTED infinity gauntlet style I am Thanos but better (or WORSE?????)\",\n  )+\n  theme_cowplot()+\n  scale_fill_manual(values=custom_colors)+\n  theme(\n    axis.text.x=element_text(color=\"pink4\",size = 18),\n    axis.text.y=element_text(color=\"purple4\",size=9),\n    panel.background = element_rect(fill=\"magenta\")\n  )\n\n\n\n\n\n\n\nPlot 19\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(here)\nlibrary(ggplot2)\nlibrary(tidyquant)\nlibrary(cowplot)\nlibrary(dplyr)\n\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"BBBYQ\", \"GME\")\n\nprices &lt;- tq_get(tickers,\n                 from = \"2017-01-01\",\n                 to = \"2017-12-31\",\n                 get = \"stock.prices\")\n\nmeme_stocks &lt;- prices %&gt;%\n  group_by(symbol)\n\np2 &lt;- meme_stocks %&gt;%\n  ggplot(aes(x = date, y = adjusted, color = symbol)) +\n  geom_line(linewidth = 2) +\n  geom_point(shape=23, fill=\"blue\", color=\"yellow\", size=3) +\n  geom_smooth() +\n  geom_polygon() +\n  facet_grid(symbol ~ ., scales = \"free_y\") +\n  theme_cowplot(font_size = 20) +\n  labs(x = 'Date',\n       y = \"Adjusted Price\",\n       title = \"Before the Meme Stocks Era: Gamestop (GME) and Bed, Bath & Beyond (BBBYQ)\",\n       caption = \"Data Source from CodingFinance\") +\n  scale_x_date(date_breaks = \"month\",\n               date_labels = \"%b\\n%y\") +\n  theme(axis.text.x = element_text(face = \"bold\", color = \"#993333\", \n                           size = 12, angle = 45), plot.caption = element_text(color = \"red\", face = \"italic\", size = 15)) +\n  xlab(\"\\nDate\") + ylab(\"Adjusted Price\\n\")\n   #+\n  #geom_density(alpha = 0.5) #+\n  #transition_reveal(date, keep_last = TRUE) +\n  #view_follow(fixed_y=T)\n\nx &lt;- ggdraw() +\n  draw_image(\"https://i.kym-cdn.com/entries/icons/facebook/000/033/559/cover1.jpg\") +\n  draw_plot(p2) +\n  theme(rect = element_rect(fill = \"transparent\"))\nx\n\n\n\n\n\nPlot 20\n\n\nCode\nstorms1 &lt;- drop_na(storms)\nstorms2 &lt;- sample_n(storms1,100)\n\nstorms3 &lt;- ggplot(\n  storms2, \n  aes(\n    x = pressure,\n    y = wind,\n)\n) +\n  geom_point(\n    aes(\n       fill = pressure,\n      size = category\n      ),\n    alpha = 0.8,\n    shape = 25,\n    color = \"green\"\n  ) + coord_flip()+\n  theme_cowplot()+\n  labs(y =\"Wind speed\",\n       x =\" # Waffle Homes open\",\n       title = \"Is wafflehouse open?\")+\n  geom_jitter(\n    color = \"pink\",\n    shape = 17\n  )+ \n  theme(plot.background = element_rect(fill = \"magenta\")) +\n  theme(plot.title = element_text(color = \"orange\"))\n\nstorms3 + geom_line()\n\n\n\n\n\n\n\nPlot 21\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(cowplot)\n\npenguins_clean &lt;- drop_na(penguins)\n\npenguin_subset1 &lt;- penguins_clean |&gt;\n  sample_n(size = 40)\n\npenguin_subset2 &lt;- penguins_clean |&gt;\n  sample_n(size = 40)\n\npenguin_subset3 &lt;- penguins_clean |&gt;\n  sample_n(size = 40)\n\npenguin_subset4 &lt;- penguins_clean |&gt;\n  sample_n(size = 40)\n\nggplot(\n  penguins_clean,\n  aes(\n    x = body_mass_g,\n    y = species\n  )\n) +\n  geom_jitter(alpha=0.2)+\n  geom_jitter(\n    data = penguin_subset1,\n    color = \"black\",\n    aes(\n      show.legend = \"confused by the concept of weight\"\n    )\n  )+\n  geom_jitter(\n    data = penguin_subset2,\n    color = \"red\"\n  )+\n  geom_jitter(\n    data = penguin_subset3,\n    color = \"green\"\n  )+\n  geom_jitter(\n    data = penguin_subset4,\n    color = \"blue\"\n  )+\n    labs(\n      x = \"Fatness\",\n      y = \"\",\n      title = \"Name the Fattest Penguin\",\n      caption = \"be nice.\"\n    ) +\n  theme_bw()+\n  theme(\n    plot.caption = element_text(face = \"bold\", color = \"black\", size = 25),\n    plot.background = element_rect(fill = \"white\"),\n    legend.position = \"right\",\n    legend\n  )\n\n\n\n\n\nPlot 22\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(cowplot)\n\npenguins_clean &lt;- drop_na(penguins)\n\nggplot(\n  penguins_clean,\n  aes(\n    x = body_mass_g / 1000,\n    y = bill_length_mm)\n  )  +\n  geom_point(alpha = 1, shape = 21, colour = \"pink\", fill = \"orange\", size = 5, stroke = 5)"
  }
]