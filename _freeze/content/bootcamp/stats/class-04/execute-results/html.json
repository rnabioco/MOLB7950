{
  "hash": "7987435b14dbfa2d11a0413e5ca2b0b1",
  "result": {
    "markdown": "---\ntitle: 'Bootcamp: Stats class 4'\nauthor: \"[Neelanjan Mukherjee](neelanjan.mukherjee@cuanschutz.edu)\"\ndate: \"[Office Hours](https://calendly.com/molb7950)\"\noutput:\n  html_document: default\n  pdf_document: default\neditor_options: \n  chunk_output_type: console\n  markdown: \n    wrap: 72\n---\n\n\n\n\n------------------------------------------------------------------------\n\n# Learning Objectives\n\n-   **Visualize** and **Summarize** the data being compared\n-   **Formulate** and **Execute** null hypothesis testing\n-   **Identify** and **Perform** the proper statistical test for data\n    type/comparison\n-   **Calculate** and **Interpret** p-values\n-   **Prevent** p-hacking and **Recognize** issues with simultaneously\n    testing multiple hypotheses.\n\n------------------------------------------------------------------------\n\n# Outline\n\n-   Concepts and Definitions\n    -   Simplifying principles: Common tests as linear models\n    -   Types of comparisons and statistical tests\n    -   Definitions\\\n-   Day 1: Relationship between two or more continuous variables\n    -   Correlation vs Regression\n    -   Fitting it a line to data\n    -   Linear regression concepts\n    -   Multiple regression\\\n-   **Day 2: Relationship between categorical and continuous variables**\n    -   **Comparing means between two groups (t-Test)**\n\n    -   **Comparing means between 3 or more groups (ANOVA)\\\n        **\n-   Day 3: Multiple test correction, Bayesian intro, History\n\n------------------------------------------------------------------------\n\n## Provide a **simple** and **flexible** framework\n\n![](img/easy_hard.jpg)\n\n------------------------------------------------------------------------\n\n# CHEATSHEET\n\n![](img/linear_tests_cheat_sheet_adapted.png)\n\n------------------------------------------------------------------------\n\n## Variables definitions\n\n### Random variables (x, y)\n\n**Response Variable** ( **y** - aka dependent or outcome variable): this\nvariable is predicted or its variation is explained by the explanatory\nvariable. In an experiment, this is the outcome that is measured\nfollowing manipulation of the explanatory variable.\n\n**Explanatory Variable** ( **x** - aka independent or predictor\nvariable): explains variations in the response variable. In an\nexperiment, it is manipulated by the researcher.\n\n### Quantitative Variables\n\n**Discrete variable**: numeric variables that have a countable number of\nvalues between any two values - `integer` in R (e.g., number of mice,\nread counts).\n\n**Continuous variable**: numeric variables that have an infinite number\nof values between any two values - `numeric` in R (e.g., normalized\nexpression values, fluorescent intensity).\n\n### Categorical Variables\n\n**Nominal variable**: (unordered) random variables have categories where\norder doesn't matter - `factor` in R (e.g., country, type of gene,\ngenotype).\n\n**Ordinal variable**: (ordered) random variables have ordered\ncategories - order of `levels` in R ( e.g. grade of tumor).\n\n------------------------------------------------------------------------\n\n## Hypothesis testing definitions\n\n**Hypothesis testing** is a statistical analysis that uses sample data\nto assess two mutually exclusive theories about the properties of a\npopulation. Statisticians call these theories the null hypothesis and\nthe alternative hypothesis. A hypothesis test assesses your sample\nstatistic and factors in an estimate of the sample error to determine\nwhich hypothesis the data support.\n\nWhen you can reject the null hypothesis, the results are statistically\nsignificant, and your data support the theory that an effect exists at\nthe population level.\n\n[**A legal analogy: Guilty or not\nguilty?**](https://www.graphpad.com/guides/prism/latest/statistics/hypothesis_testing_and_statistical_significance.htm)**\\\n**The statistical concept of 'significant' vs. 'not significant' can be\nunderstood by comparing to the legal concept of 'guilty' vs. 'not\nguilty'.\n\nIn the American legal system (and much of the world) a criminal\ndefendant is presumed innocent until proven guilty. If the evidence\nproves the defendant guilty beyond a reasonable doubt, the verdict is\n'guilty'. Otherwise the verdict is 'not guilty'. In some countries, this\nverdict is 'not proven', which is a better description. A 'not guilty'\nverdict does not mean the judge or jury concluded that the defendant is\ninnocent \\-- it just means that the evidence was not strong enough to\npersuade the judge or jury that the defendant was guilty.\n\nIn statistical hypothesis testing, you start with the null hypothesis\n(usually that there is no difference between groups). If the evidence\nproduces a small enough P value, you reject that null hypothesis, and\nconclude that the difference is real. If the P value is higher than your\nthreshold (usually 0.05), you don't reject the null hypothesis. This\ndoesn't mean the evidence convinced you that the treatment had no\neffect, only that the evidence was not persuasive enough to convince you\nthat there is an effect.\n\n**Effect** --- the difference between the population value and the null\nhypothesis value. The effect is also known as population effect or the\ndifference. Typically, you do not know the size of the actual effect.\nHowever, you can use a hypothesis test to help you determine whether an\neffect exists and to estimate its size.\n\n**Null Hypothesis** or $\\mathcal{H}_0$ --- one of two mutually exclusive\ntheories about the properties of the population in hypothesis testing.\nTypically, the null hypothesis states that there is no effect (i.e., the\neffect size equals zero).\n\n**Alternative Hypothesis** or $\\mathcal{H}_1$ --- the other theory about\nthe properties of the population in hypothesis testing. Typically, the\nalternative hypothesis states that a population parameter does not equal\nthe null hypothesis value. In other words, there is a non-zero effect.\nIf your sample contains sufficient evidence, you can reject the null and\nfavor the alternative hypothesis.\n\n**P-values** --- the probability of obtaining test results at least as\nextreme as the results actually observed, under the assumption that the\nnull hypothesis is correct. Lower p-values represent stronger evidence\nagainst the null. P-values in conjunction with the significance level\ndetermines whether your data favor the null or alternative hypothesis.\n\n[StatQuest: P Values, clearly\nexplained](https://www.youtube.com/watch?v=5Z9OIYA8He8)\n\n[StatQuest: How to calculate\np-values](https://www.youtube.com/watch?v=JQc3yx0-Q9E)\n\n**Significance Level** or $a$ --- an evidentiary standard set before the\nstudy. It is the probability that you say there is an effect when there\nis no effect (the probability of rejecting the null hypothesis given\nthat it is true). Lower significance levels indicate that you require\nstronger evidence before you will reject the null.It is usually set at\nor below .05.\n\n![Guinness](https://upload.wikimedia.org/wikipedia/commons/3/35/Guinness_Glass_2010.jpg){width=\"10%\"}\n\n------------------------------------------------------------------------\n\n## Null hypothesis testing\n\n1.  Specify the variables\n2.  Declare null hypothesis $\\mathcal{H}_0$\n3.  Calculate test-statistic, exact p-value\n4.  *Generate and visualize data reflecting null-distribution*\n5.  *Calculate the p-value from the test statistic and null\n    distribution*\n\n\\*4-5: For calculating empirical p-value\n\n------------------------------------------------------------------------\n\n## The simplicity underlying common tests\n\nMost of the common statistical models (t-test, correlation, ANOVA;\nchi-square, etc.) are special cases of linear models or a very close\napproximation. This simplicity means that there is less to learn. In\nparticular, it all comes down to:\\\n$y = a \\cdot x + b$\n\nThis needless complexity multiplies when students try to rote learn the\nparametric assumptions underlying each test separately rather than\ndeducing them from the linear model.\n\n------------------------------------------------------------------------\n\n## Parametric vs Non-Parametric tests\n\n**Parametric tests** are suitable for normally distributed data.\n\n**Non-Parametric tests** are suitable for any continuous data. For the\nsake of simplicity and sticking with a consistent framework, we will\nconsider Non-Parametric tests as the **ranked versions of the\ncorresponding parametric tests**.\n\n[More on choosing Parametric vs\nNon-Parametric](https://statisticsbyjim.com/hypothesis-testing/nonparametric-parametric-tests/)\n\n\n::: {.cell}\n::: {.cell-output-display}\n|Info              |Parametric |Non-Parametric |\n|:-----------------|:----------|:--------------|\n|better descriptor |mean       |median         |\n|# of samples (N)  |many       |few            |\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Import and tidy data\n\nWe will be using mouse data from [Resources for Outbred\nMice](https://wp.cs.ucl.ac.uk/outbredmice/). The goal of the study was\nto establish genotype-phenotype relationships for highly recombinant\noutbred mouse populations. We will be using the phenotypic data for our\nexercises.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# we are reading the data directly from the internet\nbiochem <- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/Biochemistry.txt\", show_col_types = FALSE) %>%\n  janitor::clean_names()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00C4>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00D6>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00DC>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00E4>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00F6>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00FC>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00DF>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00C6>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00E6>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00D8>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00F8>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00C5>' to native encoding\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in FUN(X[[i]], ...): unable to translate '<U+00E5>' to native encoding\n```\n:::\n\n```{.r .cell-code}\n# simplify names a bit more\ncolnames(biochem) <- gsub(pattern = \"biochem_\", replacement = \"\", colnames(biochem))\n\n# we are going to simplify this a bit and only keep some columns\nkeep <- colnames(biochem)[c(1, 6, 9, 14, 15, 24:28)]\nbiochem <- biochem[, keep]\n\n# get weights for each individual mouse\n# careful: did not come with column names\nweight <- read_tsv(\"http://mtweb.cs.ucl.ac.uk/HSMICE/PHENOTYPES/weight\", col_names = F, show_col_types = FALSE)\n\n# add column names\ncolnames(weight) <- c(\"subject_name\", \"weight\")\n\n# add weight to biochem table and get rid of NAs\nbiochem <- inner_join(biochem, weight, by = \"subject_name\") %>%\n  na.omit()\n\n\n# explore the data a bit\n# colnames(biochem)\n# str(biochem)\n# View(biochem)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n# Review linear regression from yesterday\n\n## Equation for a line (Stats version)\n\nModel: the recipe for $y$ is a slope ($\\beta_1$) times $x$ plus an\nintercept ($\\beta_0$, aka a straight line).\n\n$y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x \\qquad \\mathcal{H}_0: \\beta_1 = 0 \\qquad y = \\beta_0 \\cdot 1$\n\n$y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x \\qquad \\mathcal{H}_0: \\beta_1 \\neq 0$\n\n## Find the best $\\beta$ coefficients\n\nThese $\\beta$ coefficients are also called the paramters of the model.\nThe $\\beta$ coefficients returned are for the lineear model that best\nfits the data.\n\n## Specify variables and hypothesis\n\nRemember: $y = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x$\n\nNull Hypothesis: $\\mathcal{H}_0: \\beta_1 = 0$\n\n$\\mathcal{H}_0:$ mouse $cholesterol$ does NOT explain $weight$\n\nAlternative Hypothesis: $\\mathcal{H}_1: \\beta_1 \\neq 0$\n\nSimple model: $y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x$\n\n$\\mathcal{H}_1:$ mouse $cholesterol$ does explain $weight$\n\n------------------------------------------------------------------------\n\n## Relationship between mouse weight and cholesterol\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting a line weight vs intercept (mean weight)\nfit_W <- lm(formula = weight ~ 1, data = biochem)\n\n# augment data to add fit/residuals\nbiochem_W <- augment(fit_W, data = biochem)\n\n# plot data\np_wch <- ggplot(data = biochem, aes(y = weight, x = tot_cholesterol)) +\n  geom_point(size = .5) +\n  geom_smooth(method = lm, col = \"red\") +\n  scale_color_manual() +\n  theme_minimal()\n\np_WvInt_res <- ggplot(data = biochem_W, aes(x = tot_cholesterol, y = weight)) +\n  geom_hline(yintercept = biochem_W$.fitted, col = \"red\", size = .5) + # plot linear model fit\n  geom_point(size = .5, aes(color = .resid)) + # plot height as points and color code by the value of the residual\n  scale_color_gradient2(low = \"blue\", mid = \"black\", high = \"yellow\") + # color code for plotting residuals\n  geom_segment(aes(xend = tot_cholesterol, yend = .fitted), alpha = .25) + # plot line representing residuals\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` instead.\n```\n:::\n\n```{.r .cell-code}\n# fitting a line weight vs icholesterol\nfit_WvC <- lm(\n  data = biochem,\n  formula = weight ~ 1 + tot_cholesterol\n)\n\n# augment data to add fit/residuals\nbiochem_WvC <- augment(fit_WvC, data = biochem)\n\n# plot data\np_WvC_res <- ggplot(data = biochem_WvC, aes(x = tot_cholesterol, y = weight)) +\n  geom_point(size = .5, aes(color = .resid)) +\n  geom_smooth(method = lm, col = \"red\") +\n  scale_color_gradient2(low = \"blue\", mid = \"black\", high = \"yellow\") + # color code\n  geom_segment(aes(xend = tot_cholesterol, yend = .fitted), alpha = .1) + # plot line representing residuals\n  theme_minimal()\n\n\n\nbiochem_WvC_rsq <- fit_WvC %>%\n  glance() %>%\n  pull(r.squared)\n\nbiochem_WvC_pval <- fit_WvC %>%\n  glance() %>%\n  pull(p.value)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_grid(p_WvInt_res, p_WvC_res, ncol = 2, labels = c(\"weight by intercept\", \"weight by cholesterol\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](class-04_files/figure-html/review plot-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### To what extent does mouse cholesterol predict mouse weight?\n\n$R^2$ or coefficient of determination --- the proportion of the variance\nin the dependent variable that is predictable from the independent\nvariable(s).\n\n13%\n\n### Probability that relationship is due to chance?\n\n$p-value$ --- the probability of obtaining an $F-statistic$ in the null\ndistribution at least as extreme as our observed $F-statistic$.\n\n8.9241551\\times 10^{-54}\n\n------------------------------------------------------------------------\n\n# Comparing means between two groups (Student's t-test)\n\nThe T-Distribution, also known as Student's t-distribution, gets its\nname from William Sealy Gosset who first published it in English in 1908\nin the scientific journal Biometrika using his pseudonym\n\"Student\"\\[9\\]\\[10\\] because his employer preferred staff to use pen\nnames when publishing scientific papers instead of their real name, so\nhe used the name \"Student\" to hide his identity.\\[11\\]\n\n[The Curious Tale of William Sealy\nGosset](https://medium.com/value-stream-design/the-curious-tale-of-william-sealy-gosset-b3178a9f6ac8)\n\n## Guinness Brewery in Dublin\n\n![](img/gosset.jpg){width=\"19%\"}\n![](img/inara_guinness.jpg){width=\"40%\"}\n\nWe will compare mouse $weight$ by $gender$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](class-04_files/figure-html/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Specify variables and hypothesis\n\nModel: $y_{i} = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x_{i}$\n\nNull Hypothesis: $\\mathcal{H}_0: \\beta_1 = 0$\n\n$\\mathcal{H}_0:$ mouse $gender$ does NOT explain $weight$\n\nAlternative Hypothesis: $\\mathcal{H}_1: \\beta_1 \\neq 0$\n\n$\\mathcal{H}_1:$ mouse $gender$ does explain $weight$\n\n**Important:** $x_{i}$ is an indicator (0 or 1) saying whether data\npoint i was sampled from one or the other group (female or male).\n\nWe will explore this in more detail soon.\n\n------------------------------------------------------------------------\n\n## 1. Calculate $SS_{mean}$ for weight by gender (female vs male)\n\n### Compare $SS_{mean}$ for weight by cholesterol *versus* weight by gender\n\n\n::: {.cell}\n\n:::\n\n\n$SS_{mean}$ --- sum of squares around the overall mean of $y$\n\n$SS_{mean} = \\sum_{i=1}^{n} (data - mean)^2$\n\n$SS_{mean} = \\sum_{i=1}^{n} (y_{i} - \\overline{y})^2$\n\n</br>\n\n**Residuals**, $e$ --- the difference between the observed value of the\ndependent variable $y$ and the predicted value $\\widehat{y}$ is called\nthe residual. Each data point has one residual.\n\n$e = y_{i} - \\widehat{y}$\n\n### **Class exercise 1**:\n\nWhich of these are valid ways to calculate $SS_{mean}$ from `biochem_W`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A. sum((biochem_W$weight - biochem_W$.fitted)^2)\n# B. sum((biochem_W$weight - biochem_W$.resid)^2)\n# C. sum(biochem_W$.resid^2)\n# D. sum((biochem_W$weight - mean(biochem_W$weight))^2)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## 2. Calculate $SS_{fit}$ for weight by gender\n\n### Compare $SS_{fit}$ vs $SS_{fit}$ weight by gender\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting a line weight vs intercept + gender\nfit_WvG <- lm(formula = weight ~ 1 + gender, data = biochem)\n\n# augment (i.e. add fitted and residual values)\nbiochem_WvG <- augment(fit_WvG, data = biochem)\n\n# plot of data with mean and colored by residuals\np_WvG_res <- ggplot(biochem_WvG, aes(x = gender, y = weight)) +\n  geom_point(position = position_jitter(), aes(color = .resid)) +\n  scale_color_gradient2(low = \"blue\", mid = \"black\", high = \"yellow\") + # color code for plotting residuals\n  geom_segment(aes(x = .5, xend = 1.5, y = fit_WvG$coefficients[1], yend = fit_WvG$coefficients[1]), color = \"red\") +\n  geom_segment(aes(x = 1.5, xend = 2.5, y = sum(fit_WvG$coefficients)), yend = sum(fit_WvG$coefficients), color = \"red\") +\n  theme_minimal()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](class-04_files/figure-html/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n### NOTE: We are fitting 2 lines to the data\n\nFor the weight by intercept model (right) we fit **1** line.\\\nFor the weight by gender model (left) we fit **2** lines (i.e. male and\nfemale).\n\n### Exceptions to the fit\n\nCheck the residuals!\n\n\n::: {.cell}\n\n:::\n\n\n### *Matrices Interlude Begin*\n\n#### How do we go from **2 fit lines** to **1 equation**\n\nSince we don't want to calculate any of this by hand, the framework\nneeds to be flexible such that a computer can execute for different\nflavors of comparison (cont y vs cont x, cont y vs 2 or more categorical\nx, ...).\n\nLet's break this down and focus on just a few players.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_exc\n```\n\n::: {.cell-output-display}\n![](class-04_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n\n```{.r .cell-code}\n# ggplot(data = biochem_WvG, aes(.resid, color=gender)) +\n#   geom_density() +\n#   theme_minimal()\n```\n:::\n\n\nRemember that:\\\n$weight$ is $y$\\\n$F_{avg}$ is the average $weight$ of $females$\\\n$M_{avg}$ is the average $weight$ of $males$\n\n------------------------------------------------------------------------\n\nA0480548**85**, female\\\n$y_{85}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{85}$\n\nA0671097**71**, female\\\n$y_{71}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{71}$\n\n------------------------------------------------------------------------\n\nA0668223**51**, male\\\n$y_{51}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{51}$\n\nA0482743**62**, male\\\n$y_{62}= 0 \\cdot F_{avg} + 1 \\cdot M_{avg} + residual_{62}$\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-3cd3dcc6bf4566a18662\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3cd3dcc6bf4566a18662\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\"],[\"A048054885\",\"A067109771\",\"A048274362\",\"A066822351\"],[24,25.5,13.4,13.2],[\"F\",\"F\",\"M\",\"M\"],[18.07586980920318,18.07586980920318,22.40594837261504,22.40594837261504],[5.924130190796816,7.424130190796816,-9.005948372615043,-9.205948372615044]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>subject_name<\\/th>\\n      <th>weight<\\/th>\\n      <th>gender<\\/th>\\n      <th>.fitted<\\/th>\\n      <th>.resid<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,4,5]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Need a volunteer\n\n**Me:** Ooohh my, imagine how tedious it would be to do this for all\n1782 mice...\\\n**Volunteer:** Wait a sec...isn't there a way to formulate this as a\nmatrix algebra problem.\\\n**Me:** You're right - I'm so glad you asked! Let's wield our\nmatrix-magic at this problem and see what happens.\n\n$f_{avg} = \\beta_0$ is the average $weight$ of $female$ mice\\\n$m_{avg} = \\beta_1$ is the average $weight$ of $male$ mice\n\n$\\begin{bmatrix} y_{85} \\\\ y_{71} \\\\ y_{51} \\\\y_{62} \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ 0 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} e_{85} \\\\ e_{71} \\\\ e_{51} \\\\e_{62} \\end{bmatrix}$\n\n**So basically this looks like the same equation for fitting a line\nwe've been discussing, just w/a few more dimensions :)**\n\nThis is a conceptual peak into the underbelly of how the $\\beta$\ncofficients and least squares is performed using matrix operations\n(remember linear algebra, maybe?). We will not go any deeper in this\ncourse, but if you are interested in learning more I recommend the\nfollowing resources:\\\n\n[Linear Models Pt.3 - Design\nMatrices](https://www.youtube.com/watch?v=CqLGvwi-5Pc&list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU&index=6)\\\n\n[A Matrix Formulation of the Multiple Regression\nModel](https://online.stat.psu.edu/stat462/node/132/)\n\n### *Matrices Interlude FIN*\n\n### **Class exercise 2**:\n\nWhich of these are valid ways to calculate $SS_{mean}$ from `biochem_W`?\n\n$SS_{fit}$ --- sum of squares around the least-squares fit\n\n$SS_{fit} = \\sum_{i=1}^{n} (data - line)^2$\n\nWhich of these are valid ways to calculate $SS_{fit}$ from\n`biochem_WvG`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A. sum(biochem_WvG$.resid^2)\n# B. sum((biochem_WvG$weight - biochem_WvG$.resid)^2)\n# C. sum((biochem_WvG$weight - biochem_WvG$.fitted)^2)\n# D. sum((biochem_WvG$weight - mean(biochem_WvG$weight))^2)\n\np_WvG_res\n```\n\n::: {.cell-output-display}\n![](class-04_files/figure-html/exercise 2-1.png){width=672}\n:::\n:::\n\n\n## 3. Calculate $F-statistic$\n\n**F-statistic** --- the proportion of the variance in the dependent\nvariable that is predictable from the independent variable(s).\n\n$F = \\displaystyle \\frac{SS_{fit}/(p_{fit}-p_{mean})} {SS_{mean}/(n-p_{fit})}$\n\n$p_{fit}$ --- number of parameters in the fit line\\\n$p_{mean}$ --- number of parameters in the mean line\\\n$n$ --- number of data points\n\n## 4. Sanity check\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sum of squares of the residuals for the simple model\nss.mean <- sum(biochem_W$.resid^2)\n\n# sum of squares of the residuals for the complex model\nss.fit <- sum(biochem_WvG$.resid^2)\n\n#### COEFFICIENTS NEEL\n\n# number of paramters in simple model\npmean <- 1\n\n# number of paramters in complex model\npfit <- 2\n\n# F-value\nbiochem_WvG_F <- ((ss.mean - ss.fit) / (pfit - 1)) /\n  (ss.fit / (nrow(biochem_WvG) - pfit))\n\nbiochem_WvG_F\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1296.507\n```\n:::\n\n```{.r .cell-code}\nglance(fit_WvG) %>% pull(statistic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   value \n1296.507 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nLet's take a look at the statistic and p-values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_WvG_stats <- tidy(fit_WvG) %>%\n  filter(term == \"genderM\") %>%\n  select(statistic, p.value)\n\n\n# to run a t.test in R we need numeric vectors for each of our groups of interest\nmale_weight_t <- biochem_WvG %>%\n  filter(gender == \"M\") %>%\n  pull(weight)\n\nfemale_weight_t <- biochem_WvG %>%\n  filter(gender == \"F\") %>%\n  pull(weight)\n\n\ntrad_t <- t.test(male_weight_t, female_weight_t, var.equal = T)\n\ntrad_WvG_stats <- tidy(trad_t) %>% select(statistic, p.value)\n\nfit_WvG_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 2\n  statistic   p.value\n      <dbl>     <dbl>\n1      36.0 9.25e-214\n```\n:::\n\n```{.r .cell-code}\ntrad_WvG_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 2\n  statistic   p.value\n      <dbl>     <dbl>\n1      36.0 9.25e-214\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Comparing means of 3 or more?\n\n## One-way ANOVA\n\nLet's compare the $weight$ by $family$, but only for a few selected\nfamilies.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# biochem %>%\n#   group_by(family) %>%\n#   count(family) %>%\n#   arrage(-n) %>%\n#   View()\n\nbigfams <- biochem %>%\n  group_by(family) %>%\n  count(family) %>%\n  filter(n > 10) %>%\n  pull(family)\n\nbiochem_bigfams <- biochem %>%\n  filter(family %in% bigfams)\n\n# i have pre-selected some families to compare\nmyfams <- c(\n  \"B1.5:E1.4(4) B1.5:A1.4(5)\",\n  \"F1.3:A1.2(3) F1.3:E2.2(3)\",\n  \"A1.3:D1.2(3) A1.3:H1.2(3)\",\n  \"D5.4:G2.3(4) D5.4:C4.3(4)\"\n)\n\n# only keep the familys in myfams\nfam_data <- biochem_bigfams %>%\n  filter(family %in% myfams) %>%\n  droplevels()\n\n# simplify family names and make factor\nfam_data$family <- gsub(\n  pattern = \"\\\\..*\",\n  replacement = \"\",\n  x = fam_data$family\n) %>%\n  as.factor()\n\n\n# make B1 the reference (most similar to overall mean)\nfam_data$family <- relevel(x = fam_data$family, ref = \"B1\")\n```\n:::\n\n\nModel: $y_{i} = \\beta_0 \\cdot 1+ \\beta_1 \\cdot x_{i}$\n\nNull Hypothesis: $\\mathcal{H}_0: \\beta_1 = 0$\n\n$\\mathcal{H}_0:$ mouse $family$ does NOT explain $weight$\n\nAlternative Hypothesis: $\\mathcal{H}_1: \\beta_1 \\neq 0$\n\n$\\mathcal{H}_1:$ mouse $family$ does explain $weight$\n\n**Important:** $x_{i}$ is an indicator (0 or 1) saying which group point\n$i$ was sampled from using the matrix encoding of 0s and 1s.\n\nBelow is an example depicting 6 observations with 2 from each of 3\nfamilies:\n\n$\\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ y_{3} \\\\y_{4} \\\\y_{5} \\\\y_{5} \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 1 \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix} + \\begin{bmatrix} e_{1} \\\\ e_{2} \\\\ e_{3} \\\\e_{4} \\\\e_{5} \\\\e_{6} \\end{bmatrix}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fitting a line weight vs intercept + family\nfit_WvFam <- lm(formula = weight ~ family, data = fam_data)\n\n\n# augment (i.e. add fitted and residual values)\nbiochem_WvFam <- augment(fit_WvFam, fam_data)\n\nmean_B1 <- fit_WvFam$coefficients[1]\nmean_A1 <- fit_WvFam$coefficients[1] + fit_WvFam$coefficients[2]\nmean_D5 <- fit_WvFam$coefficients[1] + fit_WvFam$coefficients[3]\nmean_F1 <- fit_WvFam$coefficients[1] + fit_WvFam$coefficients[4]\n\n# plot of data with mean and colored by residuals\np_WvFam_res <- ggplot(biochem_WvFam, aes(x = family, y = weight)) +\n  geom_point(position = position_jitter(), aes(color = .resid)) +\n  geom_segment(aes(x = .5, xend = 1.5, y = mean_B1, yend = mean_B1), color = \"red\") +\n  geom_segment(aes(x = 1.5, xend = 2.5, y = mean_A1, yend = mean_A1), color = \"red\") +\n  geom_segment(aes(x = 2.5, xend = 3.5, y = mean_D5, yend = mean_D5), color = \"red\") +\n  geom_segment(aes(x = 3.5, xend = 4.5, y = mean_F1, yend = mean_F1), color = \"red\") +\n  geom_segment(aes(x = .5, xend = 4.5, y = mean(weight), yend = mean(weight)), color = \"black\") +\n  scale_color_gradient2(low = \"blue\", mid = \"black\", high = \"yellow\") + # color code for plotting residuals\n  theme_minimal()\n\np_WvFam_res\n```\n\n::: {.cell-output-display}\n![](class-04_files/figure-html/fit weight to families-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_WvFam <- aov(formula = weight ~ family, data = fam_data)\n\n# are the coefficients the same?\nbind_cols(tidy(fit_WvFam) %>% select(term, estimate),\n  ANOVA_coef = anova_WvFam$coefficients\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 3\n  term        estimate ANOVA_coef\n  <chr>          <dbl>      <dbl>\n1 (Intercept)   18.1       18.1  \n2 familyA1      -3.66      -3.66 \n3 familyD5       5.86       5.86 \n4 familyF1      -0.682     -0.682\n```\n:::\n\n```{.r .cell-code}\nglance(fit_WvFam) %>% select(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n   p.value\n     <dbl>\n1 7.62e-13\n```\n:::\n\n```{.r .cell-code}\ntidy(anova_WvFam) %>% select(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 1\n    p.value\n      <dbl>\n1  7.62e-13\n2 NA       \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### **Class exercise 3**:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](class-04_files/figure-html/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\nWhat are the $p_{mean}$ and $p_{fit}$ for the models above?\n\n\n::: {.cell}\n::: {.cell-output-display}\n|Parameter  |fit cholesterol |fit gender |fit family |\n|:----------|:---------------|:----------|:----------|\n|$p_{mean}$ |?               |?          |?          |\n|$p_{fit}$  |?               |?          |?          |\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Comparing 2 continuouse variables for 2 groups?\n\n## ANCOVA, Analysis of Covariance\n\nANOVA with more than one independent variable. In this case, what is the\nimpact of mouse age on mouse weight for males vs females.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# more info here https://towardsdatascience.com/doing-and-reporting-your-first-anova-and-ancova-in-r-1d820940f2ef\n\np_WvA_gender <- ggplot(data = biochem, aes(y = weight, x = age, color = gender)) +\n  geom_point(size = .5) +\n  geom_smooth(method = lm) +\n  theme_minimal()\n\np_WvA_gender\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](class-04_files/figure-html/ANCOVA-1.png){width=672}\n:::\n\n```{.r .cell-code}\nWvA_gender <- lm(formula = weight ~ 1 + age + gender, data = biochem)\n\nWvA_gender %>% glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.475         0.475  2.42      805. 8.37e-250     2 -4100. 8209. 8231.\n# i 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n\n```{.r .cell-code}\naov(formula = weight ~ 1 + age + gender, data = biochem) %>% glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 6\n  logLik   AIC   BIC deviance  nobs r.squared\n   <dbl> <dbl> <dbl>    <dbl> <int>     <dbl>\n1 -4100. 8209. 8231.   10402.  1782     0.475\n```\n:::\n:::\n\n\n# References and resources\n\nI have borrowed heavily from, directly taken, and/or highly recommend\nthe following fantastic resources:\n\n1.  [Common statistical tests are linear\n    models](https://lindeloev.github.io/tests-as-linear/) from Jonas\n    Kristoffer Lindel<c3><b8>v\\\n2.  [Statquest](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw)\n3.  [Stats\n    gobbledygook](https://www.rapidtables.com/math/symbols/Statistical_Symbols.html)\n4.  [Linear Regression Assumptions and Diagnostics in R:\n    Essentials](http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/)\\\n5.  [PRINCIPLES OF\n    STATISTICS](https://www.graphpad.com/guides/prism/latest/statistics/stat_---_principles_of_statistics_-.htm)\n    from GraphPad/SAS.\n",
    "supporting": [
      "class-04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/htmlwidgets-1.6.2/htmlwidgets.js\"></script>\n<link href=\"../../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/datatables-binding-0.28/datatables.js\"></script>\n<script src=\"../../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../../../site_libs/dt-core-1.13.4/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../../../site_libs/dt-core-1.13.4/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/dt-core-1.13.4/js/jquery.dataTables.min.js\"></script>\n<link href=\"../../../site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}