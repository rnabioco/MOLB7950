{
  "hash": "5566fc8af8ea505a2a192e6f2df4bee0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Single cell RNA-Seq:\"\nsubtitle: \"Clustering, Dimensionality reduction, and cell-type annotation\"\nauthor: \"Kent Riemondy and Kristen Wells\"\n---\n\n\n\n\n\n\n## Contact Info \n\nGreetings experimentalist humans üëã\n\n<i class=\"fa fa-envelope\"></i> &nbsp; [kristen.wells-wrasman@cuanschutz.edu](mailto:kristen.wells-wrasman@cuanschutz.edu) <br>\n\nRBI Informatics Fellows [Office hours](https://medschool.cuanschutz.edu/rbi/training-and-education/rbi-office-hours)\n\n<i class=\"fa fa-envelope\"></i> &nbsp; [rbi.fellows@cuanschutz.edu](mailto:rbi.fellows@cuanschutz.edu) \n<br>\n\n\n## Learning Objectives\n\n:::: {.columns}\n\n::: {.column .nonincremental}\n### Lecture 1\n- Identify key quality control issues with single cell RNA-seq data and perform filtering onto exclude poor quality cells \n- Interact with single cell data using Bioconductor \n\n::: \n \n::: {.column .nonincremental}\n### Lecture 2 \n- Perform analysis to identify cell types in single cell data by using unsupervised clustering methods and comparing to public datasets\n- Describe the importance and reasoning for conducting each step of the analysis\n\n::: \n\n::::\n\n\n## Learning key\n* We will switch between lecture and your exercise `qmd`. \n* To denote a slide that corresponds to your exercise, I will include ‚å®Ô∏è in the slide title\n\n## Analysis steps revisited {.smaller}\n\n:::: {.columns}\n\n::: {.column width=\"50%}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"grViz html-widget html-fill-item\" id=\"htmlwidget-e512a57021c932f37d72\" style=\"width:70%;height:70%;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-e512a57021c932f37d72\">{\"x\":{\"diagram\":\"\\ndigraph workflow {\\n  graph [layout = dot,\\n         rankdir = TD]\\n\\n  node [shape = cicle,\\n        style = filled,\\n        fontcolor = black,\\n        fontname = \\\"Helvetica\\\"]\\n\\n  # green\\n  node [fillcolor = \\\"#009E73\\\"]\\n  load [label= \\\"Import data\\ntximport::tximport()\\nSingleCellExperiment()\\ncounts()\\\"]\\n\\n  # blue\\n  node [fillcolor = \\\"#56B4E9\\\"]\\n  cell_qc [label = \\\"QC cells\\n addPerCellQCMetrics()\\n plotColData()\\\"]\\n  norm [label = \\\"Normalize UMI counts\\nquickCluster()\\n computeSumFactors()\\n logNormCounts()\\\"]\\n\\n  # yellow\\n  node [fillcolor = \\\"#F0E442\\\"]\\n  feature [label = \\\"Identify variable genes\\nmodelGeneVarByPoisson()\\n getTopHVGs()\\\"]\\n  dim_red [label = \\\"Dimensionality reduction via PCA \\n runPCA()\\\"]\\n  cluster [label = \\\"Clustering\\n clusterCells()\\\"]\\n  viz [label = \\\"Make 2D-Visualization\\nrunUMAP()\\\"]\\n\\n  # blue\\n  node [fillcolor = \\\"#56B4E9\\\"]\\n\\n  markers [label = \\\"Discover cell type markers \\nscoreMarkers()\\\"]\\n  annot [label = \\\"Annotate cell types\\nclustifyr and SingleR\\\"]\\n\\n  edge [color = black\\n        fontname = \\\"Helvetica\\\"]\\n\\n  load -> cell_qc\\n  cell_qc -> norm\\n  norm -> feature\\n  norm -> markers\\n  feature -> dim_red\\n  dim_red -> cluster\\n  dim_red -> viz\\n  cluster -> markers\\n  markers -> annot\\n\\n  edge [color = \\\"grey\\\"\\n        style = \\\"dashed\\\"]\\n  annot -> cell_qc [label = \\\"Repeat\\n as needed\\\"]\\n  annot -> feature\\n  annot -> dim_red\\n  annot -> cluster\\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n::: \n\n::: {.column width=\"50%}\n\n- Normalize and log transform UMI counts to correct for sequencing depth. \n\n- Select genes with high variance to use for clustering and UMAP generation\n\n- Use PCA to reduce the size of the dataset to ~20-50 dimensions\n\n- Use UMAP or tSNE to further reduce the PCA matrix into 2D for visualization\n\n- Use clustering on PCA matrix to identify clusters of related cells.\n\n- Find marker genes that are specifically expressed in each cluster. \n\n- Compare the gene expression profile of each cluster to public data to help annotate the cell type.\n\n:::\n\n::::\n\n\n# TL;DR ‚å®Ô∏è\n\n```r\n# normalize data\nclusters <- quickCluster(sce)\nsce <- computeSumFactors(sce, clusters=clusters)\nsce <- logNormCounts(sce)\n\n# get variable genes\ndec <- modelGeneVarByPoisson(sce)\ntop <- getTopHVGs(dec, prop=0.1)\n\n# get PCA and UMAP\nsce <- runPCA(sce, subset_row = top)\nsce <- runUMAP(sce, dimred = \"PCA\")\n\n# cluster cells\nsce$clusters <- clusterCells(sce, use.dimred = \"PCA\")\n\n# get marker genes\nmrks <- scoreMarkers(sce, sce$clusters)\n\n...\n```\n\n## Rerun steps from previous class ‚å®Ô∏è\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load data\nlibrary(tximport)\ntx <- tximport(\n  here(\"data/block-rna/scrna/pbmc/alevin/quants_mat.gz\"),\n  type = \"alevin\"\n)\n\n# setup gene ids\nsce <- SingleCellExperiment(list(counts = tx$counts))\nah <- AnnotationHub()\nens_db <- ah[[\"AH113665\"]]\n\ngene_names <- mapIds(ens_db,\n  keys = rownames(sce),\n  keytype = \"GENEID\",\n  column = \"SYMBOL\"\n)\n\nrowData(sce)$gene <- gene_names\nrowData(sce)$gene_id <- rownames(sce)\nrownames(sce) <- uniquifyFeatureNames(\n  rowData(sce)$gene_id,\n  rowData(sce)$gene\n)\n\n# drop non/low expressed genes\nrowData(sce)$n_cells <- rowSums(counts(sce) > 0)\nsce <- sce[rowData(sce)$n_cells >= 10, ]\n\n# basic QC\nis_mito <- startsWith(rowData(sce)$gene, \"MT-\")\nsce <- addPerCellQCMetrics(sce, subsets = list(Mito = is_mito))\nsce$pass_qc <- sce$subsets_Mito_percent < 20 & sce$sum > 1000 & sce$detected > 500\nsce <- sce[, sce$pass_qc]\n```\n:::\n\n\n\n\n## Normalization refresher ‚å®Ô∏è  {.smaller}\n\n`quickCluster()`: Crude clustering to group related cells into groups with similar expression profiles\n\n`computeSumFactors()`: Pool counts across clusters to establish an average cell profile for each cluster. Then use deconvolution to estimate a cell-specific scaling factor for\nnormalization\n\n`logNormCounts()`: Apply scaling factors (size factors) to counts and log transform\nwith a pseudocount.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20231023)\nclusters <- quickCluster(sce)\nsce <- computeSumFactors(sce, clusters = clusters)\nsce <- logNormCounts(sce)\n\nlogcounts(sce)[50:60, 1:4]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n11 x 4 sparse Matrix of class \"dgCMatrix\"\n           GCTGCAGTCCGATCTC ACTATGGAGGTCCCTG ATTTCTGTCTCTATGT TATCTGTAGGTGATAT\nCPTP              .                0.2645668        .                .        \nTAS1R3            .                .                .                .        \nDVL1              .                0.2645668        .                .        \nMXRA8             .                .                .                .        \nAURKAIP1          0.3500082        1.9327619        0.2923841        0.7922116\nCCNL2             0.6314635        .                0.7432885        0.5731981\nMRPL20-AS1        0.3500082        0.2645668        0.2923841        .        \nMRPL20            0.8668712        1.1425125        0.9249737        0.7922116\nRN7SL657P         .                .                .                .        \nMRPL20-DT         .                .                .                0.3148810\nATAD3C            .                .                .                .        \n```\n\n\n:::\n:::\n\n\n\n\n## Variable gene selection {.smaller}\n\n- Genes that have high variance across cells are genes that tend to be differentially expressed between cell types\n\n- Low variance genes are usually low-expressed or \"house-keeping\" genes whose expression will not help us distinguish between cell populations\n\n- Including these genes could potentially introduce more technical variation rather then helpful biological variation. \n\n- Keeping uninteresting genes will increase the computational burden and likely either not improve or be deleterious to the clustering. \n\n## Variable gene selection ‚å®Ô∏è {.smaller}\n\n`modelGeneVarByPoisson()`: Fit curve, using Poisson distribution, to variance against the mean expression distribution. Estimate technical (Poisson estimate) and biological (the residuals from the Poisson) variance for each gene.\n\n`getTopHVGs()`: Filter output from `modelGeneVarByPoisson` to select top variable genes. Use `prop` to identify the proportion of genes to call highly variable or `n` to identify a number. Often starting between 1000-2000 is best.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Variable gene selection ‚å®Ô∏è {.smaller}\n\n`modelGeneVarByPoisson()`: Fit curve, using Poisson distribution, to variance against the mean expression distribution. Estimate technical (Poisson estimate) and biological (the residuals from the Poisson) variance for each gene.\n\n`getTopHVGs()`: Filter output from `modelGeneVarByPoisson` to select top variable genes. Use `prop` to identify the proportion of genes to call highly variable or `n` to identify a number. Often starting between 1000-2000 is best.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(00010101)\ndec <- modelGeneVarByPoisson(sce)\ntop <- getTopHVGs(dec, prop = 0.1)\ntop[1:4]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"LYZ\"     \"S100A9\"  \"S100A8\"  \"HLA-DRA\"\n```\n\n\n:::\n:::\n\n\n\n## Variable gene selection ‚å®Ô∏è  {.smaller}\nWe can plot mean expression against variance to see the trend and visualize the top variable genes. These are often marker genes of specific cell populations.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_genes <- as.data.frame(dec[top[1:10], ])\ntop_genes$genes <- rownames(top_genes)\n\nggplot(as.data.frame(dec), aes(mean, total)) +\n  geom_point() +\n  geom_text(\n    data = top_genes,\n    aes(label = genes)\n  ) +\n  stat_function(\n    fun = function(x) metadata(dec)$trend(x),\n    linetype = \"dashed\",\n    colour = \"blue\"\n  )\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-5-1.png){width=864}\n:::\n:::\n\n\n\n## Variable gene selection {.smaller}\n\n```r\ndec <- modelGeneVarByPoisson(sce)\ntop <- getTopHVGs(dec, prop = 0.1)\n```\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndec_df <- as.data.frame(dec)\ndec_df$genes <- rownames(dec_df)\ndec_df$variable_gene <- dec_df$genes %in% top\n\nggplot(dec_df, aes(mean, total)) +\n  geom_point(aes(color = variable_gene),\n    size = 0.75\n  ) +\n  stat_function(\n    fun = function(x) metadata(dec)$trend(x),\n    linetype = \"dashed\",\n    colour = \"blue\"\n  )\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-6-1.png){width=864}\n:::\n:::\n\n\n\n\n## Dimensionality reduction {.smaller}\n\n\nDimensionality reduction is the concept of transforming high dimensional data and representing it with a smaller set of dimensions.\n\nWe can reduce the # of dimensions without loosing much information because many features (genes) are highly correlated which can be approximated with fewer dimensions. \n\nThis is analogous to reducing the gene expression data into a set of metagenes that represents the expression of many correlated genes.\n\nUsing fewer dimensions makes computation much quicker and as we will see will reorder the data in a manner that still captures the heterogeneity in the data.\n\n## Dimensionality reduction via PCA {.smaller}\n\nWe will use PCA to reduce the dimensionality of the data from 20,000 genes to ~10-50 principle components.\n\n[PCA](http://setosa.io/ev/principal-component-analysis/) takes a matrix of features (genes) and samples (cells) and transforms the matrix into a new set of features known as a principal components. A principal component is a linear combination of the original genes that is oriented to capture variance in the dataset. \n\n`PC1` is a vector through the dataset oriented in a direction that spans the most variation in the data.  The second component is another linear combination of the original variables but is uncorrelated to the first component (points in an orthogonal direction).\n\nIn a geometric sense, PCA produces a new coordinate system whereby instead of the axes being each gene, the axes are each a PC and the first axis points through the largest spread in the data. \n\n## PCA in 2 dimensions {.smaller}\n\nIn this two dimensional space, PCA minimizes the distances from a line and every point in the x and y direction (think of a regression line). For a great walk through of how PCA works, see [section 7.3 in Modern Statistics for Modern Biology](https://web.stanford.edu/class/bios221/book/07-chap.html#dimension-reduction)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/pca-intro-1.png){width=960}\n:::\n:::\n\n\n\n## PCA with more dimensions {.smaller}\n* If we add more dimensions, we now need to fit this line in a much higher dimensional space while still minimizing the distance of each point from the line.\n* We end up with the same number of PCs as the number of our initial dimensions\n  * In our 2-D example, we get two PCs\n  * Adding more genes increases the number of PCs.\n\nWhat if we had more dimensions that are uninteresting variance/noise? How does this impact the PCA? \n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n     gene_1    gene_2 gene_noise_1 gene_noise_2 gene_noise_3\n1 -2.995217 -2.123704  0.089215287  -0.40819808  -0.48037882\n2 -2.821900 -2.933205 -0.339377410  -0.03582506   0.41886793\n3 -2.278693 -2.375272  0.131539067  -0.42624492   0.28643147\n4 -2.167279 -2.535480  0.098178061  -0.20509451  -0.06692551\n5 -1.528019 -1.310610  0.007170167   0.04159706   0.03533156\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n## PCA as dimensional reduction {.smaller}\n* PC 1 and PC 2 capture less of the total variance (from capturing 100% of the variance to capturing about 80% of the variance)\n* Additionally, the points are spread more and differently because the distance had to be minimized in a higher dimensional space\n* However adding random noise does not dramatically change PC1 and PC2\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n\n## computing PCA with scater ‚å®Ô∏è {.smaller}\n\n`runPCA()`: computes an approximate truncated PCA, returning 50 PCs by default. \n\n`reducedDim(sce, \"PCA\")`: function to access or assign reduced dimensionality results\n\n`plotPCA()`: plot 2 or more PC components\n\n`plotReducedDim()`: plot 2 or more dimensions or arbitrary `reducedDim()` matrix \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(101010011) # runPCA uses a specialize form of PCA that has a random component\nsce <- runPCA(sce, subset_row = top)\nplotPCA(sce, color_by = \"CD3D\")\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-10-1.png){width=864}\n:::\n:::\n\n\n\n## computing PCA with scater ‚å®Ô∏è {.smaller}\n\n`runPCA()`: computes an approximate truncated PCA, returning 50 PCs by default. \n\n`reducedDim(sce, \"PCA\")`: function to access or assign reduced dimensionality results\n\n`plotPCA()`: plot 2 or more PC components\n\n`plotReducedDim()`: plot 2 or more dimensions or arbitrary `reducedDim()` matrix \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotPCA(sce, ncomponents = 4, colour_by = \"CD3D\")\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-11-1.png){width=864}\n:::\n:::\n\n\n\n## How many PCs to retain? ‚å®Ô∏è {.smaller}\n* In general the # of PCs to use for downstream steps depends on the complexity and heterogeneity in the data, as well as the biological question. For this analysis we will retain the top 30, but you should explore how the downstream steps are affected by including fewer or more PCs.  \n\n* In practice picking fewer PCs will identify fewer subpopulations, and picking more PCs will find more subpopulations, at the expense of potentially increased noise and longer runtime.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npercent.var <- attr(reducedDim(sce), \"percentVar\")\nplot(percent.var, log = \"y\", xlab = \"PC\", ylab = \"Variance explained (%)\", pch = 16)\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-12-1.png){width=864}\n:::\n:::\n\n\n\n## How is PCA data stored? ‚å®Ô∏è \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreducedDim(sce, \"PCA\")[1:4, 1:4] # the PCA is stored in the reducedDim() slot\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                         PC1       PC2       PC3        PC4\nGCTGCAGTCCGATCTC -17.7865879 -5.494428 -3.609731 -2.2119402\nACTATGGAGGTCCCTG  -0.0933944  7.195291  2.840164  0.0138008\nATTTCTGTCTCTATGT -17.8824692 -1.533912 -3.546737  0.5637093\nTATCTGTAGGTGATAT -16.7533963 -2.843034 -5.289824 -1.3747961\n```\n\n\n:::\n\n```{.r .cell-code}\n# we can subset the PCA to fewer dimensions, e.g. 30\nreducedDim(sce, \"PCA\") <- reducedDim(sce, \"PCA\")[, 1:30]\n```\n:::\n\n\n\n## Which dimensional reduction to use {.smaller}\n:::: {.columns}\n\n::: {.column}\n\n### PCA\n* Used by early studies (and bulk methods)\n* In bulk studies, we expect to have a large amount of variation captured by PC1 (>50%)\n* Best for small and simple data sets \n* In large single cell studies lots of information is present at the higher principal components\n\n:::\n\n::: {.column}\n\n### UMAP\n* Popular in current single cell studies\n* Does a good job of preserving local differences between cells while balancing global differences\n\n:::\n\n::::\n\n## Projecting PCs into 2 dimensions (UMAP, tSNE, etc.) ‚å®Ô∏è  {.smaller}\n\n\nNon-linear dimensionallty reductions are commonly used to project the PCA matrix into 2 dimensions for visualization\n\nThis entails trying to reduce the ~10-50 PCA dimensions into a 2 dimensional space. \n\nTo do this the algorithm performs non-linear transformations that distort the true distances between cells\n\nAttempts to balance global and local differences to produce visualization that capture variation in data. \n\n`runUMAP()` and `runTSNE()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234323523)\nsce <- runUMAP(sce, dimred = \"PCA\")\nreducedDims(sce)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of length 2\nnames(2): PCA UMAP\n```\n\n\n:::\n:::\n\n\n\n## Plotting the UMAP ‚å®Ô∏è\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotUMAP(sce)\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-15-1.png){width=864}\n:::\n:::\n\n\n\n## Plotting the UMAP ‚å®Ô∏è\nWe can also color by any gene expression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotUMAP(sce, colour_by = \"CD3D\")\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-16-1.png){width=864}\n:::\n:::\n\n\n\n## Plotting the UMAP ‚å®Ô∏è\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotUMAP(sce, colour_by = \"CD79A\")\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-17-1.png){width=864}\n:::\n:::\n\n\n\n## Parameters affect the visualization  {.smaller}\n\n\n:::: {.columns}\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n::: {.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\n:::\n::::\n\n\n## Clustering {.smaller}\n\nWe use clustering to assign cells to discrete cell populations. This is a simplification of the true complexity of the underlying data.\n\nClustering is a data analysis tool rather than a result. We can increase, decrease, merge, or subset clusters at our whim by changing clustering parameters, the # of PCs used, the # of variable genes, and the particular cell subsets analyzed. \n\nThere is no correct or valid number of clusters. It depends on what biological question you are trying to explore and at what granularity you want to ask the question. \n\n>[A]sking for an unqualified ‚Äúbest‚Äù clustering is akin to asking for the best magnification on a microscope without any context - OSCA book\n \n\n## Graph based clustering {.smaller .nonincremental}\n\nApproach:\n\n- identify the K nearest neighbors of each cell in the PCA matrix (e.g. k = 10)\n- weight the connection between cells based on \"connectivity\" of shared nearest neighbors (total number, proportion, average rank of neighbors, etc.)\n- apply a community detection algorithm to cluster the shared nearest neighbor graph (walktrap, louvain, leiden, etc.)\n- `clusterCells()` \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/clustering-1.png){width=1152}\n:::\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n**Note that the clustering is performed on the PCA matrix not the 2D UMAP plot**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(10101010)\nclusters <- clusterCells(sce, use.dimred = \"PCA\")\nsce$clusters <- clusters\ntable(clusters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclusters\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n 766  257  552  122  369  211  141 1409   52   74   55   63   44   47  103   97 \n  17   18   19 \n 163   24   16 \n```\n\n\n:::\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n\nThe parameters of the clustering can be changed by changing the `NNGraphParam`. Here are the defaults:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bluster)\nset.seed(10101010)\nclusters <- clusterCells(sce,\n  use.dimred = \"PCA\",\n  BLUSPARAM = NNGraphParam(\n    k = 10,\n    type = \"rank\",\n    cluster.fun = \"walktrap\"\n  )\n)\ntable(clusters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nclusters\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n 766  257  552  122  369  211  141 1409   52   74   55   63   44   47  103   97 \n  17   18   19 \n 163   24   16 \n```\n\n\n:::\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n\nThe parameters of the clustering can be changed by changing the `NNGraphParam`. Here are the defaults:\n\n```r\nlibrary(bluster)\nset.seed(10101010)\nclusters <- clusterCells(sce,\n  use.dimred = \"PCA\",\n  BLUSPARAM = NNGraphParam(\n    k = 10,\n    type = \"rank\",\n    cluster.fun = \"walktrap\"\n  )\n)\ntable(clusters)\n```\n\n## Clustering ‚å®Ô∏è {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsce$clusters <- clusters\n\ncolor_palette <- colorRampPalette(\n  colors = RColorBrewer::brewer.pal(n = 9, name = \"Set1\")\n)(length(unique(clusters)))\n```\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-25-1.png){width=960}\n:::\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n\nGenerally increasing the # of neighbors will decrease the number of clusters and vice versa. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12121212)\n\nclusters <- clusterCells(sce,\n  use.dimred = \"PCA\",\n  BLUSPARAM = NNGraphParam(\n    k = 100,\n    type = \"rank\",\n    cluster.fun = \"walktrap\"\n  )\n)\n\nsce$coarse_clusters <- clusters\n\ncolor_palette2 <- colorRampPalette(\n  colors = RColorBrewer::brewer.pal(n = 9, name = \"Set1\")\n)(length(unique(clusters)))\n```\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-27-1.png){width=960}\n:::\n:::\n\n\n\n## Clustering ‚å®Ô∏è {.smaller}\n\nWhat clusters are the genes S100A8, CD79A and CD3G most highly expressed in? We can use the `plotExpression()` function to visualize the expression data in each cluster.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotExpression(sce, features = c(\"S100A8\", \"CD79A\", \"CD3G\"), x = \"clusters\",\n               color_by = \"clusters\") +\n  ggplot2::scale_color_manual(values = color_palette)\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-28-1.png){width=864}\n:::\n:::\n\n\n\n## How many clusters? {.smaller}\nClustering algorithms produce clusters, even if there isn‚Äôt anything meaningfully different between cells. Determining the optimal number of clusters can be tricky and also dependent on the biological question.\n\nSome guidelines:\n\n1) Cluster the data into a small number of clusters to identify cell types, then recluster to generate additional clusters to define sub-populations of cell types.\n\n2) To determine if the data is overclustered examine differentially expressed genes between clusters. If the clusters have few or no differentially expressed genes then the data is likely overclustered. Similar clusters can be merged post-hoc if necessary as sometimes it is difficult to use 1 clustering approach for many diverse cell populations. Using a reference-based approach to name cell types will also often merge similar clusters.\n\n3) A hybrid approach is to first annotate major cell types using a small # of clusters (e.g. B-cell, T-cell, Myeloid, etc.), then subset the SingleCellExperiment object for each cluster and perform additional clustering to obtain 'subclusters' (e.g. b-cell-subset 1, b-cell-subset 2, t-cell-subset-1, etc.)\n\n## Identifying marker genes using scoreMarkers() {.smaller}\nClustering algorithms produce clusters, even if there isn‚Äôt anything meaningfully different between cells. Determining the optimal number of clusters can be tricky and also dependent on the biological question.\n\nSome guidelines:\n\n1) Cluster the data into a small number of clusters to identify cell types, then recluster to generate additional clusters to define sub-populations of cell types.\n\n2) To determine if the data is overclustered examine differentially expressed genes between clusters. If the clusters have few or no differentially expressed genes then the data is likely overclustered. Similar clusters can be merged post-hoc if necessary as sometimes it is difficult to use 1 clustering approach for many diverse cell populations. Using a reference-based approach to name cell types will also often merge similar clusters.\n\n3) A hybrid approach is to first annotate major cell types using a small # of clusters (e.g. B-cell, T-cell, Myeloid, etc.), then subset the SingleCellExperiment object for each cluster and perform additional clustering to obtain 'subclusters' (e.g. b-cell-subset 1, b-cell-subset 2, t-cell-subset-1, etc.)\n\n## Identifying marker genes using scoreMarkers()  ‚å®Ô∏è {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmrks <- scoreMarkers(sce, sce$clusters)\nmrks\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of length 19\nnames(19): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n```\n\n\n:::\n:::\n\n\n\n## How do we identify marker genes? ‚å®Ô∏è {.smaller}\nTo identify marker genes we will need to decide of cutoffs based on effect sizes. There are many reported by scoreMarkers(). \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(mrks[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"self.average\"          \"other.average\"         \"self.detected\"        \n [4] \"other.detected\"        \"mean.logFC.cohen\"      \"min.logFC.cohen\"      \n [7] \"median.logFC.cohen\"    \"max.logFC.cohen\"       \"rank.logFC.cohen\"     \n[10] \"mean.AUC\"              \"min.AUC\"               \"median.AUC\"           \n[13] \"max.AUC\"               \"rank.AUC\"              \"mean.logFC.detected\"  \n[16] \"min.logFC.detected\"    \"median.logFC.detected\" \"max.logFC.detected\"   \n[19] \"rank.logFC.detected\"  \n```\n\n\n:::\n:::\n\n\n\n## How do we identify marker genes? {.smaller}\nWhat is a marker gene?\n* Differentially expressed between cluster 1 and all others?\n  * This could be too strict, what if the same gene marks clusters 1-8 but not 9? We would miss that as a marker\n* Differentially expressed between some or any pairwise clusters\n\nThe output of scoreMarkers() allows you to filter the data in many different ways depending on what type of marker you want to identify. Importantly it doesn't hide the complexity of this data. I highly recommend reading the chapter on [marker gene detection](https://bioconductor.org/books/3.17/OSCA.basic/marker-detection.html#motivation-2) from the OSCA book to understand how best to identify markers depending on the dataset you are analyzing. \n\n## How do we identify marker genes? {.smaller}\n* We will use `AUC` to rank markers\n  * Probability that a randomly chosen observation from our cluster of interest is greater than a randomly chosen obsevation from the other cluster\n  * Value of 1 = upregulated in the cluster of interest, 0 = downregulated, 0.5 = no difference.\n* Other ranking options include log fold change or fold change in the detection rate\n* Can chose `mean`, `min`, `median`, `max`, or `rank` for potential ranking\n\nParaphrasing from the OSCA book:\n* The most obvious summary statistic is the mean. For cluster X, a large mean effect size (>0.5 for the AUCs) indicates that the gene is upregulated in X compared to the average of the other groups.\n* Another summary statistic is the median, where a large value indicates that the gene is upregulated in  X compared to most (>50%) other clusters. \n* The minimum value (min.*) is the most stringent summary for identifying upregulated genes, as a large value indicates that the gene is upregulated in X compared to all other clusters. \n* The maximum value (max.*) is the least stringent summary for identifying upregulated genes, as a large value can be obtained if there is strong upregulation in X compared to any other cluster.\n*  The minimum rank, a.k.a., ‚Äúmin-rank‚Äù (rank.*) is the smallest rank of each gene across all pairwise comparisons. Specifically, genes are ranked within each pairwise comparison based on decreasing effect size, and then the smallest rank across all comparisons is reported for each gene. If a gene has a small min-rank, we can conclude that it is one of the top upregulated genes in at least one comparison of  X to another cluster.\n\n## Cluster 1 genes ‚å®Ô∏è {.smaller}\nPlotting top genes ranked by `mean.AUC` for cluster 1. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster1_markers <- as.data.frame(mrks[[1]]) |> tibble::rownames_to_column(\"gene\")\n\nordered <- cluster1_markers |>\n  dplyr::filter(mean.AUC > 0.5) |>\n  dplyr::arrange(desc(mean.AUC))\n\nplotExpression(sce,\n  features = head(ordered$gene),\n  x = \"clusters\",\n  colour_by = \"clusters\",\n  color = color_palette\n)\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-31-1.png){width=864}\n:::\n:::\n\n\n\n## Top marker heatmap ‚å®Ô∏è {.smaller}\nNext we will extract the top N markers from each cluster, ranked on `mean.AUC`, then plot the average expression of these markers in each cluster as a heatmap.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_top_markers <- 5\n\ntop_markers <- purrr::map_dfr(mrks, ~ {\n  .x |>\n    as.data.frame() |>\n    tibble::rownames_to_column(\"gene\") |>\n    dplyr::filter(mean.AUC > 0.5) |>\n    dplyr::arrange(desc(mean.AUC)) |>\n    dplyr::slice(1:n_top_markers)\n}, .id = \"cluster\")\n\ntop_markers[1:10, 1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   cluster      gene\n1        1    S100A9\n2        1    S100A8\n3        1       LYZ\n4        1      MNDA\n5        1      FCN1\n6        2     BANK1\n7        2     CD79A\n8        2     MS4A1\n9        2 TNFRSF13C\n10       2   RALGPS2\n```\n\n\n:::\n:::\n\n\n\n## Top marker heatmap ‚å®Ô∏è {.smaller}\nNext we will extract the top N markers from each cluster, ranked on `mean.AUC`, then plot the average expression of these markers in each cluster as a heatmap.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotGroupedHeatmap(sce,\n  features = unique(top_markers$gene),\n  group = \"clusters\",\n  center = TRUE,\n  zlim = c(-3, 3)\n)\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-33-1.png){width=864}\n:::\n:::\n\n\n\n## Some differnetial expression thoughts {.smaller}\n* Differential expression in single cell RNA-seq should be interpreted with caution\n* Data is very overpowered\n  * Individual cells are treated as independent replicates (often using a Wilcoxin test)\n  * They are however NOT independent\n    * Come from the same sample\n    * Come from identical processing\n    * Come from highly correlated environments\n  * This means that p-values will be inflated and there will be many false negatives\n  * Most methods don't account for batch effects and # of DE genes does not change with increase variability between batches\n* If you are performing DE between samples, it is better to use a pseudobulk approach and control for batch effect\n* More info in two articles: [false-discoveries](https://www.nature.com/articles/s41467-021-25960-2), [pseudoreplication bias](https://www.nature.com/articles/s41467-021-21038-1)\n\n## Annotating cell types {.smaller}\n\n* Early days of single cell used manual cluster annotation\n  * Using visual inspection of key genes using expertise in the lab\n* Now it is becomming more comon to compare your dataset to another dataset or a reference\n  * Leads to more reproducability and agreement across publications\n  * Not biased to only a handful of genes, instead thousand of genes are used\n  * Correlation and machine learning approaches are common\n* Packages include `clustifyr`, `SingleR`, `SignacX`, and `Azimuth`\n\n\n## Annotating cell types {.smaller}\nWe we use [`clustifyr`](https://rnabioco.github.io/clustifyr/) which was developed by a previous RBI fellow Rui Fu. There are also many other methods (e.g. `SingleR`)\n\n* `clustifyr` compares the average gene expression in each cluster to a reference matrix that contains average gene signatures of reference cell types.\n* The reference can be built from other single cell data, bulk-rna-seq, or other sources.\n* Ranked spearman correlation is used to compare the reference to the clusters. \n* Only the variable genes are used for the correlation. \n  * Fewer variable genes (ie 1000) are recommended as too many genes leads to high correlations across the board (think of a lot of zero values).\n\nIn order to compare our dataset we need to use a publicly available reference dataset. Thankfully many datasets have been organized into a separate package: [clustifyrdatahub](https://github.com/rnabioco/clustifyrdatahub). This is an extension of the `ExperimentHub` package on bioconductor that allows you to easily download and cache external datasets. \n\n## Annotating cell types ‚å®Ô∏è {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(clustifyr)\nlibrary(clustifyrdatahub)\n\n# get reference dataset derived from a microarray experiment of sorted immune cell types\nref_hema_microarray()[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Basophils CD4+ Central Memory CD4+ Effector Memory CD8+ Central Memory\nDDR1    6.084244            5.967502             5.933039            6.005278\nRFC2    6.280044            6.028615             6.047005            5.992979\nHSPA6   6.535444            5.811475             5.746326            5.928349\nPAX8    6.669153            5.896401             6.118577            6.270870\nGUCA1A  5.239230            5.232116             5.206960            5.227415\n       CD8+ Effector Memory\nDDR1               5.895926\nRFC2               5.942426\nHSPA6              5.942670\nPAX8               6.323922\nGUCA1A             5.090882\n```\n\n\n:::\n:::\n\n\n\n## Annotating cell types ‚å®Ô∏è {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- clustify(\n  sce, # SingleCellExperiment object\n  ref_mat = ref_hema_microarray(), # cell type reference data\n  cluster_col = \"clusters\", # column in metadata with clusters\n  # don't add to SingleCellExperiment object, just return results\n  obj_out = FALSE,\n  # use variable genes for comparison\n  query_genes = top,\n)\n\nres[1:12, 1:4]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Basophils CD4+ Central Memory CD4+ Effector Memory CD8+ Central Memory\n1  0.5370093           0.4111325            0.4176017           0.3936302\n10 0.5945973           0.4591039            0.4655590           0.4433302\n11 0.4386922           0.7151960            0.7115503           0.6798845\n12 0.6333579           0.5402749            0.5289964           0.5160502\n13 0.3935435           0.6535071            0.6516310           0.6321161\n14 0.4656631           0.6099487            0.6324938           0.6493463\n15 0.6258199           0.5493260            0.5378138           0.5284327\n16 0.4883762           0.7668150            0.7549072           0.7346618\n17 0.6277840           0.5580115            0.5459105           0.5343926\n18 0.5650205           0.5267830            0.5237343           0.5021841\n19 0.3379409           0.3154402            0.3177152           0.3003928\n2  0.6210041           0.5744730            0.5678439           0.5518513\n```\n\n\n:::\n:::\n\n\n\n## Annotating cell types ‚å®Ô∏è {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| fig.height: 5\n#| fig.width: 5\nlibrary(ComplexHeatmap)\nHeatmap(t(res))\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-36-1.png){width=960}\n:::\n:::\n\n\n\n## Annotating cell types ‚å®Ô∏è {.smaller}\nWe can use `cor_to_call` to pull out the highest correlation for each cluster\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor_to_call(res) # assign cluster to highest correlation cell type (above a threshold). Cell types lower than a threshold will be assigned as unassigned.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 19 √ó 3\n# Groups:   cluster [19]\n   cluster type                                r\n   <chr>   <chr>                           <dbl>\n 1 11      CD4+ Central Memory             0.715\n 2 13      CD4+ Central Memory             0.654\n 3 5       CD4+ Effector Memory            0.769\n 4 3       CD8+ Effector Memory            0.747\n 5 2       Mature B-cell class switched    0.772\n 6 14      Mature NK cell_CD56- CD16- CD3- 0.715\n 7 6       Mature NK cell_CD56+ CD16+ CD3- 0.729\n 8 7       Mature NK cell_CD56+ CD16+ CD3- 0.735\n 9 19      Megakaryocyte                   0.462\n10 1       Monocyte                        0.756\n11 4       Monocyte                        0.713\n12 10      Myeloid Dendritic Cell          0.743\n13 9       Myeloid Dendritic Cell          0.641\n14 12      Na√Øve B-cells                   0.778\n15 15      Na√Øve B-cells                   0.794\n16 17      Na√Øve B-cells                   0.797\n17 16      Naive CD4+ T-cell               0.781\n18 8       Naive CD4+ T-cell               0.765\n19 18      Plasmacytoid Dendritic Cell     0.673\n```\n\n\n:::\n:::\n\n\n\n## Annotating cell types ‚å®Ô∏è {.smaller}\nOr we can insert the classification results into the SingleCellExperiment object directly which will be called `type`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nsce <- clustify(\n  sce, # seurat object\n  ref_mat = ref_hema_microarray(), # cell type reference data\n  cluster_col = \"clusters\", # column in metadata with clusters\n  obj_out = TRUE,\n  # use variable genes for comparison\n  query_genes = top\n)\n\nplotUMAP(sce, colour_by = \"type\")\n```\n\n::: {.cell-output-display}\n![](slides-32_files/figure-revealjs/unnamed-chunk-38-1.png){width=960}\n:::\n:::\n\n\n\n## Saving and sharing objects\n1) You can share your SingleCellExperiment objects with collaborators by saving the object as an `.rds` file. \n\n2) If you plan on publishing the data, then the best practices are to upload the UMI count matrix and your colData() data.frame containing the cell type annotations. \n\nTo save the UMI count matrix use write10xcounts() from the DropletUtils Bioconductor package.\n``` r\nmat <- counts(sce) \nwrite10xCounts(\"path/to/output\", mat)\n``` \n\n## Saving and sharing objects\nWhen saving the `colData()` it is also a nice gesture to include the UMAP coordinates that you used for the main visualizations in your manuscript. The clustering and UMAP coordinates are very hard to reproduce because of the non-deterministic elements of the algorithms. \n\n``` r\ncbind(colData(sce), reducedDim(sce, \"UMAP\")) |> \n  rownames_to_column(\"cell\") |> ()\n  write_csv(\"cell-level-metadata.csv\")\n```  \n\n## Saving and sharing objects\n* In addition to sharing count tables, in most cases (except for some cases of human data), you must publish your fastq files\n* Make sure these are always protected using the 3-2-1 strategy:\n  * 3 copies\n  * 2 storage types\n  * 1 off site\n* For me, this is:\n  * Peta library active allocation\n  * Peta library archive allocation\n  * AWS glacial storage (with version control)\n  * Nightly backup between each\n  * Changing the permissions to read only for fastq files\n\n## Saving and sharing objects\n* It is also best practice to share your code\n* Keep your code on github\n  * Version control - if you make a mistake it's easy to go back\n  * Github counts as a backup for your scripts. The sever goes down, you can recover everything from github\n  * Easy to change a repo to public when your manuscript is accepted",
    "supporting": [
      "slides-32_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../site_libs/viz-1.8.2/viz.js\"></script>\n<link href=\"../site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/grViz-binding-1.0.11/grViz.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}